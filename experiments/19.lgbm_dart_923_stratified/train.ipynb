{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd2ca34-3410-4078-aa48-7adbba211ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import joblib\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import random\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from itertools import repeat\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, fbeta_score, make_scorer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb17d64c-4cdb-4906-be84-1348484a4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import ListedColormap\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "from colorama import Fore, Back, Style\n",
    "plt.rcParams['axes.facecolor'] = '#0057b8' # blue\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n",
    "                                         plt.rcParams['axes.prop_cycle'].by_key()['color'][1:])\n",
    "plt.rcParams['text.color'] = 'w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a084bef6-4434-40fb-bafc-d7d3e4c57a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common import (\n",
    "    sigmoid, pad_column_name\n",
    ")\n",
    "from utils.constants import *\n",
    "from utils.eval_helpers import (\n",
    "    plot_roc_curves, plot_feature_importance, \n",
    "    amex_metric, get_final_metric_df, amex_metric_np, lgb_amex_metric\n",
    ")\n",
    "from utils.eda_helpers import (\n",
    "    plot_missing_proportion_barchart, \n",
    "    get_cols\n",
    ")\n",
    "from utils.extraction_helpers import read_file\n",
    "from utils.feature_group import (\n",
    "    CATEGORY_COLUMNS, CONTINUOUS_COLUMNS, NON_FEATURE_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67194602-57fc-4e92-9801-8d600e52a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d61a64-56d4-4f2d-ba70-09af3d6e3a43",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10289f15-1333-485c-a3ac-c530c5a90507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████▏                                                                                                            | 1/5 [00:00<00:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (82603, 4083)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████▍                                                                                 | 2/5 [00:01<00:02,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (82603, 4083)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████████████████████████████▌                                                      | 3/5 [00:03<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (82603, 4083)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4/5 [00:04<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (82602, 4083)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (82602, 4083)\n",
      "CPU times: user 2.02 s, sys: 3.33 s, total: 5.35 s\n",
      "Wall time: 6.08 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_dict = {}\n",
    "for i in tqdm(range(5)):\n",
    "    df_dict[i] = read_file(f\"../{PROCESSED_DATA_PATH}/v10/validation_fold{i}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c74185-93e2-45a3-b711-0dc3b5dba2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (458913, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = read_file(f\"../{RAW_DATA_PATH}/train_labels.csv\")\n",
    "target = labels[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "664aa1a5-f8a4-48d2-83c7-cdb15594f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict = {}\n",
    "for i in range(5):\n",
    "    y_dict[i] = df_dict[i][\"target\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4346203-95a4-4ac2-bf84-d9645e2e56c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 442 ms, sys: 1.99 s, total: 2.43 s\n",
      "Wall time: 3.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for i in tqdm(range(5)):\n",
    "    df_dict[i].drop(columns=NON_FEATURE_COLUMNS + [\"target\"], errors=\"ignore\", inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86cab4cb-c0cf-4d84-9c64-5cc46766d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_model = joblib.load(f\"../{EXP_PATH}/1.lgbm_dart_923/models/model_fold2_seed923.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5166347-0e77-4e59-a682-e2861e857ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2526"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prev_model.feature_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d763ec79-3b4e-47bb-8f17-5a46726cedcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 434 ms, sys: 1.38 s, total: 1.81 s\n",
      "Wall time: 1.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for df in tqdm(df_dict.values()):\n",
    "    df.drop(columns=list(set(df.columns) - set(prev_model.feature_name())), inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00195db7-f127-44f5-bdcf-5f7b009bca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file(f\"../{EXP_PATH}/1.lgbm_dart_923/feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe9c5197-55d9-4b16-95d7-0222789c3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_columns = get_cols(df, [\"D_87\", \"S_9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c0cb72-ed12-4dc1-8877-6f6c524bb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 ms, sys: 851 ms, total: 1.07 s\n",
      "Wall time: 1.31 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for df in tqdm(df_dict.values()):\n",
    "    df.drop(columns=drift_columns, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604f119e-10b6-4f0f-9883-44cb35c9b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_38_last', 'D_63_last', 'D_64_last', 'D_68_last', 'D_92_last', 'D_114_last', 'D_116_last', 'D_117_last', 'D_120_last', 'D_126_last', 'B_30_second_last', 'B_38_second_last', 'D_64_second_last', 'D_68_second_last', 'D_92_second_last', 'D_114_second_last', 'D_116_second_last', 'D_117_second_last', 'D_126_second_last', 'B_30_first', 'B_38_first', 'D_64_first', 'D_68_first', 'D_114_first', 'D_116_first', 'D_117_first', 'D_120_first']\n"
     ]
    }
   ],
   "source": [
    "cat_features = get_cols(df_dict[0], CATEGORY_COLUMNS)\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35773bb3-325e-49ee-b079-1abe1cb36e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = plot_missing_proportion_barchart(df_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96742084-cbae-4c4a-9d85-20ada1166ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_missing_columns = m.loc[m[\"missing_proportion\"] > 99.9][\"column\"].tolist()\n",
    "# len(high_missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cec23f08-913e-4a15-b0c7-0bd92166a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for df in tqdm(df_dict.values()):\n",
    "#     df = df.drop(columns=high_missing_columns, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46942b4a-fd5a-4bd0-9dbd-7ceb4b99f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 284 ms, sys: 621 ms, total: 905 ms\n",
      "Wall time: 930 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for df in tqdm(df_dict.values()):\n",
    "    df.drop(columns=NON_FEATURE_COLUMNS + [\"target\"], errors=\"ignore\", inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe8f01a-341d-4cbe-8c46-8ae026830c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = get_cols(df_dict[0], CATEGORY_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f2abbb-1269-4190-92cc-d2f50fed158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_38_last', 'D_63_last', 'D_64_last', 'D_68_last', 'D_92_last', 'D_114_last', 'D_116_last', 'D_117_last', 'D_120_last', 'D_126_last', 'B_30_second_last', 'B_38_second_last', 'D_64_second_last', 'D_68_second_last', 'D_92_second_last', 'D_114_second_last', 'D_116_second_last', 'D_117_second_last', 'D_126_second_last', 'B_30_first', 'B_38_first', 'D_64_first', 'D_68_first', 'D_114_first', 'D_116_first', 'D_117_first', 'D_120_first']\n"
     ]
    }
   ],
   "source": [
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80925934-1a9e-4dda-b8dc-4557eb8c6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_agg.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63209e65-9d82-4b2e-bf34-f4a15560f08f",
   "metadata": {},
   "source": [
    "### Train LGBM using pre-set hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3d2e782-8f4d-4e59-a03e-e962e88db2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dff6a648-ded8-43f6-b031-5b0799c5dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': \"binary_logloss\",\n",
    "    'boosting': 'dart',\n",
    "    'seed': seed,\n",
    "    'num_leaves': 89,\n",
    "    'learning_rate': 0.0118,\n",
    "    'feature_fraction': 0.195,\n",
    "    'bagging_freq': 9,\n",
    "    'bagging_fraction': 0.57,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 16,\n",
    "    'min_data_in_leaf': 80,\n",
    "    'scale_pos_weight': 1.4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1b37088-1024-4866-a5af-f8d07793b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = labels[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9283e489-e41d-433c-a2da-174aab8aa0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = plot_feature_importance(model.feature_name(), model.feature_importance(), limit=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f50fec67-2703-4170-84c8-dae15fc3ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noob_features1 = m.loc[m[\"feature_importance\"] < 5][\"feature\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e23688c-07aa-4a77-8c58-96cf62028876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for df in tqdm(df_dict.values()):\n",
    "#     df.drop(columns=noob_features1, errors=\"ignore\", inplace=True)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cf6696a-416c-4f14-8b69-44730d0efc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82603, 2485)\n"
     ]
    }
   ],
   "source": [
    "print(df_dict[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a3f9da4-3caf-4f89-8d0d-814127b7b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2485 features...\n",
      "--------------------------------------------------\n",
      "X shape:  (330410, 2485) (82603, 2485)\n",
      "Y shape:  (330410,) (82603,)\n",
      "[LightGBM] [Info] Number of positive: 85542, number of negative: 244868\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.568487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 394702\n",
      "[LightGBM] [Info] Number of data points in the train set: 330410, number of used features: 2466\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258897 -> initscore=-1.051712\n",
      "[LightGBM] [Info] Start training from score -1.051712\n",
      "[1000]\ttraining's binary_logloss: 0.241675\ttraining's amex: 0.794774\tvalid_1's binary_logloss: 0.249609\tvalid_1's amex: 0.776322\n",
      "[2000]\ttraining's binary_logloss: 0.208224\ttraining's amex: 0.822542\tvalid_1's binary_logloss: 0.226201\tvalid_1's amex: 0.78866\n",
      "[3000]\ttraining's binary_logloss: 0.193622\ttraining's amex: 0.84316\tvalid_1's binary_logloss: 0.221366\tvalid_1's amex: 0.793813\n",
      "[4000]\ttraining's binary_logloss: 0.181648\ttraining's amex: 0.862798\tvalid_1's binary_logloss: 0.219139\tvalid_1's amex: 0.795553\n",
      "[5000]\ttraining's binary_logloss: 0.171313\ttraining's amex: 0.880537\tvalid_1's binary_logloss: 0.218103\tvalid_1's amex: 0.796582\n",
      "[6000]\ttraining's binary_logloss: 0.16075\ttraining's amex: 0.898735\tvalid_1's binary_logloss: 0.217198\tvalid_1's amex: 0.797472\n",
      "[7000]\ttraining's binary_logloss: 0.15103\ttraining's amex: 0.915894\tvalid_1's binary_logloss: 0.216701\tvalid_1's amex: 0.798498\n",
      "[8000]\ttraining's binary_logloss: 0.142429\ttraining's amex: 0.930574\tvalid_1's binary_logloss: 0.21634\tvalid_1's amex: 0.798286\n",
      "[9000]\ttraining's binary_logloss: 0.134097\ttraining's amex: 0.943863\tvalid_1's binary_logloss: 0.216069\tvalid_1's amex: 0.799137\n",
      "Our fold 0 CV score is 0.799311523198661\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2485 features...\n",
      "--------------------------------------------------\n",
      "X shape:  (330410, 2485) (82603, 2485)\n",
      "Y shape:  (330410,) (82603,)\n",
      "[LightGBM] [Info] Number of positive: 85542, number of negative: 244868\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.557301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 394796\n",
      "[LightGBM] [Info] Number of data points in the train set: 330410, number of used features: 2467\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258897 -> initscore=-1.051712\n",
      "[LightGBM] [Info] Start training from score -1.051712\n",
      "[1000]\ttraining's binary_logloss: 0.241809\ttraining's amex: 0.79505\tvalid_1's binary_logloss: 0.249803\tvalid_1's amex: 0.778418\n",
      "[2000]\ttraining's binary_logloss: 0.208435\ttraining's amex: 0.822659\tvalid_1's binary_logloss: 0.225797\tvalid_1's amex: 0.787541\n",
      "[3000]\ttraining's binary_logloss: 0.193905\ttraining's amex: 0.842587\tvalid_1's binary_logloss: 0.220576\tvalid_1's amex: 0.791938\n",
      "[4000]\ttraining's binary_logloss: 0.181848\ttraining's amex: 0.862156\tvalid_1's binary_logloss: 0.21837\tvalid_1's amex: 0.795557\n",
      "[5000]\ttraining's binary_logloss: 0.171514\ttraining's amex: 0.880889\tvalid_1's binary_logloss: 0.217287\tvalid_1's amex: 0.796299\n",
      "[6000]\ttraining's binary_logloss: 0.160931\ttraining's amex: 0.89825\tvalid_1's binary_logloss: 0.216367\tvalid_1's amex: 0.797413\n",
      "[7000]\ttraining's binary_logloss: 0.151178\ttraining's amex: 0.915503\tvalid_1's binary_logloss: 0.215896\tvalid_1's amex: 0.797896\n",
      "[8000]\ttraining's binary_logloss: 0.142477\ttraining's amex: 0.930522\tvalid_1's binary_logloss: 0.215643\tvalid_1's amex: 0.798281\n",
      "[9000]\ttraining's binary_logloss: 0.134136\ttraining's amex: 0.943373\tvalid_1's binary_logloss: 0.215438\tvalid_1's amex: 0.798869\n",
      "Our fold 1 CV score is 0.7990197209136167\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2485 features...\n",
      "--------------------------------------------------\n",
      "X shape:  (330410, 2485) (82603, 2485)\n",
      "Y shape:  (330410,) (82603,)\n",
      "[LightGBM] [Info] Number of positive: 85542, number of negative: 244868\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.494868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 394549\n",
      "[LightGBM] [Info] Number of data points in the train set: 330410, number of used features: 2466\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258897 -> initscore=-1.051712\n",
      "[LightGBM] [Info] Start training from score -1.051712\n",
      "[1000]\ttraining's binary_logloss: 0.241365\ttraining's amex: 0.795555\tvalid_1's binary_logloss: 0.250539\tvalid_1's amex: 0.774107\n",
      "[2000]\ttraining's binary_logloss: 0.208198\ttraining's amex: 0.822729\tvalid_1's binary_logloss: 0.226786\tvalid_1's amex: 0.786576\n",
      "[3000]\ttraining's binary_logloss: 0.193623\ttraining's amex: 0.842746\tvalid_1's binary_logloss: 0.221647\tvalid_1's amex: 0.790788\n",
      "[4000]\ttraining's binary_logloss: 0.181612\ttraining's amex: 0.862075\tvalid_1's binary_logloss: 0.219492\tvalid_1's amex: 0.793579\n",
      "[5000]\ttraining's binary_logloss: 0.171258\ttraining's amex: 0.880191\tvalid_1's binary_logloss: 0.218382\tvalid_1's amex: 0.794533\n",
      "[6000]\ttraining's binary_logloss: 0.160678\ttraining's amex: 0.898637\tvalid_1's binary_logloss: 0.217527\tvalid_1's amex: 0.795592\n",
      "[7000]\ttraining's binary_logloss: 0.150992\ttraining's amex: 0.915514\tvalid_1's binary_logloss: 0.216983\tvalid_1's amex: 0.796139\n",
      "[8000]\ttraining's binary_logloss: 0.142303\ttraining's amex: 0.930194\tvalid_1's binary_logloss: 0.216666\tvalid_1's amex: 0.796015\n",
      "[9000]\ttraining's binary_logloss: 0.133996\ttraining's amex: 0.94342\tvalid_1's binary_logloss: 0.216375\tvalid_1's amex: 0.795774\n",
      "Our fold 2 CV score is 0.7959017935440993\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 2485 features...\n",
      "--------------------------------------------------\n",
      "X shape:  (330411, 2485) (82602, 2485)\n",
      "Y shape:  (330411,) (82602,)\n",
      "[LightGBM] [Info] Number of positive: 85543, number of negative: 244868\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.459453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 394621\n",
      "[LightGBM] [Info] Number of data points in the train set: 330411, number of used features: 2465\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258899 -> initscore=-1.051700\n",
      "[LightGBM] [Info] Start training from score -1.051700\n",
      "[1000]\ttraining's binary_logloss: 0.241603\ttraining's amex: 0.795067\tvalid_1's binary_logloss: 0.250129\tvalid_1's amex: 0.776174\n",
      "[2000]\ttraining's binary_logloss: 0.208226\ttraining's amex: 0.822129\tvalid_1's binary_logloss: 0.22631\tvalid_1's amex: 0.790392\n",
      "[3000]\ttraining's binary_logloss: 0.193625\ttraining's amex: 0.842916\tvalid_1's binary_logloss: 0.221341\tvalid_1's amex: 0.795283\n",
      "[4000]\ttraining's binary_logloss: 0.181616\ttraining's amex: 0.86235\tvalid_1's binary_logloss: 0.219441\tvalid_1's amex: 0.795897\n",
      "[5000]\ttraining's binary_logloss: 0.171256\ttraining's amex: 0.880537\tvalid_1's binary_logloss: 0.218423\tvalid_1's amex: 0.797198\n",
      "[6000]\ttraining's binary_logloss: 0.160706\ttraining's amex: 0.898338\tvalid_1's binary_logloss: 0.217649\tvalid_1's amex: 0.796725\n",
      "[7000]\ttraining's binary_logloss: 0.150995\ttraining's amex: 0.915284\tvalid_1's binary_logloss: 0.217122\tvalid_1's amex: 0.796962\n",
      "[8000]\ttraining's binary_logloss: 0.142356\ttraining's amex: 0.930348\tvalid_1's binary_logloss: 0.216952\tvalid_1's amex: 0.797655\n",
      "[9000]\ttraining's binary_logloss: 0.134038\ttraining's amex: 0.943222\tvalid_1's binary_logloss: 0.21676\tvalid_1's amex: 0.798954\n",
      "Our fold 3 CV score is 0.7985285128704216\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 2485 features...\n",
      "--------------------------------------------------\n",
      "X shape:  (330411, 2485) (82602, 2485)\n",
      "Y shape:  (330411,) (82602,)\n",
      "[LightGBM] [Info] Number of positive: 85543, number of negative: 244868\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.510094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 394571\n",
      "[LightGBM] [Info] Number of data points in the train set: 330411, number of used features: 2466\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258899 -> initscore=-1.051700\n",
      "[LightGBM] [Info] Start training from score -1.051700\n",
      "[1000]\ttraining's binary_logloss: 0.241427\ttraining's amex: 0.795407\tvalid_1's binary_logloss: 0.250229\tvalid_1's amex: 0.775931\n",
      "[2000]\ttraining's binary_logloss: 0.208261\ttraining's amex: 0.822905\tvalid_1's binary_logloss: 0.22651\tvalid_1's amex: 0.787927\n",
      "[3000]\ttraining's binary_logloss: 0.193679\ttraining's amex: 0.842962\tvalid_1's binary_logloss: 0.221368\tvalid_1's amex: 0.792209\n",
      "[4000]\ttraining's binary_logloss: 0.18168\ttraining's amex: 0.862856\tvalid_1's binary_logloss: 0.219163\tvalid_1's amex: 0.795063\n",
      "[5000]\ttraining's binary_logloss: 0.171376\ttraining's amex: 0.880793\tvalid_1's binary_logloss: 0.218077\tvalid_1's amex: 0.796959\n",
      "[6000]\ttraining's binary_logloss: 0.160775\ttraining's amex: 0.898513\tvalid_1's binary_logloss: 0.217218\tvalid_1's amex: 0.796991\n",
      "[7000]\ttraining's binary_logloss: 0.151049\ttraining's amex: 0.915707\tvalid_1's binary_logloss: 0.216789\tvalid_1's amex: 0.797453\n",
      "[8000]\ttraining's binary_logloss: 0.142387\ttraining's amex: 0.930707\tvalid_1's binary_logloss: 0.216522\tvalid_1's amex: 0.797621\n",
      "[9000]\ttraining's binary_logloss: 0.134087\ttraining's amex: 0.943638\tvalid_1's binary_logloss: 0.216325\tvalid_1's amex: 0.798288\n",
      "Our fold 4 CV score is 0.7979096681357412\n"
     ]
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {df_dict[0].shape[1]} features...')\n",
    "    print('-'*50)\n",
    "    x_train = pd.concat([df for idx, df in df_dict.items() if idx != fold], ignore_index=True)\n",
    "    x_val = df_dict[fold]\n",
    "    print(\"X shape: \", x_train.shape, x_val.shape)\n",
    "    y_train = pd.concat([y_dict[idx] for idx in range(5) if idx != fold], ignore_index=True)\n",
    "    y_val = y_dict[fold]\n",
    "    print(\"Y shape: \", y_train.shape, y_val.shape)\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 9000,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 300,\n",
    "        verbose_eval = 1000,\n",
    "        feval = lgb_amex_metric\n",
    "    )\n",
    "    # Save best model\n",
    "    joblib.dump(model, f'./models/model_fold{fold}_seed{seed}.pkl')\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(x_val, raw_score=True)\n",
    "    val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)                                      \n",
    "    print(f'Our fold {fold} CV score is {val_score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cfb04-2bd9-44c1-b637-6fe5ff33ac78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

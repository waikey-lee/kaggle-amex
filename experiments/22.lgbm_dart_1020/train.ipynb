{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd2ca34-3410-4078-aa48-7adbba211ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import joblib\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import repeat\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, fbeta_score, make_scorer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb17d64c-4cdb-4906-be84-1348484a4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import ListedColormap\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "from colorama import Fore, Back, Style\n",
    "plt.rcParams['axes.facecolor'] = '#0057b8' # blue\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n",
    "                                         plt.rcParams['axes.prop_cycle'].by_key()['color'][1:])\n",
    "plt.rcParams['text.color'] = 'w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a084bef6-4434-40fb-bafc-d7d3e4c57a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common import (\n",
    "    sigmoid, pad_column_name\n",
    ")\n",
    "from utils.constants import *\n",
    "from utils.eval_helpers import (\n",
    "    plot_roc_curves, plot_feature_importance, TreeExperiment,\n",
    "    amex_metric, get_final_metric_df, amex_metric_np, lgb_amex_metric\n",
    ")\n",
    "from utils.eda_helpers import (\n",
    "    plot_missing_proportion_barchart, \n",
    "    get_cols\n",
    ")\n",
    "from utils.extraction_helpers import read_file\n",
    "from utils.feature_group import (\n",
    "    CATEGORY_COLUMNS, CONTINUOUS_COLUMNS, NON_FEATURE_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67194602-57fc-4e92-9801-8d600e52a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885beac-e245-43b6-a2cc-73e9f871d132",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d46155-ea8e-4212-8c63-5b7ac8b08d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (458913, 3476)\n",
      "CPU times: user 3.36 s, sys: 12.1 s, total: 15.5 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = read_file(f\"../{PROCESSED_DATA_PATH}/v22/train_agg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35773bb3-325e-49ee-b079-1abe1cb36e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = plot_missing_proportion_barchart(train_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c7632d-3cf9-4ff9-9467-9ebe9d2daecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (458913, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = read_file(f\"../{RAW_DATA_PATH}/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96742084-cbae-4c4a-9d85-20ada1166ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_missing_columns = m.loc[m[\"missing_proportion\"] > 98][\"column\"].tolist()\n",
    "len(high_missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cec23f08-913e-4a15-b0c7-0bd92166a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 745 ms, sys: 2.31 s, total: 3.05 s\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = train_agg.drop(columns=high_missing_columns, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e33c5bb-d206-419d-8935-adb74be8117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 3262)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46942b4a-fd5a-4bd0-9dbd-7ceb4b99f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 522 ms, sys: 2.91 s, total: 3.43 s\n",
      "Wall time: 5.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10782"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = train_agg.drop(columns=NON_FEATURE_COLUMNS + [\"target\"], errors=\"ignore\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffe8f01a-341d-4cbe-8c46-8ae026830c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = train_agg.select_dtypes(\"category\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60d24887-0440-4dd0-83b3-6b9e3a451aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 3260), 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.shape, len(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523bed1-cab5-4ae2-84be-5e9d50df9c6e",
   "metadata": {},
   "source": [
    "### Train LGBM GBDT using pre-set hyperparams to filter out some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3d2e782-8f4d-4e59-a03e-e962e88db2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4242c36-4936-45c9-a8e7-33ff9a312586",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': \"binary_logloss\",\n",
    "    'boosting': 'gbdt',\n",
    "    'seed': seed,\n",
    "    'num_leaves': 90,\n",
    "    'learning_rate': 0.025,\n",
    "    'feature_fraction': 0.22,\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 30,\n",
    "    'min_data_in_leaf': 128,\n",
    "    'scale_pos_weight': 1.35,\n",
    "    'max_bins': 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c57a3a3d-a51c-436e-9b0b-d19a66668b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1b37088-1024-4866-a5af-f8d07793b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = labels[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8849e455-d1e2-4e91-91c4-5b476a96ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 3260 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.234909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 401043\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3255\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.242897\ttraining's amex: 0.779044\tvalid_1's binary_logloss: 0.251555\tvalid_1's amex: 0.766815\n",
      "[200]\ttraining's binary_logloss: 0.21623\ttraining's amex: 0.801431\tvalid_1's binary_logloss: 0.231437\tvalid_1's amex: 0.77954\n",
      "[300]\ttraining's binary_logloss: 0.205505\ttraining's amex: 0.816903\tvalid_1's binary_logloss: 0.227014\tvalid_1's amex: 0.786164\n",
      "[400]\ttraining's binary_logloss: 0.19736\ttraining's amex: 0.829099\tvalid_1's binary_logloss: 0.224925\tvalid_1's amex: 0.788998\n",
      "[500]\ttraining's binary_logloss: 0.19047\ttraining's amex: 0.840402\tvalid_1's binary_logloss: 0.223747\tvalid_1's amex: 0.790534\n",
      "[600]\ttraining's binary_logloss: 0.18408\ttraining's amex: 0.850863\tvalid_1's binary_logloss: 0.222783\tvalid_1's amex: 0.791551\n",
      "[700]\ttraining's binary_logloss: 0.178209\ttraining's amex: 0.861855\tvalid_1's binary_logloss: 0.222287\tvalid_1's amex: 0.792586\n",
      "[800]\ttraining's binary_logloss: 0.172625\ttraining's amex: 0.871496\tvalid_1's binary_logloss: 0.221838\tvalid_1's amex: 0.792827\n",
      "Early stopping, best iteration is:\n",
      "[781]\ttraining's binary_logloss: 0.17367\ttraining's amex: 0.869566\tvalid_1's binary_logloss: 0.221936\tvalid_1's amex: 0.793695\n",
      "Our fold 0 CV score is 0.7934555824973957\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 3260 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.960401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400995\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3255\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.24347\ttraining's amex: 0.778894\tvalid_1's binary_logloss: 0.249868\tvalid_1's amex: 0.76743\n",
      "[200]\ttraining's binary_logloss: 0.216788\ttraining's amex: 0.801036\tvalid_1's binary_logloss: 0.229269\tvalid_1's amex: 0.781796\n",
      "[300]\ttraining's binary_logloss: 0.205999\ttraining's amex: 0.815999\tvalid_1's binary_logloss: 0.22461\tvalid_1's amex: 0.786788\n",
      "[400]\ttraining's binary_logloss: 0.197884\ttraining's amex: 0.828387\tvalid_1's binary_logloss: 0.222461\tvalid_1's amex: 0.789037\n",
      "[500]\ttraining's binary_logloss: 0.190918\ttraining's amex: 0.839761\tvalid_1's binary_logloss: 0.221276\tvalid_1's amex: 0.791203\n",
      "[600]\ttraining's binary_logloss: 0.184588\ttraining's amex: 0.850898\tvalid_1's binary_logloss: 0.220577\tvalid_1's amex: 0.792038\n",
      "[700]\ttraining's binary_logloss: 0.178653\ttraining's amex: 0.861653\tvalid_1's binary_logloss: 0.220153\tvalid_1's amex: 0.792311\n",
      "[800]\ttraining's binary_logloss: 0.173061\ttraining's amex: 0.871575\tvalid_1's binary_logloss: 0.219857\tvalid_1's amex: 0.792813\n",
      "[900]\ttraining's binary_logloss: 0.167694\ttraining's amex: 0.880443\tvalid_1's binary_logloss: 0.219547\tvalid_1's amex: 0.793167\n",
      "[1000]\ttraining's binary_logloss: 0.162638\ttraining's amex: 0.889297\tvalid_1's binary_logloss: 0.219332\tvalid_1's amex: 0.793121\n",
      "Early stopping, best iteration is:\n",
      "[973]\ttraining's binary_logloss: 0.163991\ttraining's amex: 0.887286\tvalid_1's binary_logloss: 0.219383\tvalid_1's amex: 0.793716\n",
      "Our fold 1 CV score is 0.7934769394314092\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 3260 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.186518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400909\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3255\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.243717\ttraining's amex: 0.778205\tvalid_1's binary_logloss: 0.249409\tvalid_1's amex: 0.767983\n",
      "[200]\ttraining's binary_logloss: 0.217152\ttraining's amex: 0.800443\tvalid_1's binary_logloss: 0.228403\tvalid_1's amex: 0.782133\n",
      "[300]\ttraining's binary_logloss: 0.206387\ttraining's amex: 0.816046\tvalid_1's binary_logloss: 0.223604\tvalid_1's amex: 0.787923\n",
      "[400]\ttraining's binary_logloss: 0.198315\ttraining's amex: 0.828039\tvalid_1's binary_logloss: 0.221516\tvalid_1's amex: 0.790125\n",
      "[500]\ttraining's binary_logloss: 0.191314\ttraining's amex: 0.839791\tvalid_1's binary_logloss: 0.220297\tvalid_1's amex: 0.79088\n",
      "[600]\ttraining's binary_logloss: 0.184969\ttraining's amex: 0.850116\tvalid_1's binary_logloss: 0.219568\tvalid_1's amex: 0.79299\n",
      "[700]\ttraining's binary_logloss: 0.179055\ttraining's amex: 0.860804\tvalid_1's binary_logloss: 0.219106\tvalid_1's amex: 0.793351\n",
      "[800]\ttraining's binary_logloss: 0.173438\ttraining's amex: 0.870825\tvalid_1's binary_logloss: 0.218687\tvalid_1's amex: 0.793717\n",
      "[900]\ttraining's binary_logloss: 0.168199\ttraining's amex: 0.879964\tvalid_1's binary_logloss: 0.218437\tvalid_1's amex: 0.794421\n",
      "[1000]\ttraining's binary_logloss: 0.163169\ttraining's amex: 0.888363\tvalid_1's binary_logloss: 0.218196\tvalid_1's amex: 0.794499\n",
      "Early stopping, best iteration is:\n",
      "[942]\ttraining's binary_logloss: 0.166023\ttraining's amex: 0.883613\tvalid_1's binary_logloss: 0.21829\tvalid_1's amex: 0.795001\n",
      "Our fold 2 CV score is 0.7947620986630964\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 3260 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.070503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400889\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 3255\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.243589\ttraining's amex: 0.778639\tvalid_1's binary_logloss: 0.249003\tvalid_1's amex: 0.768012\n",
      "[200]\ttraining's binary_logloss: 0.21694\ttraining's amex: 0.800353\tvalid_1's binary_logloss: 0.228025\tvalid_1's amex: 0.781762\n",
      "[300]\ttraining's binary_logloss: 0.20626\ttraining's amex: 0.815851\tvalid_1's binary_logloss: 0.223272\tvalid_1's amex: 0.787808\n",
      "[400]\ttraining's binary_logloss: 0.198186\ttraining's amex: 0.827828\tvalid_1's binary_logloss: 0.221099\tvalid_1's amex: 0.791278\n",
      "[500]\ttraining's binary_logloss: 0.191262\ttraining's amex: 0.839624\tvalid_1's binary_logloss: 0.219861\tvalid_1's amex: 0.793031\n",
      "[600]\ttraining's binary_logloss: 0.18486\ttraining's amex: 0.850548\tvalid_1's binary_logloss: 0.219109\tvalid_1's amex: 0.793801\n",
      "[700]\ttraining's binary_logloss: 0.178973\ttraining's amex: 0.860427\tvalid_1's binary_logloss: 0.218553\tvalid_1's amex: 0.793983\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttraining's binary_logloss: 0.18391\ttraining's amex: 0.852264\tvalid_1's binary_logloss: 0.218992\tvalid_1's amex: 0.794242\n",
      "Our fold 3 CV score is 0.7940936434602582\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 3260 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.039248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400836\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 3255\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.244025\ttraining's amex: 0.778598\tvalid_1's binary_logloss: 0.24851\tvalid_1's amex: 0.770058\n",
      "[200]\ttraining's binary_logloss: 0.217387\ttraining's amex: 0.80085\tvalid_1's binary_logloss: 0.227227\tvalid_1's amex: 0.783214\n",
      "[300]\ttraining's binary_logloss: 0.206631\ttraining's amex: 0.815666\tvalid_1's binary_logloss: 0.222355\tvalid_1's amex: 0.78882\n",
      "[400]\ttraining's binary_logloss: 0.198605\ttraining's amex: 0.827965\tvalid_1's binary_logloss: 0.220267\tvalid_1's amex: 0.792273\n",
      "[500]\ttraining's binary_logloss: 0.191578\ttraining's amex: 0.839566\tvalid_1's binary_logloss: 0.219114\tvalid_1's amex: 0.793639\n",
      "[600]\ttraining's binary_logloss: 0.185283\ttraining's amex: 0.850587\tvalid_1's binary_logloss: 0.218446\tvalid_1's amex: 0.795111\n",
      "[700]\ttraining's binary_logloss: 0.17936\ttraining's amex: 0.860424\tvalid_1's binary_logloss: 0.217852\tvalid_1's amex: 0.795236\n",
      "[800]\ttraining's binary_logloss: 0.173735\ttraining's amex: 0.869805\tvalid_1's binary_logloss: 0.217423\tvalid_1's amex: 0.795928\n",
      "[900]\ttraining's binary_logloss: 0.168415\ttraining's amex: 0.879188\tvalid_1's binary_logloss: 0.217127\tvalid_1's amex: 0.79656\n",
      "[1000]\ttraining's binary_logloss: 0.163325\ttraining's amex: 0.887785\tvalid_1's binary_logloss: 0.216901\tvalid_1's amex: 0.796739\n",
      "[1100]\ttraining's binary_logloss: 0.158559\ttraining's amex: 0.896274\tvalid_1's binary_logloss: 0.216767\tvalid_1's amex: 0.797044\n",
      "[1200]\ttraining's binary_logloss: 0.153904\ttraining's amex: 0.904552\tvalid_1's binary_logloss: 0.216543\tvalid_1's amex: 0.796599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's binary_logloss: 0.153904\ttraining's amex: 0.904552\tvalid_1's binary_logloss: 0.216543\tvalid_1's amex: 0.796599\n",
      "Our fold 4 CV score is 0.796408808919532\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_agg, target)):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {train_agg.shape[1]} features...')\n",
    "    print('-'*50)\n",
    "    x_train, x_val = train_agg.iloc[trn_ind], train_agg.iloc[val_ind]\n",
    "    y_train, y_val = target[trn_ind], target[val_ind]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 1200,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 100,\n",
    "        verbose_eval = 100,\n",
    "        feval = lgb_amex_metric\n",
    "    )\n",
    "    # Save best model\n",
    "    joblib.dump(model, f'./gbdt_models/model_fold{fold}_seed{seed}.pkl')\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(x_val, raw_score=True)\n",
    "    val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)                                      \n",
    "    print(f'Our fold {fold} CV score is {val_score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d3522aa-c8f7-4a8c-88c2-10178f7cfcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 489 ms, sys: 313 ms, total: 803 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_gbdt = TreeExperiment(\n",
    "    exp_full_path=\"../22.lgbm_dart_1020\",\n",
    "    seed=6666, \n",
    "    model_path=\"gbdt_models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f234ea06-c16f-41a2-9df5-b998abd69e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lgbm_gbdt.feature_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5248d6d7-502c-4366-ab52-1688d380ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_use_features = f.loc[f[\"average_importance\"] == 0][\"feature\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e596d1c4-8d79-49d1-9004-0757c7128a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg.drop(columns=no_use_features, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70a16a09-58ab-471f-a282-84caa09db512",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = train_agg.select_dtypes(\"category\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98b34546-73c8-497b-b223-e863929de1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 3094), 18)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.shape, len(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d36d46-d0ee-4366-9e41-a58978803005",
   "metadata": {},
   "source": [
    "### Train LGBM Dart using pre-set hyperparams to further filter out some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85a0543d-1957-40a8-81de-505bc653bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9ecf9d4-a829-4b6b-8896-1853fe29983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': \"binary_logloss\",\n",
    "    'boosting': 'dart',\n",
    "    'seed': seed,\n",
    "    'num_leaves': 95,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.22,\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 20,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'scale_pos_weight': 1.35,\n",
    "    'max_bins': 200,\n",
    "    'skip_drop': 0.6,\n",
    "    'drop_rate': 0.075\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ccc5d9b7-0973-4894-abe9-3feefc730866",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b148e65a-9157-4658-bcc7-9a1a9593bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = labels[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0d93913-3ad8-479d-97a0-dec0dfb918c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 3094 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.940564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 398927\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3094\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[100]\ttraining's binary_logloss: 0.271333\ttraining's amex: 0.775608\tvalid_1's binary_logloss: 0.27454\tvalid_1's amex: 0.769527\n",
      "[200]\ttraining's binary_logloss: 0.248192\ttraining's amex: 0.787952\tvalid_1's binary_logloss: 0.253305\tvalid_1's amex: 0.776403\n",
      "[300]\ttraining's binary_logloss: 0.228717\ttraining's amex: 0.796815\tvalid_1's binary_logloss: 0.236534\tvalid_1's amex: 0.780904\n",
      "[400]\ttraining's binary_logloss: 0.217938\ttraining's amex: 0.806153\tvalid_1's binary_logloss: 0.228509\tvalid_1's amex: 0.784837\n",
      "[500]\ttraining's binary_logloss: 0.213116\ttraining's amex: 0.812444\tvalid_1's binary_logloss: 0.225772\tvalid_1's amex: 0.787558\n",
      "[600]\ttraining's binary_logloss: 0.20747\ttraining's amex: 0.818973\tvalid_1's binary_logloss: 0.223016\tvalid_1's amex: 0.789251\n",
      "[700]\ttraining's binary_logloss: 0.203271\ttraining's amex: 0.825284\tvalid_1's binary_logloss: 0.22139\tvalid_1's amex: 0.790347\n",
      "[800]\ttraining's binary_logloss: 0.201881\ttraining's amex: 0.82933\tvalid_1's binary_logloss: 0.221266\tvalid_1's amex: 0.791861\n",
      "[900]\ttraining's binary_logloss: 0.197263\ttraining's amex: 0.834939\tvalid_1's binary_logloss: 0.219852\tvalid_1's amex: 0.793181\n",
      "[1000]\ttraining's binary_logloss: 0.193288\ttraining's amex: 0.8408\tvalid_1's binary_logloss: 0.218667\tvalid_1's amex: 0.794008\n",
      "[1100]\ttraining's binary_logloss: 0.190074\ttraining's amex: 0.84684\tvalid_1's binary_logloss: 0.218019\tvalid_1's amex: 0.794803\n",
      "[1200]\ttraining's binary_logloss: 0.186274\ttraining's amex: 0.852525\tvalid_1's binary_logloss: 0.217377\tvalid_1's amex: 0.794356\n",
      "[1300]\ttraining's binary_logloss: 0.183837\ttraining's amex: 0.857915\tvalid_1's binary_logloss: 0.217268\tvalid_1's amex: 0.794583\n",
      "[1400]\ttraining's binary_logloss: 0.180416\ttraining's amex: 0.863139\tvalid_1's binary_logloss: 0.216741\tvalid_1's amex: 0.794161\n",
      "[1500]\ttraining's binary_logloss: 0.178103\ttraining's amex: 0.867634\tvalid_1's binary_logloss: 0.216574\tvalid_1's amex: 0.79436\n",
      "[1600]\ttraining's binary_logloss: 0.175572\ttraining's amex: 0.871574\tvalid_1's binary_logloss: 0.216387\tvalid_1's amex: 0.795004\n",
      "[1700]\ttraining's binary_logloss: 0.172523\ttraining's amex: 0.876696\tvalid_1's binary_logloss: 0.215997\tvalid_1's amex: 0.795536\n",
      "[1800]\ttraining's binary_logloss: 0.16955\ttraining's amex: 0.881715\tvalid_1's binary_logloss: 0.215813\tvalid_1's amex: 0.79599\n",
      "[1900]\ttraining's binary_logloss: 0.166761\ttraining's amex: 0.886706\tvalid_1's binary_logloss: 0.215666\tvalid_1's amex: 0.796498\n",
      "[2000]\ttraining's binary_logloss: 0.164591\ttraining's amex: 0.890598\tvalid_1's binary_logloss: 0.215518\tvalid_1's amex: 0.796375\n",
      "Our fold 0 CV score is 0.7961369729632155\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 3094 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.002185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 399071\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3094\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[100]\ttraining's binary_logloss: 0.270763\ttraining's amex: 0.776611\tvalid_1's binary_logloss: 0.276614\tvalid_1's amex: 0.762968\n",
      "[200]\ttraining's binary_logloss: 0.247504\ttraining's amex: 0.788465\tvalid_1's binary_logloss: 0.255407\tvalid_1's amex: 0.771948\n",
      "[300]\ttraining's binary_logloss: 0.228068\ttraining's amex: 0.797647\tvalid_1's binary_logloss: 0.238776\tvalid_1's amex: 0.777695\n",
      "[400]\ttraining's binary_logloss: 0.21723\ttraining's amex: 0.807145\tvalid_1's binary_logloss: 0.230818\tvalid_1's amex: 0.782277\n",
      "[500]\ttraining's binary_logloss: 0.212437\ttraining's amex: 0.812919\tvalid_1's binary_logloss: 0.228336\tvalid_1's amex: 0.784798\n",
      "[600]\ttraining's binary_logloss: 0.206808\ttraining's amex: 0.819425\tvalid_1's binary_logloss: 0.225755\tvalid_1's amex: 0.786932\n",
      "[700]\ttraining's binary_logloss: 0.202561\ttraining's amex: 0.826022\tvalid_1's binary_logloss: 0.224255\tvalid_1's amex: 0.788441\n",
      "[800]\ttraining's binary_logloss: 0.201158\ttraining's amex: 0.829459\tvalid_1's binary_logloss: 0.224106\tvalid_1's amex: 0.789288\n",
      "[900]\ttraining's binary_logloss: 0.196459\ttraining's amex: 0.835462\tvalid_1's binary_logloss: 0.222785\tvalid_1's amex: 0.790562\n",
      "[1000]\ttraining's binary_logloss: 0.192501\ttraining's amex: 0.84143\tvalid_1's binary_logloss: 0.221744\tvalid_1's amex: 0.79088\n",
      "[1100]\ttraining's binary_logloss: 0.189328\ttraining's amex: 0.847176\tvalid_1's binary_logloss: 0.22121\tvalid_1's amex: 0.791688\n",
      "[1200]\ttraining's binary_logloss: 0.185602\ttraining's amex: 0.853141\tvalid_1's binary_logloss: 0.220716\tvalid_1's amex: 0.792205\n",
      "[1300]\ttraining's binary_logloss: 0.183168\ttraining's amex: 0.857779\tvalid_1's binary_logloss: 0.220555\tvalid_1's amex: 0.792448\n",
      "[1400]\ttraining's binary_logloss: 0.179757\ttraining's amex: 0.863091\tvalid_1's binary_logloss: 0.21996\tvalid_1's amex: 0.793247\n",
      "[1500]\ttraining's binary_logloss: 0.177442\ttraining's amex: 0.86792\tvalid_1's binary_logloss: 0.219723\tvalid_1's amex: 0.793152\n",
      "[1600]\ttraining's binary_logloss: 0.174896\ttraining's amex: 0.872249\tvalid_1's binary_logloss: 0.2195\tvalid_1's amex: 0.79333\n",
      "[1700]\ttraining's binary_logloss: 0.171876\ttraining's amex: 0.877148\tvalid_1's binary_logloss: 0.219281\tvalid_1's amex: 0.793644\n",
      "[1800]\ttraining's binary_logloss: 0.16896\ttraining's amex: 0.882195\tvalid_1's binary_logloss: 0.219053\tvalid_1's amex: 0.794898\n",
      "[1900]\ttraining's binary_logloss: 0.166122\ttraining's amex: 0.887634\tvalid_1's binary_logloss: 0.218954\tvalid_1's amex: 0.795457\n",
      "[2000]\ttraining's binary_logloss: 0.163966\ttraining's amex: 0.891206\tvalid_1's binary_logloss: 0.21881\tvalid_1's amex: 0.796233\n",
      "Our fold 1 CV score is 0.7959939585149672\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 3094 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.450307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 399173\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3094\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[100]\ttraining's binary_logloss: 0.271191\ttraining's amex: 0.774986\tvalid_1's binary_logloss: 0.275462\tvalid_1's amex: 0.765819\n",
      "[200]\ttraining's binary_logloss: 0.247822\ttraining's amex: 0.787849\tvalid_1's binary_logloss: 0.254114\tvalid_1's amex: 0.774035\n",
      "[300]\ttraining's binary_logloss: 0.228521\ttraining's amex: 0.797061\tvalid_1's binary_logloss: 0.237557\tvalid_1's amex: 0.780235\n",
      "[400]\ttraining's binary_logloss: 0.217765\ttraining's amex: 0.806209\tvalid_1's binary_logloss: 0.229608\tvalid_1's amex: 0.784463\n",
      "[500]\ttraining's binary_logloss: 0.212927\ttraining's amex: 0.812429\tvalid_1's binary_logloss: 0.226814\tvalid_1's amex: 0.787733\n",
      "[600]\ttraining's binary_logloss: 0.207372\ttraining's amex: 0.818936\tvalid_1's binary_logloss: 0.224141\tvalid_1's amex: 0.789548\n",
      "[700]\ttraining's binary_logloss: 0.203112\ttraining's amex: 0.824928\tvalid_1's binary_logloss: 0.222494\tvalid_1's amex: 0.791465\n",
      "[800]\ttraining's binary_logloss: 0.201775\ttraining's amex: 0.828742\tvalid_1's binary_logloss: 0.222282\tvalid_1's amex: 0.792099\n",
      "[900]\ttraining's binary_logloss: 0.197075\ttraining's amex: 0.834538\tvalid_1's binary_logloss: 0.220803\tvalid_1's amex: 0.793158\n",
      "[1000]\ttraining's binary_logloss: 0.193156\ttraining's amex: 0.840242\tvalid_1's binary_logloss: 0.219646\tvalid_1's amex: 0.794248\n",
      "[1100]\ttraining's binary_logloss: 0.189949\ttraining's amex: 0.845882\tvalid_1's binary_logloss: 0.218969\tvalid_1's amex: 0.795083\n",
      "[1200]\ttraining's binary_logloss: 0.18617\ttraining's amex: 0.85195\tvalid_1's binary_logloss: 0.218347\tvalid_1's amex: 0.795729\n",
      "[1300]\ttraining's binary_logloss: 0.183656\ttraining's amex: 0.857023\tvalid_1's binary_logloss: 0.218234\tvalid_1's amex: 0.795251\n",
      "[1400]\ttraining's binary_logloss: 0.180231\ttraining's amex: 0.861892\tvalid_1's binary_logloss: 0.217594\tvalid_1's amex: 0.795692\n",
      "[1500]\ttraining's binary_logloss: 0.177963\ttraining's amex: 0.866371\tvalid_1's binary_logloss: 0.217532\tvalid_1's amex: 0.79651\n",
      "[1600]\ttraining's binary_logloss: 0.175409\ttraining's amex: 0.871169\tvalid_1's binary_logloss: 0.217318\tvalid_1's amex: 0.796483\n",
      "[1700]\ttraining's binary_logloss: 0.172422\ttraining's amex: 0.876086\tvalid_1's binary_logloss: 0.217003\tvalid_1's amex: 0.796504\n",
      "[1800]\ttraining's binary_logloss: 0.169475\ttraining's amex: 0.8809\tvalid_1's binary_logloss: 0.216769\tvalid_1's amex: 0.796389\n",
      "[1900]\ttraining's binary_logloss: 0.166673\ttraining's amex: 0.886126\tvalid_1's binary_logloss: 0.216704\tvalid_1's amex: 0.796387\n",
      "[2000]\ttraining's binary_logloss: 0.164503\ttraining's amex: 0.890742\tvalid_1's binary_logloss: 0.216599\tvalid_1's amex: 0.797035\n",
      "Our fold 2 CV score is 0.7967962450210523\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 3094 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.887933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 399107\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 3094\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[100]\ttraining's binary_logloss: 0.271026\ttraining's amex: 0.775344\tvalid_1's binary_logloss: 0.275937\tvalid_1's amex: 0.767537\n",
      "[200]\ttraining's binary_logloss: 0.247572\ttraining's amex: 0.787777\tvalid_1's binary_logloss: 0.2546\tvalid_1's amex: 0.777084\n",
      "[300]\ttraining's binary_logloss: 0.228184\ttraining's amex: 0.797144\tvalid_1's binary_logloss: 0.238115\tvalid_1's amex: 0.780727\n",
      "[400]\ttraining's binary_logloss: 0.217386\ttraining's amex: 0.806349\tvalid_1's binary_logloss: 0.230345\tvalid_1's amex: 0.784605\n",
      "[500]\ttraining's binary_logloss: 0.212584\ttraining's amex: 0.813254\tvalid_1's binary_logloss: 0.227733\tvalid_1's amex: 0.786752\n",
      "[600]\ttraining's binary_logloss: 0.206921\ttraining's amex: 0.819981\tvalid_1's binary_logloss: 0.225007\tvalid_1's amex: 0.789045\n",
      "[700]\ttraining's binary_logloss: 0.202688\ttraining's amex: 0.826265\tvalid_1's binary_logloss: 0.223429\tvalid_1's amex: 0.791308\n",
      "[800]\ttraining's binary_logloss: 0.201327\ttraining's amex: 0.829727\tvalid_1's binary_logloss: 0.223339\tvalid_1's amex: 0.791786\n",
      "[900]\ttraining's binary_logloss: 0.196644\ttraining's amex: 0.835416\tvalid_1's binary_logloss: 0.22199\tvalid_1's amex: 0.79175\n",
      "[1000]\ttraining's binary_logloss: 0.192733\ttraining's amex: 0.841366\tvalid_1's binary_logloss: 0.220934\tvalid_1's amex: 0.792187\n",
      "[1100]\ttraining's binary_logloss: 0.189566\ttraining's amex: 0.846966\tvalid_1's binary_logloss: 0.220404\tvalid_1's amex: 0.793409\n",
      "[1200]\ttraining's binary_logloss: 0.18579\ttraining's amex: 0.852862\tvalid_1's binary_logloss: 0.219863\tvalid_1's amex: 0.793531\n",
      "[1300]\ttraining's binary_logloss: 0.183285\ttraining's amex: 0.857657\tvalid_1's binary_logloss: 0.219708\tvalid_1's amex: 0.793134\n",
      "[1400]\ttraining's binary_logloss: 0.1799\ttraining's amex: 0.863052\tvalid_1's binary_logloss: 0.219249\tvalid_1's amex: 0.793715\n",
      "[1500]\ttraining's binary_logloss: 0.177572\ttraining's amex: 0.867528\tvalid_1's binary_logloss: 0.219025\tvalid_1's amex: 0.7946\n",
      "[1600]\ttraining's binary_logloss: 0.175031\ttraining's amex: 0.872257\tvalid_1's binary_logloss: 0.218861\tvalid_1's amex: 0.795043\n",
      "[1700]\ttraining's binary_logloss: 0.172017\ttraining's amex: 0.877058\tvalid_1's binary_logloss: 0.218611\tvalid_1's amex: 0.795378\n",
      "[1800]\ttraining's binary_logloss: 0.169097\ttraining's amex: 0.882255\tvalid_1's binary_logloss: 0.218468\tvalid_1's amex: 0.794967\n",
      "[1900]\ttraining's binary_logloss: 0.166233\ttraining's amex: 0.887102\tvalid_1's binary_logloss: 0.218267\tvalid_1's amex: 0.795296\n",
      "[2000]\ttraining's binary_logloss: 0.164071\ttraining's amex: 0.89147\tvalid_1's binary_logloss: 0.218093\tvalid_1's amex: 0.794995\n",
      "Our fold 3 CV score is 0.7947841987323219\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 3094 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.706724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 399024\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 3094\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[100]\ttraining's binary_logloss: 0.270423\ttraining's amex: 0.776996\tvalid_1's binary_logloss: 0.27721\tvalid_1's amex: 0.762197\n",
      "[200]\ttraining's binary_logloss: 0.247113\ttraining's amex: 0.789304\tvalid_1's binary_logloss: 0.25635\tvalid_1's amex: 0.769824\n",
      "[300]\ttraining's binary_logloss: 0.227653\ttraining's amex: 0.798823\tvalid_1's binary_logloss: 0.240129\tvalid_1's amex: 0.77512\n",
      "[400]\ttraining's binary_logloss: 0.216773\ttraining's amex: 0.807817\tvalid_1's binary_logloss: 0.232429\tvalid_1's amex: 0.779808\n",
      "[500]\ttraining's binary_logloss: 0.212061\ttraining's amex: 0.814152\tvalid_1's binary_logloss: 0.22988\tvalid_1's amex: 0.782489\n",
      "[600]\ttraining's binary_logloss: 0.20651\ttraining's amex: 0.820186\tvalid_1's binary_logloss: 0.227378\tvalid_1's amex: 0.784424\n",
      "[700]\ttraining's binary_logloss: 0.202185\ttraining's amex: 0.827013\tvalid_1's binary_logloss: 0.225777\tvalid_1's amex: 0.786475\n",
      "[800]\ttraining's binary_logloss: 0.200841\ttraining's amex: 0.830839\tvalid_1's binary_logloss: 0.22559\tvalid_1's amex: 0.787383\n",
      "[900]\ttraining's binary_logloss: 0.196166\ttraining's amex: 0.83634\tvalid_1's binary_logloss: 0.224217\tvalid_1's amex: 0.788411\n",
      "[1000]\ttraining's binary_logloss: 0.192242\ttraining's amex: 0.842588\tvalid_1's binary_logloss: 0.223156\tvalid_1's amex: 0.789994\n",
      "[1100]\ttraining's binary_logloss: 0.188997\ttraining's amex: 0.84849\tvalid_1's binary_logloss: 0.222539\tvalid_1's amex: 0.789711\n",
      "[1200]\ttraining's binary_logloss: 0.185237\ttraining's amex: 0.853979\tvalid_1's binary_logloss: 0.221967\tvalid_1's amex: 0.7904\n",
      "[1300]\ttraining's binary_logloss: 0.182766\ttraining's amex: 0.858611\tvalid_1's binary_logloss: 0.221962\tvalid_1's amex: 0.790933\n",
      "[1400]\ttraining's binary_logloss: 0.179431\ttraining's amex: 0.863619\tvalid_1's binary_logloss: 0.221462\tvalid_1's amex: 0.791583\n",
      "[1500]\ttraining's binary_logloss: 0.177056\ttraining's amex: 0.868263\tvalid_1's binary_logloss: 0.221184\tvalid_1's amex: 0.79143\n",
      "[1600]\ttraining's binary_logloss: 0.174609\ttraining's amex: 0.872832\tvalid_1's binary_logloss: 0.221062\tvalid_1's amex: 0.791544\n",
      "[1700]\ttraining's binary_logloss: 0.171549\ttraining's amex: 0.877477\tvalid_1's binary_logloss: 0.220772\tvalid_1's amex: 0.792072\n",
      "[1800]\ttraining's binary_logloss: 0.168624\ttraining's amex: 0.883139\tvalid_1's binary_logloss: 0.220573\tvalid_1's amex: 0.792227\n",
      "[1900]\ttraining's binary_logloss: 0.165748\ttraining's amex: 0.887936\tvalid_1's binary_logloss: 0.220523\tvalid_1's amex: 0.792489\n",
      "[2000]\ttraining's binary_logloss: 0.163598\ttraining's amex: 0.892059\tvalid_1's binary_logloss: 0.220447\tvalid_1's amex: 0.79228\n",
      "Our fold 4 CV score is 0.7921311091707295\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_agg, target)):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {train_agg.shape[1]} features...')\n",
    "    print('-'*50)\n",
    "    x_train, x_val = train_agg.iloc[trn_ind], train_agg.iloc[val_ind]\n",
    "    y_train, y_val = target[trn_ind], target[val_ind]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 2000,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 100,\n",
    "        verbose_eval = 100,\n",
    "        feval = lgb_amex_metric\n",
    "    )\n",
    "    # Save best model\n",
    "    joblib.dump(model, f'./dart_models/model_fold{fold}_seed{seed}.pkl')\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(x_val, raw_score=True)\n",
    "    val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)                                      \n",
    "    print(f'Our fold {fold} CV score is {val_score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d1edb68-31c3-4765-8790-eda904deb19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 832 ms, sys: 370 ms, total: 1.2 s\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_dart = TreeExperiment(\n",
    "    exp_full_path=\"../22.lgbm_dart_1020\",\n",
    "    seed=777, \n",
    "    model_path=\"dart_models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4bac513-9230-43ae-83c5-90c978c20c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lgbm_dart.feature_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76e2f4b2-41a7-417d-979e-9bb8132218d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_use_features = f.loc[f[\"average_importance\"] < 6][\"feature\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7551c362-c177-4dcd-8c5a-349a381ad9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg.drop(columns=no_use_features, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e69ae0f9-db06-4a4c-98f2-a91c1b0fa68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = train_agg.select_dtypes(\"category\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50107707-304f-4df8-8976-6aafea2bed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 2567), 16)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.shape, len(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d0c11-845f-4dd1-987d-16438bc0cfc4",
   "metadata": {},
   "source": [
    "### Final Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f8e2b44-9f33-47cc-8c27-36215cf4ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a837ddb6-6501-4543-abc7-5803eca56f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': \"binary_logloss\",\n",
    "    'boosting': 'dart',\n",
    "    'seed': seed,\n",
    "    'num_leaves': 95,\n",
    "    'learning_rate': 0.012,\n",
    "    'feature_fraction': 0.2,\n",
    "    'bagging_freq': 8,\n",
    "    'bagging_fraction': 0.55,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 15,\n",
    "    'min_data_in_leaf': 83,\n",
    "    'scale_pos_weight': 1.38,\n",
    "    'max_bins': 288,\n",
    "    'skip_drop': 0.5,\n",
    "    'drop_rate': 0.11\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc822f59-b4e2-46ab-8e86-6267669b25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a5eb6027-49c2-4b44-8396-fd2e506eb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = labels[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31f8d0c6-1ccc-4aae-8466-1602e8184cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2567 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 89121, number of negative: 255064\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.839590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 508947\n",
      "[LightGBM] [Info] Number of data points in the train set: 344185, number of used features: 2567\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051519\n",
      "[LightGBM] [Info] Start training from score -1.051519\n",
      "[500]\ttraining's binary_logloss: 0.280097\ttraining's amex: 0.782386\tvalid_1's binary_logloss: 0.286841\tvalid_1's amex: 0.763607\n",
      "[1000]\ttraining's binary_logloss: 0.23462\ttraining's amex: 0.79893\tvalid_1's binary_logloss: 0.245512\tvalid_1's amex: 0.773975\n",
      "[1500]\ttraining's binary_logloss: 0.216861\ttraining's amex: 0.812525\tvalid_1's binary_logloss: 0.232517\tvalid_1's amex: 0.78033\n",
      "[2000]\ttraining's binary_logloss: 0.206505\ttraining's amex: 0.824568\tvalid_1's binary_logloss: 0.227243\tvalid_1's amex: 0.785006\n",
      "[2500]\ttraining's binary_logloss: 0.199943\ttraining's amex: 0.835278\tvalid_1's binary_logloss: 0.225126\tvalid_1's amex: 0.787277\n",
      "[3000]\ttraining's binary_logloss: 0.192159\ttraining's amex: 0.845601\tvalid_1's binary_logloss: 0.222786\tvalid_1's amex: 0.789001\n",
      "[3500]\ttraining's binary_logloss: 0.184507\ttraining's amex: 0.857508\tvalid_1's binary_logloss: 0.221253\tvalid_1's amex: 0.791046\n",
      "[4000]\ttraining's binary_logloss: 0.17889\ttraining's amex: 0.867751\tvalid_1's binary_logloss: 0.220594\tvalid_1's amex: 0.791864\n",
      "[4500]\ttraining's binary_logloss: 0.173307\ttraining's amex: 0.877379\tvalid_1's binary_logloss: 0.219928\tvalid_1's amex: 0.792782\n",
      "[5000]\ttraining's binary_logloss: 0.167478\ttraining's amex: 0.886318\tvalid_1's binary_logloss: 0.219377\tvalid_1's amex: 0.793321\n",
      "[5500]\ttraining's binary_logloss: 0.161845\ttraining's amex: 0.896435\tvalid_1's binary_logloss: 0.219024\tvalid_1's amex: 0.793435\n",
      "[6000]\ttraining's binary_logloss: 0.157547\ttraining's amex: 0.904148\tvalid_1's binary_logloss: 0.218858\tvalid_1's amex: 0.793303\n",
      "[6500]\ttraining's binary_logloss: 0.152033\ttraining's amex: 0.912841\tvalid_1's binary_logloss: 0.21855\tvalid_1's amex: 0.794143\n",
      "[7000]\ttraining's binary_logloss: 0.147317\ttraining's amex: 0.921791\tvalid_1's binary_logloss: 0.218422\tvalid_1's amex: 0.794559\n",
      "[7500]\ttraining's binary_logloss: 0.142649\ttraining's amex: 0.930025\tvalid_1's binary_logloss: 0.218247\tvalid_1's amex: 0.794519\n",
      "[8000]\ttraining's binary_logloss: 0.138313\ttraining's amex: 0.936629\tvalid_1's binary_logloss: 0.218144\tvalid_1's amex: 0.795701\n",
      "[8500]\ttraining's binary_logloss: 0.134179\ttraining's amex: 0.943274\tvalid_1's binary_logloss: 0.218056\tvalid_1's amex: 0.795207\n",
      "[9000]\ttraining's binary_logloss: 0.130101\ttraining's amex: 0.949108\tvalid_1's binary_logloss: 0.217997\tvalid_1's amex: 0.795079\n",
      "[9500]\ttraining's binary_logloss: 0.126272\ttraining's amex: 0.954826\tvalid_1's binary_logloss: 0.217981\tvalid_1's amex: 0.795348\n",
      "Our fold 1 CV score is 0.795534657009767\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2567 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 89121, number of negative: 255064\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.717401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 508808\n",
      "[LightGBM] [Info] Number of data points in the train set: 344185, number of used features: 2567\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051519\n",
      "[LightGBM] [Info] Start training from score -1.051519\n",
      "[500]\ttraining's binary_logloss: 0.280276\ttraining's amex: 0.781552\tvalid_1's binary_logloss: 0.286516\tvalid_1's amex: 0.768552\n",
      "[1000]\ttraining's binary_logloss: 0.234818\ttraining's amex: 0.798241\tvalid_1's binary_logloss: 0.245317\tvalid_1's amex: 0.777866\n",
      "[1500]\ttraining's binary_logloss: 0.217105\ttraining's amex: 0.812421\tvalid_1's binary_logloss: 0.232067\tvalid_1's amex: 0.784535\n",
      "[2000]\ttraining's binary_logloss: 0.206727\ttraining's amex: 0.824643\tvalid_1's binary_logloss: 0.22669\tvalid_1's amex: 0.787293\n",
      "[2500]\ttraining's binary_logloss: 0.200162\ttraining's amex: 0.835436\tvalid_1's binary_logloss: 0.224592\tvalid_1's amex: 0.790216\n",
      "[3000]\ttraining's binary_logloss: 0.192435\ttraining's amex: 0.84536\tvalid_1's binary_logloss: 0.222335\tvalid_1's amex: 0.791562\n",
      "[3500]\ttraining's binary_logloss: 0.184731\ttraining's amex: 0.857159\tvalid_1's binary_logloss: 0.220753\tvalid_1's amex: 0.792471\n",
      "[4000]\ttraining's binary_logloss: 0.179132\ttraining's amex: 0.867593\tvalid_1's binary_logloss: 0.220088\tvalid_1's amex: 0.793011\n",
      "[4500]\ttraining's binary_logloss: 0.173517\ttraining's amex: 0.876835\tvalid_1's binary_logloss: 0.219497\tvalid_1's amex: 0.794511\n",
      "[5000]\ttraining's binary_logloss: 0.167678\ttraining's amex: 0.8861\tvalid_1's binary_logloss: 0.218935\tvalid_1's amex: 0.795066\n",
      "[5500]\ttraining's binary_logloss: 0.162003\ttraining's amex: 0.895957\tvalid_1's binary_logloss: 0.218551\tvalid_1's amex: 0.794719\n",
      "[6000]\ttraining's binary_logloss: 0.157681\ttraining's amex: 0.904611\tvalid_1's binary_logloss: 0.218373\tvalid_1's amex: 0.795323\n",
      "[6500]\ttraining's binary_logloss: 0.152153\ttraining's amex: 0.913044\tvalid_1's binary_logloss: 0.218055\tvalid_1's amex: 0.795687\n",
      "[7000]\ttraining's binary_logloss: 0.147469\ttraining's amex: 0.921343\tvalid_1's binary_logloss: 0.217873\tvalid_1's amex: 0.795554\n",
      "[7500]\ttraining's binary_logloss: 0.142839\ttraining's amex: 0.92939\tvalid_1's binary_logloss: 0.217687\tvalid_1's amex: 0.795969\n",
      "[8000]\ttraining's binary_logloss: 0.138503\ttraining's amex: 0.936247\tvalid_1's binary_logloss: 0.217643\tvalid_1's amex: 0.795756\n",
      "[8500]\ttraining's binary_logloss: 0.134374\ttraining's amex: 0.942786\tvalid_1's binary_logloss: 0.217564\tvalid_1's amex: 0.79545\n",
      "[9000]\ttraining's binary_logloss: 0.130267\ttraining's amex: 0.948886\tvalid_1's binary_logloss: 0.217503\tvalid_1's amex: 0.795233\n",
      "[9500]\ttraining's binary_logloss: 0.126414\ttraining's amex: 0.954511\tvalid_1's binary_logloss: 0.217489\tvalid_1's amex: 0.795015\n",
      "Our fold 2 CV score is 0.794678760533162\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 2567 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 89121, number of negative: 255064\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.838711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 508889\n",
      "[LightGBM] [Info] Number of data points in the train set: 344185, number of used features: 2567\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051519\n",
      "[LightGBM] [Info] Start training from score -1.051519\n",
      "[500]\ttraining's binary_logloss: 0.280683\ttraining's amex: 0.780995\tvalid_1's binary_logloss: 0.285221\tvalid_1's amex: 0.770319\n",
      "[1000]\ttraining's binary_logloss: 0.235287\ttraining's amex: 0.7967\tvalid_1's binary_logloss: 0.244007\tvalid_1's amex: 0.77943\n",
      "[1500]\ttraining's binary_logloss: 0.217426\ttraining's amex: 0.810612\tvalid_1's binary_logloss: 0.230703\tvalid_1's amex: 0.786284\n",
      "[2000]\ttraining's binary_logloss: 0.20704\ttraining's amex: 0.822886\tvalid_1's binary_logloss: 0.2253\tvalid_1's amex: 0.790432\n",
      "[2500]\ttraining's binary_logloss: 0.200418\ttraining's amex: 0.833644\tvalid_1's binary_logloss: 0.223145\tvalid_1's amex: 0.793221\n",
      "[3000]\ttraining's binary_logloss: 0.192692\ttraining's amex: 0.844016\tvalid_1's binary_logloss: 0.220872\tvalid_1's amex: 0.794858\n",
      "[3500]\ttraining's binary_logloss: 0.185009\ttraining's amex: 0.856164\tvalid_1's binary_logloss: 0.219381\tvalid_1's amex: 0.795542\n",
      "[4000]\ttraining's binary_logloss: 0.179408\ttraining's amex: 0.866404\tvalid_1's binary_logloss: 0.218716\tvalid_1's amex: 0.796599\n",
      "[4500]\ttraining's binary_logloss: 0.17385\ttraining's amex: 0.87643\tvalid_1's binary_logloss: 0.218186\tvalid_1's amex: 0.797475\n",
      "[5000]\ttraining's binary_logloss: 0.168027\ttraining's amex: 0.885605\tvalid_1's binary_logloss: 0.217573\tvalid_1's amex: 0.797987\n",
      "[5500]\ttraining's binary_logloss: 0.162381\ttraining's amex: 0.89573\tvalid_1's binary_logloss: 0.217195\tvalid_1's amex: 0.798193\n",
      "[6000]\ttraining's binary_logloss: 0.158063\ttraining's amex: 0.903667\tvalid_1's binary_logloss: 0.217041\tvalid_1's amex: 0.797733\n",
      "[6500]\ttraining's binary_logloss: 0.152608\ttraining's amex: 0.912716\tvalid_1's binary_logloss: 0.216772\tvalid_1's amex: 0.798305\n",
      "[7000]\ttraining's binary_logloss: 0.147897\ttraining's amex: 0.921339\tvalid_1's binary_logloss: 0.216574\tvalid_1's amex: 0.797825\n",
      "[7500]\ttraining's binary_logloss: 0.14326\ttraining's amex: 0.929566\tvalid_1's binary_logloss: 0.21641\tvalid_1's amex: 0.797964\n",
      "[8000]\ttraining's binary_logloss: 0.138907\ttraining's amex: 0.936491\tvalid_1's binary_logloss: 0.216307\tvalid_1's amex: 0.798042\n",
      "[8500]\ttraining's binary_logloss: 0.134735\ttraining's amex: 0.943117\tvalid_1's binary_logloss: 0.216177\tvalid_1's amex: 0.798012\n",
      "[9000]\ttraining's binary_logloss: 0.130615\ttraining's amex: 0.949109\tvalid_1's binary_logloss: 0.216106\tvalid_1's amex: 0.798172\n",
      "[9500]\ttraining's binary_logloss: 0.126773\ttraining's amex: 0.954896\tvalid_1's binary_logloss: 0.216075\tvalid_1's amex: 0.797863\n",
      "Our fold 3 CV score is 0.797784243691676\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_agg, target)):\n",
    "    if fold == 0:\n",
    "        continue\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {train_agg.shape[1]} features...')\n",
    "    print('-'*50)\n",
    "    x_train, x_val = train_agg.iloc[trn_ind], train_agg.iloc[val_ind]\n",
    "    y_train, y_val = target[trn_ind], target[val_ind]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 9600,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 100,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "    )\n",
    "    # Save best model\n",
    "    joblib.dump(model, f'./dart_models2/model_fold{fold}_seed{seed}.pkl')\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(x_val, raw_score=True)\n",
    "    val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)                                      \n",
    "    print(f'Our fold {fold} CV score is {val_score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c40fe-90c7-4322-a3fd-6a59932b0c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f8bead2-4b60-42ec-bbc0-48d1252bb3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dart_models2/model_fold0_seed8888.pkl']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, f'./dart_models2/model_fold{fold}_seed{seed}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfaa6d-eca8-4d0a-b876-8df1015690ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a6537-4d7a-4712-954a-7793bb121e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a258204-44db-49fc-9477-2b541992f334",
   "metadata": {},
   "source": [
    "### Pre-train Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04b6202f-fd85-45df-854a-c63d2ce5afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_noob_features(feature_imp_df, threshold):\n",
    "    noob_features = []\n",
    "    for type_ in feature_imp_df.columns[1:]:\n",
    "        noob_features.extend(\n",
    "            (\n",
    "                feature_imp_df.loc[feature_imp_df[type_] < threshold][\"base_feature\"] + \"_\" + type_\n",
    "            ).tolist()\n",
    "        )\n",
    "    print(len(noob_features), feature_imp_df.shape[0] * (feature_imp_df.shape[1] - 1))\n",
    "    return noob_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b395be1-b942-47e1-bbc2-b4e4f610680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp_percentile(summary_df, p):\n",
    "    array = pd.Series(np.stack(summary_df.drop(columns=\"base_feature\", errors=\"ignore\").values).ravel()).dropna().values\n",
    "    return np.percentile(array, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1de3a03f-4567-43df-80ff-f60d65d8504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file 5\n",
      "Shape of data: (146, 25)\n",
      "247 3504\n",
      "Threshold = 7.86, Dropping # of features 247\n",
      "Read file 6\n",
      "Shape of data: (169, 28)\n",
      "240 4563\n",
      "Threshold = 31.16, Dropping # of features 240\n",
      "Read file 7\n",
      "Shape of data: (169, 28)\n",
      "240 4563\n",
      "Threshold = 31.14, Dropping # of features 240\n",
      "Read file 8\n",
      "Shape of data: (169, 28)\n",
      "200 4563\n",
      "Threshold = 27.20, Dropping # of features 200\n",
      "Read file 9\n",
      "Shape of data: (189, 37)\n",
      "353 6804\n",
      "Threshold = 21.60, Dropping # of features 353\n"
     ]
    }
   ],
   "source": [
    "features_to_drop = set()\n",
    "for i, threshold_percentile in zip(range(5, 10), repeat(10)):\n",
    "    print(f\"Read file {i}\")\n",
    "    summary_feature_imp = read_file(f\"../{EXP_PATH}/feature_imp_summary{i}.csv\")\n",
    "    feature_imp_thr = get_feature_imp_percentile(summary_feature_imp, threshold_percentile)\n",
    "    # feature_imp_thr = 2\n",
    "    drop_feature_subset = set(select_noob_features(summary_feature_imp, feature_imp_thr))\n",
    "    features_to_drop = features_to_drop.union(drop_feature_subset)\n",
    "    print(f\"Threshold = {feature_imp_thr:.2f}, Dropping # of features {len(drop_feature_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffab9376-a758-431a-90fd-fdc7ea94d3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c1a6a1c-ee4a-4bea-8ee6-674b22adcc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 473 ms, sys: 2.87 s, total: 3.34 s\n",
      "Wall time: 5.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(458913, 3490)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = train_agg.drop(columns=list(features_to_drop), errors=\"ignore\")\n",
    "train_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f96b66cc-0a45-4b1c-a495-2e305a05b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = labels[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44ab4593-b2af-4b8c-bbb6-ce16ede60dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 535 ms, sys: 2.98 s, total: 3.51 s\n",
      "Wall time: 5.53 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = train_agg.drop(columns=get_cols(train_agg, \"a_\"), errors=\"ignore\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "775de35c-1268-47dc-8d02-678f6cb50d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 610 ms, sys: 3.61 s, total: 4.22 s\n",
      "Wall time: 6.58 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = train_agg.drop(columns=get_cols(train_agg, \"third_last\"), errors=\"ignore\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80925934-1a9e-4dda-b8dc-4557eb8c6d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 3488), (458913,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0546bfc-d4da-4d91-9941-7b945eb19bd2",
   "metadata": {},
   "source": [
    "### Previous Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34c14df2-0c6b-44d3-b220-d59a454ddd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2526 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.460335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400600\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 2509\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.293739\ttraining's amex: 0.77623\tvalid_1's binary_logloss: 0.297458\tvalid_1's amex: 0.764339\n",
      "[1000]\ttraining's binary_logloss: 0.241355\ttraining's amex: 0.793123\tvalid_1's binary_logloss: 0.248443\tvalid_1's amex: 0.77557\n",
      "[1500]\ttraining's binary_logloss: 0.220264\ttraining's amex: 0.807932\tvalid_1's binary_logloss: 0.23157\tvalid_1's amex: 0.783222\n",
      "[2000]\ttraining's binary_logloss: 0.209213\ttraining's amex: 0.819986\tvalid_1's binary_logloss: 0.225067\tvalid_1's amex: 0.787665\n",
      "[2500]\ttraining's binary_logloss: 0.202477\ttraining's amex: 0.828883\tvalid_1's binary_logloss: 0.22225\tvalid_1's amex: 0.790662\n",
      "[3000]\ttraining's binary_logloss: 0.195258\ttraining's amex: 0.839041\tvalid_1's binary_logloss: 0.219866\tvalid_1's amex: 0.794334\n",
      "[3500]\ttraining's binary_logloss: 0.189934\ttraining's amex: 0.848242\tvalid_1's binary_logloss: 0.218758\tvalid_1's amex: 0.795788\n",
      "[4000]\ttraining's binary_logloss: 0.183741\ttraining's amex: 0.857479\tvalid_1's binary_logloss: 0.217546\tvalid_1's amex: 0.79628\n",
      "[4500]\ttraining's binary_logloss: 0.178385\ttraining's amex: 0.865997\tvalid_1's binary_logloss: 0.216848\tvalid_1's amex: 0.797163\n",
      "[5000]\ttraining's binary_logloss: 0.173885\ttraining's amex: 0.874238\tvalid_1's binary_logloss: 0.216415\tvalid_1's amex: 0.797236\n",
      "[5500]\ttraining's binary_logloss: 0.168601\ttraining's amex: 0.88315\tvalid_1's binary_logloss: 0.215877\tvalid_1's amex: 0.798241\n",
      "[6000]\ttraining's binary_logloss: 0.163763\ttraining's amex: 0.891433\tvalid_1's binary_logloss: 0.215533\tvalid_1's amex: 0.799149\n",
      "[6500]\ttraining's binary_logloss: 0.159289\ttraining's amex: 0.899193\tvalid_1's binary_logloss: 0.215263\tvalid_1's amex: 0.799023\n",
      "[7000]\ttraining's binary_logloss: 0.154398\ttraining's amex: 0.907199\tvalid_1's binary_logloss: 0.215056\tvalid_1's amex: 0.799829\n",
      "[7500]\ttraining's binary_logloss: 0.149994\ttraining's amex: 0.91538\tvalid_1's binary_logloss: 0.214866\tvalid_1's amex: 0.799845\n",
      "[8000]\ttraining's binary_logloss: 0.145967\ttraining's amex: 0.922501\tvalid_1's binary_logloss: 0.214671\tvalid_1's amex: 0.799973\n",
      "[8500]\ttraining's binary_logloss: 0.142047\ttraining's amex: 0.928695\tvalid_1's binary_logloss: 0.214573\tvalid_1's amex: 0.799952\n",
      "[9000]\ttraining's binary_logloss: 0.137927\ttraining's amex: 0.935711\tvalid_1's binary_logloss: 0.214479\tvalid_1's amex: 0.800028\n",
      "[9500]\ttraining's binary_logloss: 0.134711\ttraining's amex: 0.940824\tvalid_1's binary_logloss: 0.214483\tvalid_1's amex: 0.800154\n",
      "[10000]\ttraining's binary_logloss: 0.131047\ttraining's amex: 0.946053\tvalid_1's binary_logloss: 0.214377\tvalid_1's amex: 0.8\n",
      "Our fold 0 CV score is 0.7997615350117044\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2526 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.585243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400342\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 2506\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.293756\ttraining's amex: 0.776125\tvalid_1's binary_logloss: 0.297596\tvalid_1's amex: 0.766502\n",
      "[1000]\ttraining's binary_logloss: 0.241318\ttraining's amex: 0.791707\tvalid_1's binary_logloss: 0.248412\tvalid_1's amex: 0.777635\n",
      "[1500]\ttraining's binary_logloss: 0.220293\ttraining's amex: 0.806783\tvalid_1's binary_logloss: 0.23159\tvalid_1's amex: 0.785658\n",
      "[2000]\ttraining's binary_logloss: 0.209188\ttraining's amex: 0.819155\tvalid_1's binary_logloss: 0.225029\tvalid_1's amex: 0.790438\n",
      "[2500]\ttraining's binary_logloss: 0.202465\ttraining's amex: 0.82834\tvalid_1's binary_logloss: 0.222306\tvalid_1's amex: 0.793534\n",
      "[3000]\ttraining's binary_logloss: 0.195105\ttraining's amex: 0.838567\tvalid_1's binary_logloss: 0.219881\tvalid_1's amex: 0.795687\n",
      "[3500]\ttraining's binary_logloss: 0.189811\ttraining's amex: 0.847495\tvalid_1's binary_logloss: 0.218799\tvalid_1's amex: 0.796813\n",
      "[4000]\ttraining's binary_logloss: 0.183639\ttraining's amex: 0.856799\tvalid_1's binary_logloss: 0.217656\tvalid_1's amex: 0.797886\n",
      "[4500]\ttraining's binary_logloss: 0.178291\ttraining's amex: 0.866199\tvalid_1's binary_logloss: 0.216941\tvalid_1's amex: 0.798954\n",
      "[5000]\ttraining's binary_logloss: 0.173703\ttraining's amex: 0.874248\tvalid_1's binary_logloss: 0.216574\tvalid_1's amex: 0.799825\n",
      "[5500]\ttraining's binary_logloss: 0.168412\ttraining's amex: 0.882941\tvalid_1's binary_logloss: 0.216097\tvalid_1's amex: 0.799934\n",
      "[6000]\ttraining's binary_logloss: 0.163582\ttraining's amex: 0.891365\tvalid_1's binary_logloss: 0.21579\tvalid_1's amex: 0.800429\n",
      "[6500]\ttraining's binary_logloss: 0.159115\ttraining's amex: 0.899473\tvalid_1's binary_logloss: 0.215489\tvalid_1's amex: 0.800522\n",
      "[7000]\ttraining's binary_logloss: 0.154232\ttraining's amex: 0.907994\tvalid_1's binary_logloss: 0.215193\tvalid_1's amex: 0.800162\n",
      "[7500]\ttraining's binary_logloss: 0.149835\ttraining's amex: 0.915847\tvalid_1's binary_logloss: 0.215009\tvalid_1's amex: 0.800053\n",
      "[8000]\ttraining's binary_logloss: 0.145852\ttraining's amex: 0.922784\tvalid_1's binary_logloss: 0.21494\tvalid_1's amex: 0.800288\n",
      "[8500]\ttraining's binary_logloss: 0.141909\ttraining's amex: 0.928694\tvalid_1's binary_logloss: 0.214833\tvalid_1's amex: 0.800124\n",
      "[9000]\ttraining's binary_logloss: 0.137804\ttraining's amex: 0.935533\tvalid_1's binary_logloss: 0.214779\tvalid_1's amex: 0.801229\n",
      "[9500]\ttraining's binary_logloss: 0.13455\ttraining's amex: 0.940749\tvalid_1's binary_logloss: 0.214709\tvalid_1's amex: 0.80081\n",
      "[10000]\ttraining's binary_logloss: 0.13088\ttraining's amex: 0.946198\tvalid_1's binary_logloss: 0.214632\tvalid_1's amex: 0.800788\n",
      "Our fold 1 CV score is 0.8005498134981648\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2526 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.539496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400563\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 2510\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.2934\ttraining's amex: 0.777464\tvalid_1's binary_logloss: 0.299009\tvalid_1's amex: 0.763697\n",
      "[1000]\ttraining's binary_logloss: 0.240737\ttraining's amex: 0.79377\tvalid_1's binary_logloss: 0.250521\tvalid_1's amex: 0.772952\n",
      "[1500]\ttraining's binary_logloss: 0.219541\ttraining's amex: 0.809151\tvalid_1's binary_logloss: 0.23419\tvalid_1's amex: 0.780834\n",
      "[2000]\ttraining's binary_logloss: 0.208367\ttraining's amex: 0.820526\tvalid_1's binary_logloss: 0.228096\tvalid_1's amex: 0.785504\n",
      "[2500]\ttraining's binary_logloss: 0.201656\ttraining's amex: 0.829423\tvalid_1's binary_logloss: 0.225473\tvalid_1's amex: 0.787103\n",
      "[3000]\ttraining's binary_logloss: 0.194319\ttraining's amex: 0.83979\tvalid_1's binary_logloss: 0.22326\tvalid_1's amex: 0.788154\n",
      "[3500]\ttraining's binary_logloss: 0.188974\ttraining's amex: 0.849105\tvalid_1's binary_logloss: 0.222216\tvalid_1's amex: 0.789722\n",
      "[4000]\ttraining's binary_logloss: 0.18287\ttraining's amex: 0.858632\tvalid_1's binary_logloss: 0.221241\tvalid_1's amex: 0.790891\n",
      "[4500]\ttraining's binary_logloss: 0.177502\ttraining's amex: 0.867981\tvalid_1's binary_logloss: 0.220525\tvalid_1's amex: 0.792217\n",
      "[5000]\ttraining's binary_logloss: 0.173015\ttraining's amex: 0.875537\tvalid_1's binary_logloss: 0.220098\tvalid_1's amex: 0.793313\n",
      "[5500]\ttraining's binary_logloss: 0.167689\ttraining's amex: 0.884364\tvalid_1's binary_logloss: 0.2196\tvalid_1's amex: 0.793538\n",
      "[6000]\ttraining's binary_logloss: 0.162864\ttraining's amex: 0.892907\tvalid_1's binary_logloss: 0.219269\tvalid_1's amex: 0.793731\n",
      "[6500]\ttraining's binary_logloss: 0.158464\ttraining's amex: 0.900754\tvalid_1's binary_logloss: 0.219082\tvalid_1's amex: 0.793616\n",
      "[7000]\ttraining's binary_logloss: 0.153523\ttraining's amex: 0.908785\tvalid_1's binary_logloss: 0.218853\tvalid_1's amex: 0.793663\n",
      "[7500]\ttraining's binary_logloss: 0.14917\ttraining's amex: 0.916416\tvalid_1's binary_logloss: 0.218699\tvalid_1's amex: 0.793642\n",
      "[8000]\ttraining's binary_logloss: 0.145185\ttraining's amex: 0.923082\tvalid_1's binary_logloss: 0.218528\tvalid_1's amex: 0.793693\n",
      "[8500]\ttraining's binary_logloss: 0.141272\ttraining's amex: 0.928904\tvalid_1's binary_logloss: 0.218432\tvalid_1's amex: 0.794402\n",
      "[9000]\ttraining's binary_logloss: 0.137131\ttraining's amex: 0.935762\tvalid_1's binary_logloss: 0.218286\tvalid_1's amex: 0.793899\n",
      "[9500]\ttraining's binary_logloss: 0.133937\ttraining's amex: 0.940873\tvalid_1's binary_logloss: 0.218239\tvalid_1's amex: 0.794313\n",
      "[10000]\ttraining's binary_logloss: 0.130279\ttraining's amex: 0.946516\tvalid_1's binary_logloss: 0.218209\tvalid_1's amex: 0.79444\n",
      "Our fold 2 CV score is 0.7942011802274418\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 2526 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.482556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400618\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 2509\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[500]\ttraining's binary_logloss: 0.293553\ttraining's amex: 0.776243\tvalid_1's binary_logloss: 0.298149\tvalid_1's amex: 0.766738\n",
      "[1000]\ttraining's binary_logloss: 0.241096\ttraining's amex: 0.792319\tvalid_1's binary_logloss: 0.249578\tvalid_1's amex: 0.778467\n",
      "[1500]\ttraining's binary_logloss: 0.219984\ttraining's amex: 0.80714\tvalid_1's binary_logloss: 0.232935\tvalid_1's amex: 0.785721\n",
      "[2000]\ttraining's binary_logloss: 0.208953\ttraining's amex: 0.818653\tvalid_1's binary_logloss: 0.226637\tvalid_1's amex: 0.790677\n",
      "[2500]\ttraining's binary_logloss: 0.20229\ttraining's amex: 0.828582\tvalid_1's binary_logloss: 0.224073\tvalid_1's amex: 0.792805\n",
      "[3000]\ttraining's binary_logloss: 0.194967\ttraining's amex: 0.83888\tvalid_1's binary_logloss: 0.22168\tvalid_1's amex: 0.794966\n",
      "[3500]\ttraining's binary_logloss: 0.189613\ttraining's amex: 0.847784\tvalid_1's binary_logloss: 0.220519\tvalid_1's amex: 0.794682\n",
      "[4000]\ttraining's binary_logloss: 0.183494\ttraining's amex: 0.857172\tvalid_1's binary_logloss: 0.21945\tvalid_1's amex: 0.796341\n",
      "[4500]\ttraining's binary_logloss: 0.178115\ttraining's amex: 0.866549\tvalid_1's binary_logloss: 0.218696\tvalid_1's amex: 0.797156\n",
      "[5000]\ttraining's binary_logloss: 0.173596\ttraining's amex: 0.874775\tvalid_1's binary_logloss: 0.218295\tvalid_1's amex: 0.797214\n",
      "[5500]\ttraining's binary_logloss: 0.168307\ttraining's amex: 0.883078\tvalid_1's binary_logloss: 0.217746\tvalid_1's amex: 0.797808\n",
      "[6000]\ttraining's binary_logloss: 0.163444\ttraining's amex: 0.891366\tvalid_1's binary_logloss: 0.217307\tvalid_1's amex: 0.79843\n",
      "[6500]\ttraining's binary_logloss: 0.159028\ttraining's amex: 0.899889\tvalid_1's binary_logloss: 0.216962\tvalid_1's amex: 0.798764\n",
      "[7000]\ttraining's binary_logloss: 0.154103\ttraining's amex: 0.907801\tvalid_1's binary_logloss: 0.216695\tvalid_1's amex: 0.798384\n",
      "[7500]\ttraining's binary_logloss: 0.149774\ttraining's amex: 0.915607\tvalid_1's binary_logloss: 0.216543\tvalid_1's amex: 0.798903\n",
      "[8000]\ttraining's binary_logloss: 0.14579\ttraining's amex: 0.923022\tvalid_1's binary_logloss: 0.216401\tvalid_1's amex: 0.799667\n",
      "[8500]\ttraining's binary_logloss: 0.141806\ttraining's amex: 0.929011\tvalid_1's binary_logloss: 0.216232\tvalid_1's amex: 0.800778\n",
      "[9000]\ttraining's binary_logloss: 0.137736\ttraining's amex: 0.935175\tvalid_1's binary_logloss: 0.216107\tvalid_1's amex: 0.800546\n",
      "[9500]\ttraining's binary_logloss: 0.134507\ttraining's amex: 0.94053\tvalid_1's binary_logloss: 0.216044\tvalid_1's amex: 0.800311\n",
      "[10000]\ttraining's binary_logloss: 0.130829\ttraining's amex: 0.946138\tvalid_1's binary_logloss: 0.216035\tvalid_1's amex: 0.799772\n",
      "Our fold 3 CV score is 0.7995822263157332\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 2526 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.542928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400384\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 2509\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[500]\ttraining's binary_logloss: 0.293756\ttraining's amex: 0.775196\tvalid_1's binary_logloss: 0.29774\tvalid_1's amex: 0.769557\n",
      "[1000]\ttraining's binary_logloss: 0.2414\ttraining's amex: 0.791567\tvalid_1's binary_logloss: 0.24878\tvalid_1's amex: 0.779852\n",
      "[1500]\ttraining's binary_logloss: 0.220404\ttraining's amex: 0.807091\tvalid_1's binary_logloss: 0.23185\tvalid_1's amex: 0.787158\n",
      "[2000]\ttraining's binary_logloss: 0.209308\ttraining's amex: 0.819601\tvalid_1's binary_logloss: 0.225372\tvalid_1's amex: 0.79051\n",
      "[2500]\ttraining's binary_logloss: 0.202646\ttraining's amex: 0.828742\tvalid_1's binary_logloss: 0.22268\tvalid_1's amex: 0.793518\n",
      "[3000]\ttraining's binary_logloss: 0.195358\ttraining's amex: 0.838544\tvalid_1's binary_logloss: 0.220276\tvalid_1's amex: 0.795752\n",
      "[3500]\ttraining's binary_logloss: 0.190005\ttraining's amex: 0.847671\tvalid_1's binary_logloss: 0.219178\tvalid_1's amex: 0.796726\n",
      "[4000]\ttraining's binary_logloss: 0.183889\ttraining's amex: 0.856845\tvalid_1's binary_logloss: 0.218024\tvalid_1's amex: 0.797893\n",
      "[4500]\ttraining's binary_logloss: 0.178538\ttraining's amex: 0.865734\tvalid_1's binary_logloss: 0.2173\tvalid_1's amex: 0.798108\n",
      "[5000]\ttraining's binary_logloss: 0.174009\ttraining's amex: 0.873507\tvalid_1's binary_logloss: 0.216938\tvalid_1's amex: 0.798534\n",
      "[5500]\ttraining's binary_logloss: 0.168677\ttraining's amex: 0.882287\tvalid_1's binary_logloss: 0.216381\tvalid_1's amex: 0.799542\n",
      "[6000]\ttraining's binary_logloss: 0.163879\ttraining's amex: 0.890441\tvalid_1's binary_logloss: 0.216065\tvalid_1's amex: 0.799721\n",
      "[6500]\ttraining's binary_logloss: 0.159399\ttraining's amex: 0.898792\tvalid_1's binary_logloss: 0.215842\tvalid_1's amex: 0.800004\n",
      "[7000]\ttraining's binary_logloss: 0.154484\ttraining's amex: 0.906792\tvalid_1's binary_logloss: 0.215482\tvalid_1's amex: 0.799811\n",
      "[7500]\ttraining's binary_logloss: 0.150163\ttraining's amex: 0.914507\tvalid_1's binary_logloss: 0.215412\tvalid_1's amex: 0.800058\n",
      "[8000]\ttraining's binary_logloss: 0.146139\ttraining's amex: 0.921911\tvalid_1's binary_logloss: 0.215259\tvalid_1's amex: 0.799635\n",
      "[8500]\ttraining's binary_logloss: 0.14215\ttraining's amex: 0.928279\tvalid_1's binary_logloss: 0.215078\tvalid_1's amex: 0.799774\n",
      "[9000]\ttraining's binary_logloss: 0.138044\ttraining's amex: 0.935161\tvalid_1's binary_logloss: 0.21493\tvalid_1's amex: 0.800178\n",
      "[9500]\ttraining's binary_logloss: 0.134839\ttraining's amex: 0.940498\tvalid_1's binary_logloss: 0.214882\tvalid_1's amex: 0.799267\n",
      "[10000]\ttraining's binary_logloss: 0.131195\ttraining's amex: 0.945714\tvalid_1's binary_logloss: 0.214838\tvalid_1's amex: 0.799665\n",
      "Our fold 4 CV score is 0.7994543082699334\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_agg, target)):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {train_agg.shape[1]} features...')\n",
    "    print('-'*50)\n",
    "    x_train, x_val = train_agg.iloc[trn_ind], train_agg.iloc[val_ind]\n",
    "    y_train, y_val = target[trn_ind], target[val_ind]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features.tolist())\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features.tolist())\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 10000,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 300,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "    )\n",
    "    # Save best model\n",
    "    joblib.dump(model, f'{EXP_PATH}/lgbm_dart_923_full_fix/models/model_fold{fold}_seed{seed}.pkl')\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(x_val, raw_score=True)\n",
    "    # # Add to out of folds array\n",
    "    # oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "    # test_pred = model.predict(test[features])\n",
    "    # test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)                                      \n",
    "    print(f'Our fold {fold} CV score is {val_score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f0e02-7b2a-4b03-9baf-760ffcb52c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 3548 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.835258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 575879\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3546\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.313021\ttraining's amex: 0.775501\tvalid_1's binary_logloss: 0.31639\tvalid_1's amex: 0.761438\n",
      "[1000]\ttraining's binary_logloss: 0.251784\ttraining's amex: 0.790594\tvalid_1's binary_logloss: 0.25824\tvalid_1's amex: 0.773174\n",
      "[1500]\ttraining's binary_logloss: 0.2254\ttraining's amex: 0.804345\tvalid_1's binary_logloss: 0.235631\tvalid_1's amex: 0.782639\n",
      "[2000]\ttraining's binary_logloss: 0.212435\ttraining's amex: 0.817408\tvalid_1's binary_logloss: 0.22699\tvalid_1's amex: 0.787058\n",
      "[2500]\ttraining's binary_logloss: 0.205153\ttraining's amex: 0.826079\tvalid_1's binary_logloss: 0.223553\tvalid_1's amex: 0.789507\n",
      "[3000]\ttraining's binary_logloss: 0.197555\ttraining's amex: 0.835499\tvalid_1's binary_logloss: 0.220608\tvalid_1's amex: 0.792017\n",
      "[3500]\ttraining's binary_logloss: 0.192176\ttraining's amex: 0.844501\tvalid_1's binary_logloss: 0.219394\tvalid_1's amex: 0.793728\n",
      "[4000]\ttraining's binary_logloss: 0.18597\ttraining's amex: 0.853633\tvalid_1's binary_logloss: 0.217969\tvalid_1's amex: 0.794639\n",
      "[4500]\ttraining's binary_logloss: 0.180644\ttraining's amex: 0.862477\tvalid_1's binary_logloss: 0.217097\tvalid_1's amex: 0.795243\n",
      "[5000]\ttraining's binary_logloss: 0.17613\ttraining's amex: 0.870429\tvalid_1's binary_logloss: 0.216618\tvalid_1's amex: 0.796442\n",
      "[5500]\ttraining's binary_logloss: 0.170869\ttraining's amex: 0.878835\tvalid_1's binary_logloss: 0.215955\tvalid_1's amex: 0.796797\n",
      "[6000]\ttraining's binary_logloss: 0.166086\ttraining's amex: 0.887218\tvalid_1's binary_logloss: 0.215592\tvalid_1's amex: 0.797402\n",
      "[6500]\ttraining's binary_logloss: 0.161657\ttraining's amex: 0.895083\tvalid_1's binary_logloss: 0.21522\tvalid_1's amex: 0.798481\n",
      "[7000]\ttraining's binary_logloss: 0.156803\ttraining's amex: 0.903168\tvalid_1's binary_logloss: 0.214871\tvalid_1's amex: 0.798131\n",
      "[7500]\ttraining's binary_logloss: 0.152457\ttraining's amex: 0.911002\tvalid_1's binary_logloss: 0.214654\tvalid_1's amex: 0.798376\n",
      "[8000]\ttraining's binary_logloss: 0.148482\ttraining's amex: 0.917986\tvalid_1's binary_logloss: 0.214445\tvalid_1's amex: 0.798259\n",
      "[8500]\ttraining's binary_logloss: 0.144617\ttraining's amex: 0.924383\tvalid_1's binary_logloss: 0.214371\tvalid_1's amex: 0.799169\n",
      "[9000]\ttraining's binary_logloss: 0.140555\ttraining's amex: 0.931259\tvalid_1's binary_logloss: 0.214164\tvalid_1's amex: 0.799352\n",
      "[9500]\ttraining's binary_logloss: 0.13735\ttraining's amex: 0.93666\tvalid_1's binary_logloss: 0.214034\tvalid_1's amex: 0.800032\n",
      "[10000]\ttraining's binary_logloss: 0.13368\ttraining's amex: 0.942021\tvalid_1's binary_logloss: 0.213891\tvalid_1's amex: 0.800348\n",
      "[10500]\ttraining's binary_logloss: 0.130065\ttraining's amex: 0.947579\tvalid_1's binary_logloss: 0.213832\tvalid_1's amex: 0.799833\n",
      "[11000]\ttraining's binary_logloss: 0.126969\ttraining's amex: 0.952195\tvalid_1's binary_logloss: 0.21377\tvalid_1's amex: 0.800031\n",
      "Our fold 0 CV score is 0.7997925952677335\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 3548 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.811881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 575468\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3545\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.312994\ttraining's amex: 0.774648\tvalid_1's binary_logloss: 0.316489\tvalid_1's amex: 0.765435\n",
      "[1000]\ttraining's binary_logloss: 0.251851\ttraining's amex: 0.789109\tvalid_1's binary_logloss: 0.258415\tvalid_1's amex: 0.774545\n",
      "[1500]\ttraining's binary_logloss: 0.225385\ttraining's amex: 0.804492\tvalid_1's binary_logloss: 0.235823\tvalid_1's amex: 0.783133\n",
      "[2000]\ttraining's binary_logloss: 0.212346\ttraining's amex: 0.816419\tvalid_1's binary_logloss: 0.227092\tvalid_1's amex: 0.789711\n",
      "[2500]\ttraining's binary_logloss: 0.20512\ttraining's amex: 0.825327\tvalid_1's binary_logloss: 0.223668\tvalid_1's amex: 0.791289\n",
      "[3000]\ttraining's binary_logloss: 0.19749\ttraining's amex: 0.835386\tvalid_1's binary_logloss: 0.220681\tvalid_1's amex: 0.793678\n",
      "[3500]\ttraining's binary_logloss: 0.192088\ttraining's amex: 0.844395\tvalid_1's binary_logloss: 0.219281\tvalid_1's amex: 0.794918\n",
      "[4000]\ttraining's binary_logloss: 0.18589\ttraining's amex: 0.853963\tvalid_1's binary_logloss: 0.217985\tvalid_1's amex: 0.79597\n",
      "[4500]\ttraining's binary_logloss: 0.18055\ttraining's amex: 0.86299\tvalid_1's binary_logloss: 0.217174\tvalid_1's amex: 0.795835\n",
      "[5000]\ttraining's binary_logloss: 0.176006\ttraining's amex: 0.871033\tvalid_1's binary_logloss: 0.216697\tvalid_1's amex: 0.797451\n",
      "[5500]\ttraining's binary_logloss: 0.17072\ttraining's amex: 0.879229\tvalid_1's binary_logloss: 0.216149\tvalid_1's amex: 0.797657\n",
      "[6000]\ttraining's binary_logloss: 0.165965\ttraining's amex: 0.887607\tvalid_1's binary_logloss: 0.215758\tvalid_1's amex: 0.797847\n",
      "[6500]\ttraining's binary_logloss: 0.161518\ttraining's amex: 0.894931\tvalid_1's binary_logloss: 0.215419\tvalid_1's amex: 0.798078\n",
      "[7000]\ttraining's binary_logloss: 0.15672\ttraining's amex: 0.903386\tvalid_1's binary_logloss: 0.215172\tvalid_1's amex: 0.797868\n",
      "[7500]\ttraining's binary_logloss: 0.15237\ttraining's amex: 0.910903\tvalid_1's binary_logloss: 0.215003\tvalid_1's amex: 0.797983\n",
      "[8000]\ttraining's binary_logloss: 0.148431\ttraining's amex: 0.917875\tvalid_1's binary_logloss: 0.214866\tvalid_1's amex: 0.798309\n",
      "[8500]\ttraining's binary_logloss: 0.144513\ttraining's amex: 0.924447\tvalid_1's binary_logloss: 0.214724\tvalid_1's amex: 0.798095\n",
      "[9000]\ttraining's binary_logloss: 0.140437\ttraining's amex: 0.931377\tvalid_1's binary_logloss: 0.214602\tvalid_1's amex: 0.797808\n",
      "[9500]\ttraining's binary_logloss: 0.137211\ttraining's amex: 0.93667\tvalid_1's binary_logloss: 0.214456\tvalid_1's amex: 0.798192\n",
      "[10000]\ttraining's binary_logloss: 0.133548\ttraining's amex: 0.942151\tvalid_1's binary_logloss: 0.214334\tvalid_1's amex: 0.798545\n",
      "[10500]\ttraining's binary_logloss: 0.129928\ttraining's amex: 0.947476\tvalid_1's binary_logloss: 0.214328\tvalid_1's amex: 0.798388\n",
      "[11000]\ttraining's binary_logloss: 0.126854\ttraining's amex: 0.95227\tvalid_1's binary_logloss: 0.214316\tvalid_1's amex: 0.798585\n",
      "Our fold 1 CV score is 0.7983458970925195\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 3548 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.764199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 575665\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 3546\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.312507\ttraining's amex: 0.776019\tvalid_1's binary_logloss: 0.31759\tvalid_1's amex: 0.761876\n",
      "[1000]\ttraining's binary_logloss: 0.251214\ttraining's amex: 0.791685\tvalid_1's binary_logloss: 0.260178\tvalid_1's amex: 0.771503\n",
      "[1500]\ttraining's binary_logloss: 0.224674\ttraining's amex: 0.80592\tvalid_1's binary_logloss: 0.238128\tvalid_1's amex: 0.778754\n",
      "[2000]\ttraining's binary_logloss: 0.211673\ttraining's amex: 0.817961\tvalid_1's binary_logloss: 0.229886\tvalid_1's amex: 0.782862\n",
      "[2500]\ttraining's binary_logloss: 0.204394\ttraining's amex: 0.826383\tvalid_1's binary_logloss: 0.226584\tvalid_1's amex: 0.785123\n",
      "[3000]\ttraining's binary_logloss: 0.196759\ttraining's amex: 0.83609\tvalid_1's binary_logloss: 0.223843\tvalid_1's amex: 0.787962\n",
      "[3500]\ttraining's binary_logloss: 0.191303\ttraining's amex: 0.845778\tvalid_1's binary_logloss: 0.222628\tvalid_1's amex: 0.790253\n",
      "[4000]\ttraining's binary_logloss: 0.185146\ttraining's amex: 0.854867\tvalid_1's binary_logloss: 0.221342\tvalid_1's amex: 0.791395\n",
      "[4500]\ttraining's binary_logloss: 0.179744\ttraining's amex: 0.863869\tvalid_1's binary_logloss: 0.220497\tvalid_1's amex: 0.791835\n",
      "[5000]\ttraining's binary_logloss: 0.175277\ttraining's amex: 0.871671\tvalid_1's binary_logloss: 0.220097\tvalid_1's amex: 0.792303\n",
      "[5500]\ttraining's binary_logloss: 0.170011\ttraining's amex: 0.880271\tvalid_1's binary_logloss: 0.219532\tvalid_1's amex: 0.793177\n",
      "[6000]\ttraining's binary_logloss: 0.165214\ttraining's amex: 0.888901\tvalid_1's binary_logloss: 0.219149\tvalid_1's amex: 0.793286\n",
      "[6500]\ttraining's binary_logloss: 0.160859\ttraining's amex: 0.896468\tvalid_1's binary_logloss: 0.218857\tvalid_1's amex: 0.793361\n",
      "[7000]\ttraining's binary_logloss: 0.155972\ttraining's amex: 0.904913\tvalid_1's binary_logloss: 0.218556\tvalid_1's amex: 0.79362\n",
      "[7500]\ttraining's binary_logloss: 0.15166\ttraining's amex: 0.912291\tvalid_1's binary_logloss: 0.218444\tvalid_1's amex: 0.793666\n",
      "[8000]\ttraining's binary_logloss: 0.147724\ttraining's amex: 0.919211\tvalid_1's binary_logloss: 0.218313\tvalid_1's amex: 0.793997\n",
      "[8500]\ttraining's binary_logloss: 0.143838\ttraining's amex: 0.925593\tvalid_1's binary_logloss: 0.218194\tvalid_1's amex: 0.794582\n",
      "[9000]\ttraining's binary_logloss: 0.139749\ttraining's amex: 0.932115\tvalid_1's binary_logloss: 0.21805\tvalid_1's amex: 0.794591\n",
      "[9500]\ttraining's binary_logloss: 0.136533\ttraining's amex: 0.937502\tvalid_1's binary_logloss: 0.217956\tvalid_1's amex: 0.794385\n",
      "[10000]\ttraining's binary_logloss: 0.13292\ttraining's amex: 0.942969\tvalid_1's binary_logloss: 0.217909\tvalid_1's amex: 0.79469\n",
      "[10500]\ttraining's binary_logloss: 0.129291\ttraining's amex: 0.948297\tvalid_1's binary_logloss: 0.217915\tvalid_1's amex: 0.794511\n",
      "[11000]\ttraining's binary_logloss: 0.126225\ttraining's amex: 0.952977\tvalid_1's binary_logloss: 0.217871\tvalid_1's amex: 0.794095\n",
      "Our fold 2 CV score is 0.7938561447557022\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 3548 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.871387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 575850\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 3546\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[500]\ttraining's binary_logloss: 0.312807\ttraining's amex: 0.774629\tvalid_1's binary_logloss: 0.316897\tvalid_1's amex: 0.766479\n",
      "[1000]\ttraining's binary_logloss: 0.251567\ttraining's amex: 0.789394\tvalid_1's binary_logloss: 0.259138\tvalid_1's amex: 0.77844\n",
      "[1500]\ttraining's binary_logloss: 0.225239\ttraining's amex: 0.80361\tvalid_1's binary_logloss: 0.236953\tvalid_1's amex: 0.784834\n",
      "[2000]\ttraining's binary_logloss: 0.212211\ttraining's amex: 0.815751\tvalid_1's binary_logloss: 0.228526\tvalid_1's amex: 0.789751\n",
      "[2500]\ttraining's binary_logloss: 0.204968\ttraining's amex: 0.824969\tvalid_1's binary_logloss: 0.225154\tvalid_1's amex: 0.791676\n",
      "[3000]\ttraining's binary_logloss: 0.197297\ttraining's amex: 0.834846\tvalid_1's binary_logloss: 0.222264\tvalid_1's amex: 0.793838\n",
      "[3500]\ttraining's binary_logloss: 0.19189\ttraining's amex: 0.843572\tvalid_1's binary_logloss: 0.220904\tvalid_1's amex: 0.796423\n",
      "[4000]\ttraining's binary_logloss: 0.185685\ttraining's amex: 0.853385\tvalid_1's binary_logloss: 0.219501\tvalid_1's amex: 0.797304\n",
      "[4500]\ttraining's binary_logloss: 0.18033\ttraining's amex: 0.862715\tvalid_1's binary_logloss: 0.218601\tvalid_1's amex: 0.79852\n",
      "[5000]\ttraining's binary_logloss: 0.175829\ttraining's amex: 0.870458\tvalid_1's binary_logloss: 0.218164\tvalid_1's amex: 0.799149\n",
      "[5500]\ttraining's binary_logloss: 0.170597\ttraining's amex: 0.87957\tvalid_1's binary_logloss: 0.217628\tvalid_1's amex: 0.798106\n",
      "[6000]\ttraining's binary_logloss: 0.165768\ttraining's amex: 0.887973\tvalid_1's binary_logloss: 0.217229\tvalid_1's amex: 0.798315\n",
      "[6500]\ttraining's binary_logloss: 0.161412\ttraining's amex: 0.895334\tvalid_1's binary_logloss: 0.21692\tvalid_1's amex: 0.798238\n",
      "[7000]\ttraining's binary_logloss: 0.156562\ttraining's amex: 0.903144\tvalid_1's binary_logloss: 0.216586\tvalid_1's amex: 0.798573\n",
      "[7500]\ttraining's binary_logloss: 0.152244\ttraining's amex: 0.911153\tvalid_1's binary_logloss: 0.216409\tvalid_1's amex: 0.798935\n",
      "[8000]\ttraining's binary_logloss: 0.148279\ttraining's amex: 0.917875\tvalid_1's binary_logloss: 0.216181\tvalid_1's amex: 0.798088\n",
      "[8500]\ttraining's binary_logloss: 0.14435\ttraining's amex: 0.924257\tvalid_1's binary_logloss: 0.216058\tvalid_1's amex: 0.798576\n",
      "[9000]\ttraining's binary_logloss: 0.140303\ttraining's amex: 0.931004\tvalid_1's binary_logloss: 0.216011\tvalid_1's amex: 0.798636\n",
      "[9500]\ttraining's binary_logloss: 0.137103\ttraining's amex: 0.936206\tvalid_1's binary_logloss: 0.215914\tvalid_1's amex: 0.798481\n",
      "[10000]\ttraining's binary_logloss: 0.133444\ttraining's amex: 0.941854\tvalid_1's binary_logloss: 0.215796\tvalid_1's amex: 0.798708\n",
      "[10500]\ttraining's binary_logloss: 0.129806\ttraining's amex: 0.947284\tvalid_1's binary_logloss: 0.215728\tvalid_1's amex: 0.799165\n",
      "[11000]\ttraining's binary_logloss: 0.126695\ttraining's amex: 0.95218\tvalid_1's binary_logloss: 0.215691\tvalid_1's amex: 0.798688\n",
      "Our fold 3 CV score is 0.7984765150747437\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 3548 features...\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.838193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 575802\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 3546\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[500]\ttraining's binary_logloss: 0.313041\ttraining's amex: 0.773553\tvalid_1's binary_logloss: 0.316684\tvalid_1's amex: 0.768088\n",
      "[1000]\ttraining's binary_logloss: 0.251774\ttraining's amex: 0.78941\tvalid_1's binary_logloss: 0.25862\tvalid_1's amex: 0.777343\n",
      "[1500]\ttraining's binary_logloss: 0.225489\ttraining's amex: 0.803622\tvalid_1's binary_logloss: 0.236104\tvalid_1's amex: 0.785139\n",
      "[2000]\ttraining's binary_logloss: 0.212487\ttraining's amex: 0.816743\tvalid_1's binary_logloss: 0.227333\tvalid_1's amex: 0.789195\n",
      "[2500]\ttraining's binary_logloss: 0.205277\ttraining's amex: 0.826149\tvalid_1's binary_logloss: 0.223862\tvalid_1's amex: 0.79171\n",
      "[3000]\ttraining's binary_logloss: 0.197714\ttraining's amex: 0.835979\tvalid_1's binary_logloss: 0.220881\tvalid_1's amex: 0.794094\n",
      "[3500]\ttraining's binary_logloss: 0.192223\ttraining's amex: 0.844315\tvalid_1's binary_logloss: 0.219449\tvalid_1's amex: 0.794993\n",
      "[4000]\ttraining's binary_logloss: 0.186036\ttraining's amex: 0.853071\tvalid_1's binary_logloss: 0.218022\tvalid_1's amex: 0.797258\n",
      "[4500]\ttraining's binary_logloss: 0.180692\ttraining's amex: 0.862415\tvalid_1's binary_logloss: 0.217156\tvalid_1's amex: 0.79753\n",
      "[5000]\ttraining's binary_logloss: 0.176161\ttraining's amex: 0.870308\tvalid_1's binary_logloss: 0.216695\tvalid_1's amex: 0.798851\n",
      "[5500]\ttraining's binary_logloss: 0.170888\ttraining's amex: 0.879098\tvalid_1's binary_logloss: 0.216085\tvalid_1's amex: 0.799536\n",
      "[6000]\ttraining's binary_logloss: 0.166088\ttraining's amex: 0.887281\tvalid_1's binary_logloss: 0.215621\tvalid_1's amex: 0.799858\n",
      "[6500]\ttraining's binary_logloss: 0.161664\ttraining's amex: 0.895221\tvalid_1's binary_logloss: 0.21536\tvalid_1's amex: 0.799743\n",
      "[7000]\ttraining's binary_logloss: 0.156731\ttraining's amex: 0.903504\tvalid_1's binary_logloss: 0.215022\tvalid_1's amex: 0.799575\n",
      "[7500]\ttraining's binary_logloss: 0.152438\ttraining's amex: 0.910841\tvalid_1's binary_logloss: 0.214852\tvalid_1's amex: 0.799579\n",
      "[8000]\ttraining's binary_logloss: 0.148489\ttraining's amex: 0.917952\tvalid_1's binary_logloss: 0.214662\tvalid_1's amex: 0.800063\n",
      "[8500]\ttraining's binary_logloss: 0.144549\ttraining's amex: 0.924615\tvalid_1's binary_logloss: 0.214507\tvalid_1's amex: 0.80024\n",
      "[9000]\ttraining's binary_logloss: 0.140477\ttraining's amex: 0.93133\tvalid_1's binary_logloss: 0.214367\tvalid_1's amex: 0.799692\n",
      "[9500]\ttraining's binary_logloss: 0.137272\ttraining's amex: 0.936529\tvalid_1's binary_logloss: 0.214329\tvalid_1's amex: 0.799368\n",
      "[10000]\ttraining's binary_logloss: 0.133651\ttraining's amex: 0.941867\tvalid_1's binary_logloss: 0.214234\tvalid_1's amex: 0.799696\n",
      "[10500]\ttraining's binary_logloss: 0.129989\ttraining's amex: 0.94741\tvalid_1's binary_logloss: 0.214207\tvalid_1's amex: 0.799688\n",
      "[11000]\ttraining's binary_logloss: 0.126941\ttraining's amex: 0.952588\tvalid_1's binary_logloss: 0.214196\tvalid_1's amex: 0.799516\n",
      "Our fold 4 CV score is 0.7993046348642654\n"
     ]
    }
   ],
   "source": [
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train_agg, target)):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {train_agg.shape[1]} features...')\n",
    "    print('-'*50)\n",
    "    x_train, x_val = train_agg.iloc[trn_ind], train_agg.iloc[val_ind]\n",
    "    y_train, y_val = target[trn_ind], target[val_ind]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=cat_features.tolist())\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature=cat_features.tolist())\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 8000,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 200,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "    )\n",
    "    # Save best model\n",
    "    joblib.dump(model, f'{EXP_PATH}/lgbm_dart_923_half_fix/models/model_fold{fold}_seed{seed}.pkl')\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(x_val, raw_score=True)\n",
    "    # # Add to out of folds array\n",
    "    # oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "    # test_pred = model.predict(test[features])\n",
    "    # test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)                                      \n",
    "    print(f'Our fold {fold} CV score is {val_score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d434bd5-aded-4775-ab59-c057a09f0d4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mx_val\u001b[49m, raw_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m val_score, val_g, val_t4 \u001b[38;5;241m=\u001b[39m amex_metric(y_val, y_val_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_val' is not defined"
     ]
    }
   ],
   "source": [
    "y_val_pred = model.predict(x_val, raw_score=True)\n",
    "val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10fcb11e-2f3a-4e60-85dc-8f4d392bf6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7993821694220526, 0.9270201772619467, 0.6717441615821587)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_score, val_g, val_t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c884d89c-50a9-4a95-8e5a-a26daef20afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, x_val, y_train, y_val, lgb_train, lgb_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3726a8-22c0-4cf4-8f0b-9eea525a0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv(f'test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d0c0e-c5e3-4bfb-8df9-74090a83a208",
   "metadata": {},
   "source": [
    "### Tune LGBM using Optuna (KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e4e9c4-e33a-40b0-aed5-9535bb8ea865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../experiments/lgbm_gbdt_clean_agg_exp2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_EXP_PATH = f\"{EXP_PATH}/lgbm_gbdt_clean_agg_exp2\"\n",
    "CURRENT_EXP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7b73d2a6-968c-4e53-a61f-6148f20eff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7958662214261033"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{CURRENT_EXP_PATH}/best_scores.json\", \"r+\") as outfile:\n",
    "    best_scores_json = json.load(outfile)\n",
    "np.mean(list(best_scores_json[\"validation\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6233e718-451c-40a4-a8e1-2504eb0a0eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    kf = StratifiedKFold(n_splits=5) # , shuffle=True, random_state=1020\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metrics\": \"custom\",\n",
    "        \"first_metric_only\": True, \n",
    "        \"boost_from_average\": False,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"random_state\": 1,\n",
    "        \"learning_rate\": 0.025,\n",
    "        \"n_estimators\": 1500,\n",
    "        \"max_bins\": 127,\n",
    "        \"subsample_freq\": 2,\n",
    "        \"min_child_samples\": 1500,\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 0.1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 5, 30, log=True),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 0.25),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.65, 0.75),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1.3, 2),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 75, 120)\n",
    "    }\n",
    "    print(\n",
    "        \"alpha\", round(params[\"reg_alpha\"], 4), \n",
    "        \"lambda\", round(params[\"reg_lambda\"], 4),\n",
    "        \"colsample_bytree\", round(params[\"colsample_bytree\"], 3),\n",
    "        \"subsample\", round(params[\"subsample\"], 3), \n",
    "        \"scale_pos_weight\", round(params[\"scale_pos_weight\"], 3), \n",
    "        \"num_leaves\", round(params[\"num_leaves\"], 0)\n",
    "    )\n",
    "    train_score_list, val_score_list = [], []\n",
    "    for fold, (idx_tr, idx_va) in zip(range(1, 5+1), kf.split(train_agg, target)):\n",
    "        fold = str(fold)\n",
    "        X_train, y_train = train_agg.iloc[idx_tr], target[idx_tr]\n",
    "        train_data = lgb.Dataset(\n",
    "            X_train,\n",
    "            y_train\n",
    "        )\n",
    "        X_val, y_val = train_agg.iloc[idx_va], target[idx_va], \n",
    "        valid_data = lgb.Dataset(\n",
    "            X_val,\n",
    "            y_val,\n",
    "            reference=train_data\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', category=UserWarning)\n",
    "            model = lgb.train(\n",
    "                params=params,\n",
    "                train_set=train_data, \n",
    "                valid_sets=[valid_data, train_data], \n",
    "                feval=lgb_amex_metric, \n",
    "                early_stopping_rounds=200,\n",
    "                categorical_feature=cat_columns,\n",
    "                callbacks=[\n",
    "                    log_evaluation(100),\n",
    "                ]\n",
    "            )\n",
    "        y_train_pred = model.predict(X_train, raw_score=True)\n",
    "        train_score, train_g, train_t4 = amex_metric(y_train, y_train_pred)\n",
    "        train_data, X_train, y_train = None, None, None\n",
    "        y_val_pred = model.predict(X_val, raw_score=True)\n",
    "        val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)\n",
    "        valid_data, X_val, y_val = None, None, None\n",
    "        train_score_list.append(train_score)\n",
    "        val_score_list.append(val_score)\n",
    "        if val_score > best_scores_json[\"validation\"][fold]:\n",
    "            best_scores_json[\"train\"][fold] = train_score\n",
    "            best_scores_json[\"validation\"][fold] = val_score\n",
    "            with open(f'{CURRENT_EXP_PATH}/best_scores.json', \"w\") as outfile:\n",
    "                json.dump(best_scores_json, outfile)\n",
    "            joblib.dump(model, f'{CURRENT_EXP_PATH}/models/model{fold}.pkl')\n",
    "        elif np.mean(train_score_list) >= np.mean(list(best_scores_json[\"train\"].values())) + 0.02:\n",
    "            print(f\"Train score too high (overfitting), start a new trial\")\n",
    "            return np.mean(val_score_list)\n",
    "        print(f\"{Fore.BLUE}{Style.BRIGHT}Fold {fold} | Train Score = {train_score:.5f} ({train_g:.4f}, {train_t4:.4f})\")\n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | Val Score = {val_score:.5f} ({val_g:.4f}, {val_t4:.4f}){Style.RESET_ALL}\")\n",
    "        print(f\"Clear cache {gc.collect()}\")\n",
    "        \n",
    "    return np.mean(val_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9738158a-e0f5-4344-8cf2-d4c3dc11e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = joblib.load(f\"{CURRENT_EXP_PATH}/optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ffd19460-172e-4ffc-a8e3-3fe3be8e6626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-29 03:43:35,484]\u001b[0m A new study created in memory with name: no-name-f47c98f4-d772-41dd-9033-0954e5ba2b67\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d43bc4e-0911-4e67-b930-37331162d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e9a5e-ff8f-4646-a1fc-e1b3d559c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    num_cols = [col for col in num_cols if 'last' in col]\n",
    "    for col in num_cols:\n",
    "        train[col + '_round2'] = train[col].round(2)\n",
    "        test[col + '_round2'] = test[col].round(2)\n",
    "    # Get the difference between last and mean\n",
    "    num_cols = [col for col in train.columns if 'last' in col]\n",
    "    num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "            test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "        except:\n",
    "            pass\n",
    "    # Transform float64 and float32 to float16\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    for col in tqdm(num_cols):\n",
    "        train[col] = train[col].astype(np.float16)\n",
    "        test[col] = test[col].astype(np.float16)\n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': \"binary_logloss\",\n",
    "        'boosting': 'dart',\n",
    "        'seed': CFG.seed,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40\n",
    "        }\n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval = 500,\n",
    "            feval = lgb_amex_metric\n",
    "            )\n",
    "        # Save best model\n",
    "        joblib.dump(model, f'lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        # Predict validation\n",
    "        val_pred = model.predict(x_val)\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[val_ind] = val_pred\n",
    "        # Predict the test set\n",
    "        test_pred = model.predict(test[features])\n",
    "        test_predictions += test_pred / CFG.n_folds\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "    # Compute out of folds metric\n",
    "    score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    print(f'Our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "    oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    # Create a dataframe to store test prediction\n",
    "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    test_df.to_csv(f'test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8893b35-b961-487b-87d9-b772f110971e",
   "metadata": {},
   "source": [
    "### Train LGBM using previous hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e228ff45-7a54-4518-bce6-beb0018c9acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 627 ms, sys: 367 ms, total: 994 ms\n",
      "Wall time: 182 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_gbdt = LGBM(\n",
    "    exp_full_path=\"../experiments/lgbm_gbdt_clean_agg_exp\"\n",
    ")\n",
    "gbdt_master_feature_set = lgbm_gbdt.master_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "57a4023b-90fb-4b44-b367-260b29f1f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = [lgbm_gbdt.models[i].params for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f402c257-c06c-4733-a57c-be5544e7bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [lgbm_gbdt.models[i].feature_name() for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "086b4b4d-5506-4198-8b32-9be394894a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../experiments/lgbm_gbdt_clean_agg_exp2'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_EXP_PATH = f\"{EXP_PATH}/lgbm_gbdt_clean_agg_exp2\"\n",
    "CURRENT_EXP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40de8c96-cc56-4106-85fd-8ee3149a08d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7952671040871171"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{CURRENT_EXP_PATH}/best_scores.json\", \"r+\") as outfile:\n",
    "    best_scores_json = json.load(outfile)\n",
    "np.mean(list(best_scores_json[\"validation\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8938126d-104d-4332-b7e1-808e7ad5bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's amex: 0.772749\tvalid_0's amex: 0.764194\n",
      "[200]\ttraining's amex: 0.793912\tvalid_0's amex: 0.779027\n",
      "[300]\ttraining's amex: 0.809858\tvalid_0's amex: 0.786349\n",
      "[400]\ttraining's amex: 0.822633\tvalid_0's amex: 0.79024\n",
      "[500]\ttraining's amex: 0.833657\tvalid_0's amex: 0.792135\n",
      "[600]\ttraining's amex: 0.844581\tvalid_0's amex: 0.792309\n",
      "[700]\ttraining's amex: 0.855259\tvalid_0's amex: 0.793058\n",
      "[800]\ttraining's amex: 0.865281\tvalid_0's amex: 0.794597\n",
      "[900]\ttraining's amex: 0.875367\tvalid_0's amex: 0.794958\n",
      "[1000]\ttraining's amex: 0.884329\tvalid_0's amex: 0.795426\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.87105 (0.9584, 0.7837)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79562 (0.9229, 0.6683)\u001b[0m\n",
      "Clear cache 729\n",
      "[100]\ttraining's amex: 0.773301\tvalid_0's amex: 0.762565\n",
      "[200]\ttraining's amex: 0.793521\tvalid_0's amex: 0.776562\n",
      "[300]\ttraining's amex: 0.810059\tvalid_0's amex: 0.784916\n",
      "[400]\ttraining's amex: 0.822699\tvalid_0's amex: 0.789449\n",
      "[500]\ttraining's amex: 0.834109\tvalid_0's amex: 0.790836\n",
      "[600]\ttraining's amex: 0.844935\tvalid_0's amex: 0.7923\n",
      "[700]\ttraining's amex: 0.855193\tvalid_0's amex: 0.792364\n",
      "[800]\ttraining's amex: 0.864897\tvalid_0's amex: 0.792749\n",
      "[900]\ttraining's amex: 0.874469\tvalid_0's amex: 0.793092\n",
      "[1000]\ttraining's amex: 0.883888\tvalid_0's amex: 0.793205\n",
      "[1100]\ttraining's amex: 0.893018\tvalid_0's amex: 0.793474\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.88038 (0.9621, 0.7987)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79371 (0.9235, 0.6639)\u001b[0m\n",
      "Clear cache 60\n",
      "[100]\ttraining's amex: 0.771349\tvalid_0's amex: 0.766437\n",
      "[200]\ttraining's amex: 0.79269\tvalid_0's amex: 0.779925\n",
      "[300]\ttraining's amex: 0.808809\tvalid_0's amex: 0.786207\n",
      "[400]\ttraining's amex: 0.820989\tvalid_0's amex: 0.789915\n",
      "[500]\ttraining's amex: 0.831318\tvalid_0's amex: 0.7913\n",
      "[600]\ttraining's amex: 0.841159\tvalid_0's amex: 0.791499\n",
      "[700]\ttraining's amex: 0.850228\tvalid_0's amex: 0.792235\n",
      "[800]\ttraining's amex: 0.859488\tvalid_0's amex: 0.793283\n",
      "[900]\ttraining's amex: 0.868\tvalid_0's amex: 0.793824\n",
      "[1000]\ttraining's amex: 0.87647\tvalid_0's amex: 0.794724\n",
      "[1100]\ttraining's amex: 0.884778\tvalid_0's amex: 0.794613\n",
      "[1200]\ttraining's amex: 0.892856\tvalid_0's amex: 0.794998\n",
      "[1300]\ttraining's amex: 0.900686\tvalid_0's amex: 0.795221\n",
      "[1400]\ttraining's amex: 0.908231\tvalid_0's amex: 0.794207\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.89137 (0.9655, 0.8173)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79531 (0.9245, 0.6661)\u001b[0m\n",
      "Clear cache 316\n",
      "[100]\ttraining's amex: 0.770344\tvalid_0's amex: 0.766666\n",
      "[200]\ttraining's amex: 0.792001\tvalid_0's amex: 0.781451\n",
      "[300]\ttraining's amex: 0.807373\tvalid_0's amex: 0.788276\n",
      "[400]\ttraining's amex: 0.819284\tvalid_0's amex: 0.790971\n",
      "[500]\ttraining's amex: 0.830007\tvalid_0's amex: 0.792789\n",
      "[600]\ttraining's amex: 0.840173\tvalid_0's amex: 0.794538\n",
      "[700]\ttraining's amex: 0.848747\tvalid_0's amex: 0.796143\n",
      "[800]\ttraining's amex: 0.858065\tvalid_0's amex: 0.796312\n",
      "[900]\ttraining's amex: 0.866542\tvalid_0's amex: 0.796864\n",
      "[1000]\ttraining's amex: 0.87549\tvalid_0's amex: 0.797497\n",
      "[1100]\ttraining's amex: 0.883337\tvalid_0's amex: 0.796902\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.87569 (0.9610, 0.7904)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79767 (0.9261, 0.6692)\u001b[0m\n",
      "Clear cache 178\n",
      "[100]\ttraining's amex: 0.770434\tvalid_0's amex: 0.76502\n",
      "[200]\ttraining's amex: 0.791576\tvalid_0's amex: 0.780283\n",
      "[300]\ttraining's amex: 0.806721\tvalid_0's amex: 0.788975\n",
      "[400]\ttraining's amex: 0.81879\tvalid_0's amex: 0.792253\n",
      "[500]\ttraining's amex: 0.828558\tvalid_0's amex: 0.793851\n",
      "[600]\ttraining's amex: 0.839167\tvalid_0's amex: 0.795271\n",
      "[700]\ttraining's amex: 0.847941\tvalid_0's amex: 0.795981\n",
      "[800]\ttraining's amex: 0.857118\tvalid_0's amex: 0.79646\n",
      "[900]\ttraining's amex: 0.86601\tvalid_0's amex: 0.796396\n",
      "[1000]\ttraining's amex: 0.875087\tvalid_0's amex: 0.796827\n",
      "[1100]\ttraining's amex: 0.883459\tvalid_0's amex: 0.79704\n",
      "[1200]\ttraining's amex: 0.892014\tvalid_0's amex: 0.796892\n",
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.89363 (0.9675, 0.8197)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79668 (0.9256, 0.6677)\u001b[0m\n",
      "Clear cache 222\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5) # , shuffle=True, random_state=1020\n",
    "train_score_list, val_score_list = [], []\n",
    "for idx, fold, (idx_tr, idx_va) in zip(range(5), range(1, 5+1), kf.split(train_agg, target)):\n",
    "    fold = str(fold)\n",
    "    params_ = hyperparams[idx]\n",
    "    feature_ = features[idx]\n",
    "    X_train, y_train = train_agg.loc[idx_tr, feature_], target[idx_tr]\n",
    "    train_data = lgb.Dataset(\n",
    "        X_train,\n",
    "        y_train\n",
    "    )\n",
    "    X_val, y_val = train_agg.loc[idx_va, feature_], target[idx_va], \n",
    "    valid_data = lgb.Dataset(\n",
    "        X_val,\n",
    "        y_val,\n",
    "        reference=train_data\n",
    "    )\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model = lgb.train(\n",
    "            params=params_,\n",
    "            train_set=train_data, \n",
    "            valid_sets=[valid_data, train_data], \n",
    "            feval=lgb_amex_metric, \n",
    "            early_stopping_rounds=200,\n",
    "            callbacks=[\n",
    "                log_evaluation(100),\n",
    "            ]\n",
    "        )\n",
    "    y_train_pred = model.predict(X_train, raw_score=True)\n",
    "    train_score, train_g, train_t4 = amex_metric(y_train, y_train_pred)\n",
    "    train_data, X_train, y_train = None, None, None\n",
    "    y_val_pred = model.predict(X_val, raw_score=True)\n",
    "    val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)\n",
    "    valid_data, X_val, y_val = None, None, None\n",
    "    train_score_list.append(train_score)\n",
    "    val_score_list.append(val_score)\n",
    "    if val_score > best_scores_json[\"validation\"][fold]:\n",
    "        best_scores_json[\"train\"][fold] = train_score\n",
    "        best_scores_json[\"validation\"][fold] = val_score\n",
    "        with open(f'{CURRENT_EXP_PATH}/best_scores.json', \"w\") as outfile:\n",
    "            json.dump(best_scores_json, outfile)\n",
    "        joblib.dump(model, f'{CURRENT_EXP_PATH}/models/model{fold}.pkl')\n",
    "    elif np.mean(train_score_list) >= np.mean(list(best_scores_json[\"train\"].values())) + 0.02:\n",
    "        print(f\"Train score too high (overfitting), start a new trial\")\n",
    "    print(f\"{Fore.BLUE}{Style.BRIGHT}Fold {fold} | Train Score = {train_score:.5f} ({train_g:.4f}, {train_t4:.4f})\")\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | Val Score = {val_score:.5f} ({val_g:.4f}, {val_t4:.4f}){Style.RESET_ALL}\")\n",
    "    print(f\"Clear cache {gc.collect()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b2c30-f361-4d54-aa1a-2baf2d20715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_agg, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1057729-4387-49b7-b4e3-784ed649f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "090d2444-b672-429f-aedf-555f94fb8a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=13, values=[0.7957243237457016], datetime_start=datetime.datetime(2022, 7, 23, 17, 10, 17, 948928), datetime_complete=datetime.datetime(2022, 7, 23, 17, 49, 22, 128688), params={'reg_alpha': 0.03419275048156644, 'reg_lambda': 10.13682796954036, 'colsample_bytree': 0.21796494267435756, 'subsample': 0.6247849970379308, 'scale_pos_weight': 1.9341486908332768, 'num_leaves': 83}, distributions={'reg_alpha': LogUniformDistribution(high=0.2, low=0.001), 'reg_lambda': LogUniformDistribution(high=50.0, low=10.0), 'colsample_bytree': UniformDistribution(high=0.3, low=0.19), 'subsample': UniformDistribution(high=0.75, low=0.5), 'scale_pos_weight': UniformDistribution(high=2.5, low=1.5), 'num_leaves': IntUniformDistribution(high=125, low=75, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=13, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e3895998-c541-42b5-8580-44eb8bc20e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../experiments/lgbm_gbdt_clean_agg_exp2/optuna_study.pkl']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, f\"{CURRENT_EXP_PATH}/optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c866019b-d808-4f28-928a-7dc0d8421c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "52e2b9d7-e6ae-4e0e-af6c-9a3ee33bf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = study_df.loc[study_df[\"state\"] == \"COMPLETE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3cbfdcc0-fb3b-4f1d-8fbe-89c1b8bc3a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>params_reg_alpha</th>\n",
       "      <th>params_reg_lambda</th>\n",
       "      <th>params_scale_pos_weight</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.795199</td>\n",
       "      <td>2022-07-29 03:43:37.134571</td>\n",
       "      <td>2022-07-29 04:15:38.718854</td>\n",
       "      <td>0 days 00:32:01.584283</td>\n",
       "      <td>0.211736</td>\n",
       "      <td>107</td>\n",
       "      <td>0.035459</td>\n",
       "      <td>19.665238</td>\n",
       "      <td>1.732579</td>\n",
       "      <td>0.718203</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.794633</td>\n",
       "      <td>2022-07-29 04:15:38.720092</td>\n",
       "      <td>2022-07-29 04:51:31.726391</td>\n",
       "      <td>0 days 00:35:53.006299</td>\n",
       "      <td>0.240126</td>\n",
       "      <td>112</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>8.493242</td>\n",
       "      <td>1.637483</td>\n",
       "      <td>0.683979</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.795288</td>\n",
       "      <td>2022-07-29 04:51:31.727066</td>\n",
       "      <td>2022-07-29 05:00:37.160492</td>\n",
       "      <td>0 days 00:09:05.433426</td>\n",
       "      <td>0.242709</td>\n",
       "      <td>106</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>7.959416</td>\n",
       "      <td>1.762319</td>\n",
       "      <td>0.738242</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.795027</td>\n",
       "      <td>2022-07-29 05:00:37.170322</td>\n",
       "      <td>2022-07-29 05:35:14.543992</td>\n",
       "      <td>0 days 00:34:37.373670</td>\n",
       "      <td>0.246249</td>\n",
       "      <td>116</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>5.280905</td>\n",
       "      <td>1.579482</td>\n",
       "      <td>0.718656</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.795043</td>\n",
       "      <td>2022-07-29 05:35:14.545466</td>\n",
       "      <td>2022-07-29 06:10:02.834035</td>\n",
       "      <td>0 days 00:34:48.288569</td>\n",
       "      <td>0.209132</td>\n",
       "      <td>88</td>\n",
       "      <td>0.077343</td>\n",
       "      <td>15.609217</td>\n",
       "      <td>1.367447</td>\n",
       "      <td>0.716029</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.795520</td>\n",
       "      <td>2022-07-29 06:10:02.835018</td>\n",
       "      <td>2022-07-29 06:46:57.128561</td>\n",
       "      <td>0 days 00:36:54.293543</td>\n",
       "      <td>0.237866</td>\n",
       "      <td>76</td>\n",
       "      <td>0.054068</td>\n",
       "      <td>14.030964</td>\n",
       "      <td>1.854585</td>\n",
       "      <td>0.671884</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.795208</td>\n",
       "      <td>2022-07-29 06:46:57.129502</td>\n",
       "      <td>2022-07-29 07:19:31.398416</td>\n",
       "      <td>0 days 00:32:34.268914</td>\n",
       "      <td>0.234447</td>\n",
       "      <td>87</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>6.484752</td>\n",
       "      <td>1.590657</td>\n",
       "      <td>0.674611</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.794258</td>\n",
       "      <td>2022-07-29 07:19:31.399761</td>\n",
       "      <td>2022-07-29 07:28:16.288871</td>\n",
       "      <td>0 days 00:08:44.889110</td>\n",
       "      <td>0.200135</td>\n",
       "      <td>113</td>\n",
       "      <td>0.096341</td>\n",
       "      <td>6.831739</td>\n",
       "      <td>1.445638</td>\n",
       "      <td>0.718477</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.794641</td>\n",
       "      <td>2022-07-29 07:28:16.298937</td>\n",
       "      <td>2022-07-29 07:37:16.176247</td>\n",
       "      <td>0 days 00:08:59.877310</td>\n",
       "      <td>0.239228</td>\n",
       "      <td>105</td>\n",
       "      <td>0.073812</td>\n",
       "      <td>10.654995</td>\n",
       "      <td>1.520339</td>\n",
       "      <td>0.737015</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.794920</td>\n",
       "      <td>2022-07-29 07:37:16.179792</td>\n",
       "      <td>2022-07-29 08:08:40.770623</td>\n",
       "      <td>0 days 00:31:24.590831</td>\n",
       "      <td>0.205050</td>\n",
       "      <td>92</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>26.370648</td>\n",
       "      <td>1.600485</td>\n",
       "      <td>0.732880</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.794677</td>\n",
       "      <td>2022-07-29 08:08:40.772263</td>\n",
       "      <td>2022-07-29 08:41:09.822491</td>\n",
       "      <td>0 days 00:32:29.050228</td>\n",
       "      <td>0.224772</td>\n",
       "      <td>76</td>\n",
       "      <td>0.019755</td>\n",
       "      <td>14.080355</td>\n",
       "      <td>1.969562</td>\n",
       "      <td>0.654610</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.795406</td>\n",
       "      <td>2022-07-29 08:41:09.823444</td>\n",
       "      <td>2022-07-29 09:15:27.144188</td>\n",
       "      <td>0 days 00:34:17.320744</td>\n",
       "      <td>0.229399</td>\n",
       "      <td>99</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>10.312228</td>\n",
       "      <td>1.824824</td>\n",
       "      <td>0.689469</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.795086</td>\n",
       "      <td>2022-07-29 09:15:27.145373</td>\n",
       "      <td>2022-07-29 09:47:13.254606</td>\n",
       "      <td>0 days 00:31:46.109233</td>\n",
       "      <td>0.227032</td>\n",
       "      <td>76</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>10.959554</td>\n",
       "      <td>1.895681</td>\n",
       "      <td>0.687519</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.794644</td>\n",
       "      <td>2022-07-29 09:47:13.255935</td>\n",
       "      <td>2022-07-29 09:55:42.761822</td>\n",
       "      <td>0 days 00:08:29.505887</td>\n",
       "      <td>0.226810</td>\n",
       "      <td>96</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>18.672315</td>\n",
       "      <td>1.831794</td>\n",
       "      <td>0.660384</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.795155</td>\n",
       "      <td>2022-07-29 12:03:00.933167</td>\n",
       "      <td>2022-07-29 12:32:31.178222</td>\n",
       "      <td>0 days 00:29:30.245055</td>\n",
       "      <td>0.219153</td>\n",
       "      <td>83</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>12.348109</td>\n",
       "      <td>1.997473</td>\n",
       "      <td>0.702173</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.795022</td>\n",
       "      <td>2022-07-29 12:32:31.180001</td>\n",
       "      <td>2022-07-29 13:03:23.825415</td>\n",
       "      <td>0 days 00:30:52.645414</td>\n",
       "      <td>0.234464</td>\n",
       "      <td>99</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>9.802143</td>\n",
       "      <td>1.745741</td>\n",
       "      <td>0.669698</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.794763</td>\n",
       "      <td>2022-07-29 13:03:23.826882</td>\n",
       "      <td>2022-07-29 13:34:52.689278</td>\n",
       "      <td>0 days 00:31:28.862396</td>\n",
       "      <td>0.233843</td>\n",
       "      <td>120</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>24.830502</td>\n",
       "      <td>1.878941</td>\n",
       "      <td>0.698333</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.795199 2022-07-29 03:43:37.134571 2022-07-29 04:15:38.718854   \n",
       "1        1  0.794633 2022-07-29 04:15:38.720092 2022-07-29 04:51:31.726391   \n",
       "2        2  0.795288 2022-07-29 04:51:31.727066 2022-07-29 05:00:37.160492   \n",
       "3        3  0.795027 2022-07-29 05:00:37.170322 2022-07-29 05:35:14.543992   \n",
       "4        4  0.795043 2022-07-29 05:35:14.545466 2022-07-29 06:10:02.834035   \n",
       "5        5  0.795520 2022-07-29 06:10:02.835018 2022-07-29 06:46:57.128561   \n",
       "6        6  0.795208 2022-07-29 06:46:57.129502 2022-07-29 07:19:31.398416   \n",
       "7        7  0.794258 2022-07-29 07:19:31.399761 2022-07-29 07:28:16.288871   \n",
       "8        8  0.794641 2022-07-29 07:28:16.298937 2022-07-29 07:37:16.176247   \n",
       "9        9  0.794920 2022-07-29 07:37:16.179792 2022-07-29 08:08:40.770623   \n",
       "10      10  0.794677 2022-07-29 08:08:40.772263 2022-07-29 08:41:09.822491   \n",
       "11      11  0.795406 2022-07-29 08:41:09.823444 2022-07-29 09:15:27.144188   \n",
       "12      12  0.795086 2022-07-29 09:15:27.145373 2022-07-29 09:47:13.254606   \n",
       "13      13  0.794644 2022-07-29 09:47:13.255935 2022-07-29 09:55:42.761822   \n",
       "15      15  0.795155 2022-07-29 12:03:00.933167 2022-07-29 12:32:31.178222   \n",
       "16      16  0.795022 2022-07-29 12:32:31.180001 2022-07-29 13:03:23.825415   \n",
       "17      17  0.794763 2022-07-29 13:03:23.826882 2022-07-29 13:34:52.689278   \n",
       "\n",
       "                 duration  params_colsample_bytree  params_num_leaves  \\\n",
       "0  0 days 00:32:01.584283                 0.211736                107   \n",
       "1  0 days 00:35:53.006299                 0.240126                112   \n",
       "2  0 days 00:09:05.433426                 0.242709                106   \n",
       "3  0 days 00:34:37.373670                 0.246249                116   \n",
       "4  0 days 00:34:48.288569                 0.209132                 88   \n",
       "5  0 days 00:36:54.293543                 0.237866                 76   \n",
       "6  0 days 00:32:34.268914                 0.234447                 87   \n",
       "7  0 days 00:08:44.889110                 0.200135                113   \n",
       "8  0 days 00:08:59.877310                 0.239228                105   \n",
       "9  0 days 00:31:24.590831                 0.205050                 92   \n",
       "10 0 days 00:32:29.050228                 0.224772                 76   \n",
       "11 0 days 00:34:17.320744                 0.229399                 99   \n",
       "12 0 days 00:31:46.109233                 0.227032                 76   \n",
       "13 0 days 00:08:29.505887                 0.226810                 96   \n",
       "15 0 days 00:29:30.245055                 0.219153                 83   \n",
       "16 0 days 00:30:52.645414                 0.234464                 99   \n",
       "17 0 days 00:31:28.862396                 0.233843                120   \n",
       "\n",
       "    params_reg_alpha  params_reg_lambda  params_scale_pos_weight  \\\n",
       "0           0.035459          19.665238                 1.732579   \n",
       "1           0.042724           8.493242                 1.637483   \n",
       "2           0.010279           7.959416                 1.762319   \n",
       "3           0.010454           5.280905                 1.579482   \n",
       "4           0.077343          15.609217                 1.367447   \n",
       "5           0.054068          14.030964                 1.854585   \n",
       "6           0.066375           6.484752                 1.590657   \n",
       "7           0.096341           6.831739                 1.445638   \n",
       "8           0.073812          10.654995                 1.520339   \n",
       "9           0.044620          26.370648                 1.600485   \n",
       "10          0.019755          14.080355                 1.969562   \n",
       "11          0.018996          10.312228                 1.824824   \n",
       "12          0.021125          10.959554                 1.895681   \n",
       "13          0.023217          18.672315                 1.831794   \n",
       "15          0.013795          12.348109                 1.997473   \n",
       "16          0.028762           9.802143                 1.745741   \n",
       "17          0.015337          24.830502                 1.878941   \n",
       "\n",
       "    params_subsample     state  \n",
       "0           0.718203  COMPLETE  \n",
       "1           0.683979  COMPLETE  \n",
       "2           0.738242  COMPLETE  \n",
       "3           0.718656  COMPLETE  \n",
       "4           0.716029  COMPLETE  \n",
       "5           0.671884  COMPLETE  \n",
       "6           0.674611  COMPLETE  \n",
       "7           0.718477  COMPLETE  \n",
       "8           0.737015  COMPLETE  \n",
       "9           0.732880  COMPLETE  \n",
       "10          0.654610  COMPLETE  \n",
       "11          0.689469  COMPLETE  \n",
       "12          0.687519  COMPLETE  \n",
       "13          0.660384  COMPLETE  \n",
       "15          0.702173  COMPLETE  \n",
       "16          0.669698  COMPLETE  \n",
       "17          0.698333  COMPLETE  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "22995960-4df7-4390-a057-54f6a09d1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df.to_csv(f\"{CURRENT_EXP_PATH}/optuna_trials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967e81b-a756-4abe-b3e9-50804f108661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file(f'{EXP_PATH}/lgbm_gbdt_exp3/optuna_trials.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b439c86-fa0d-4db6-8b5b-2dbdc9a7aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df = study_df.drop(columns=\"number\").reset_index(drop=True).reset_index().rename(columns={\"index\": \"number\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc35b93-4119-4bfd-8f41-e84235859211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df.to_csv(f'{EXP_PATH}/lgbm_gbdt_exp3/optuna_trials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "af124361-f8db-4c40-a937-045f15dd245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in get_cols(study_df, \"params\"):\n",
    "    sns.scatterplot(data=study_df, x=study_df[col], y=study_df[\"value\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4d4d4-3000-42c0-b306-3d4ca352a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df = study.trials_dataframe()\n",
    "# study_df = study_df.loc[study_df[\"state\"] == \"COMPLETE\"].reset_index(drop=True)\n",
    "# study_df.to_csv(f\"{EXP_PATH}/lgbm_dart_exp/t.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc44c2-b5cc-47a0-a4f6-e0e393618695",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2de5f-ca9d-4b2b-99ed-4c33c5a33a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, score_list, y_pred_list, held_out_index_list = [], [], [], []\n",
    "model_dict = {}\n",
    "X_val_dict = {}\n",
    "y_val_dict = {}\n",
    "y_score_dict = {}\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "for fold, (idx_tr, idx_va), n_est in zip(range(1, 10+1), kf.split(train, target), n_est_list):\n",
    "    model_dict[fold] = joblib.load(f\"{MODELS_PATH}/lgbm_models/model_{fold}.pkl\")\n",
    "    X_val_dict[fold] = train.iloc[idx_va][features]\n",
    "    y_val_dict[fold] = target[idx_va]\n",
    "    y_score_dict[fold] = model_dict[fold].predict_proba(X_val_dict[fold], raw_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e2ea6-c065-4730-bb16-daf6cb6c3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    print(i, amex_metric_np(y_score_dict[i], y_val_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d26a2-8821-47e9-a926-133148712b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = pd.concat(list(X_val_dict.values()))\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5795c76-f1ae-420d-b1ac-26c7ae102239",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_gt = np.concatenate(list(y_val_dict.values()))\n",
    "len(full_train_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac46e0f-76dd-4d0f-97e8-9e4cd47a21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_scores = np.concatenate(list(y_score_dict.values()))\n",
    "len(full_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d6f6d-4b0b-4e6e-87f0-d866d7b2d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.loc[:, \"target\"] = full_train_gt\n",
    "full_train.loc[:, \"score\"] = full_train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba496c-cf37-4206-8308-1ba3ad7d1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_train.to_csv(f\"{EVALUATION_DATA_PATH}/train_single_raw_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65132c65-ddd3-4cb6-83ca-99422f726514",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c184d-3cc7-47b8-b7bb-cfbf853a6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, score_list, y_pred_list, held_out_index_list = [], [], [], []\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "for fold, (idx_tr, idx_va), n_est in zip(range(1, 10+1), kf.split(train, target), n_est_list):\n",
    "    X_train, X_val, y_train, y_val, model = None, None, None, None, None\n",
    "    start_time = datetime.datetime.now()\n",
    "    X_train = train.iloc[idx_tr][features]\n",
    "    X_val = train.iloc[idx_va][features]\n",
    "    y_train = target[idx_tr]\n",
    "    y_val = target[idx_va]\n",
    "    \n",
    "    model = my_booster(n_estimators=n_est)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model.fit(X_train, \n",
    "                  y_train,\n",
    "                  eval_set=[(X_val, y_val)], \n",
    "                  eval_metric=[lgb_amex_metric],\n",
    "                  callbacks=[log_evaluation(200)])\n",
    "    X_train, y_train = None, None\n",
    "    y_val_pred = model.predict_proba(X_val, raw_score=True)\n",
    "    score = amex_metric(y_val, y_val_pred)\n",
    "    n_trees = model.best_iteration_\n",
    "    if n_trees is None: \n",
    "        n_trees = model.n_estimators\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | {str(datetime.datetime.now() - start_time)[-12:-7]} |\"\n",
    "          f\" {n_trees:5} trees |\"\n",
    "          f\"                Score = {score:.5f}{Style.RESET_ALL}\")\n",
    "    score_list.append(score)\n",
    "    model_list.append(model)\n",
    "    held_out_index_list.append(idx_va)\n",
    "    # if INFERENCE:\n",
    "    #     y_pred_list.append(model.predict_proba(test[features], raw_score=True))\n",
    "        \n",
    "    # if ONLY_FIRST_FOLD:\n",
    "    #     break # we only want the first fold\n",
    "    \n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002a4ad-f9e9-45f0-b07b-dbcca8bff0e4",
   "metadata": {},
   "source": [
    "### Linear Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475d87c-9418-4c1c-822c-99708259bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = train_data.loc[train_data[\"customer_ID\"] == train_data[\"customer_ID\"][540]][\"P_2\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c37db-8369-40c2-aaee-7a73f3f09612",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.polyfit(x=range(len(array)), y=array, deg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7426308-7123-45c8-b5cd-a70ea9526215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(array):\n",
    "    if len(array) >= 2:\n",
    "        gradient, y_intercept = np.polyfit(x=range(len(array)), y=array.astype(\"float32\"), deg=1)\n",
    "        return gradient\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821d542-21f2-4717-be03-561634086e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_intercept(array):\n",
    "    if len(array) >= 2:\n",
    "        gradient, y_intercept = np.polyfit(x=range(len(array)), y=array.astype(\"float32\"), deg=1)\n",
    "        return y_intercept\n",
    "    else:\n",
    "        return array.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d01f4-6519-4e7f-9e90-dc3d1d4fd778",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.groupby(\"customer_ID\").agg(P_2_grad=(\"P_2\", calc_grad),\n",
    "                                        P_2_intercept=(\"P_2\", calc_intercept)).reset_index()\n",
    "train_agg_summary = train_agg_summary.merge(temp, on=\"customer_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b51106-4e0a-4bb2-b0fd-e10dbd9a35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test.groupby(\"customer_ID\").agg(P_2_grad=(\"P_2\", calc_grad),\n",
    "                                       P_2_intercept=(\"P_2\", calc_intercept)).reset_index()\n",
    "test_agg_summary = test_agg_summary.merge(temp, on=\"customer_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d8cfc-3c72-46e7-85fb-d176e2922edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Single LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4562d2b-ca79-4af6-ab41-7ea7d14ebe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3303e6a-e8e3-45b8-9acf-037976239cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'metrics': \"custom\",\n",
    "    'first_metric_only': True, \n",
    "    'random_state': 1,\n",
    "    'reg_alpha': 1, #0.0125, \n",
    "    'reg_lambda': 60, \n",
    "    'learning_rate': 0.1, \n",
    "    'n_estimators': 2000, \n",
    "    'colsample_bytree': 0.5, \n",
    "    'subsample': 0.7, \n",
    "    'subsample_freq': 5, \n",
    "    'min_child_samples': 2400, \n",
    "    'scale_pos_weight': 1.9, \n",
    "    'max_bins': 10, \n",
    "    'num_leaves': 50,\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a581c34-0a4e-4609-8d6e-eceefc946a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_list = repeat(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3928ad-efd2-45fe-bce6-371961aa3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_score_list, val_score_list = [], []\n",
    "# for fold, (idx_tr, idx_va) in zip(range(1, 5+1), kf.split(train_agg, target)):\n",
    "#     fold = str(fold)\n",
    "#     X_train, y_train = train_agg.iloc[idx_tr], target[idx_tr]\n",
    "#     train_data = lgb.Dataset(\n",
    "#         X_train,\n",
    "#         y_train\n",
    "#     )\n",
    "#     X_val, y_val = train_agg.iloc[idx_va], target[idx_va], \n",
    "#     valid_data = lgb.Dataset(\n",
    "#         X_val,\n",
    "#         y_val,\n",
    "#         reference=train_data\n",
    "#     )\n",
    "#     print(\"Start Training\")\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.filterwarnings('ignore', category=UserWarning)\n",
    "#         model = lgb.train(\n",
    "#             params=params,\n",
    "#             train_set=train_data, \n",
    "#             valid_sets=valid_data, \n",
    "#             feval=lgb_amex_metric, \n",
    "#             early_stopping_rounds=5,\n",
    "#             categorical_feature=cat_columns,\n",
    "#             callbacks=[\n",
    "#                 log_evaluation(5),\n",
    "#             ]\n",
    "#         )\n",
    "#     y_train_pred = model.predict(X_train, raw_score=True)\n",
    "#     train_score, train_g, train_t4 = amex_metric(y_train, y_train_pred)\n",
    "#     X_train, y_train = None, None\n",
    "#     y_val_pred = model.predict(X_val, raw_score=True)\n",
    "#     val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)\n",
    "#     X_val, y_val = None, None\n",
    "#     train_score_list.append(train_score)\n",
    "#     val_score_list.append(val_score)\n",
    "#     if val_score > best_scores_json[\"validation\"][fold]:\n",
    "#         print(\"Good\")\n",
    "#         # best_scores_json[\"train\"][fold] = train_score\n",
    "#         # best_scores_json[\"validation\"][fold] = val_score\n",
    "#         # with open(f'{CURRENT_EXP_PATH}/best_scores.json', \"w\") as outfile:\n",
    "#         #     json.dump(best_scores_json, outfile)\n",
    "#         # joblib.dump(model, f'{CURRENT_EXP_PATH}/models/model{fold}.pkl')\n",
    "#     elif np.mean(train_score_list) >= np.mean(list(best_scores_json[\"train\"].values())) + 0.05:\n",
    "#         print(f\"Train score too high (overfitting), start a new trial\")\n",
    "#     print(f\"{Fore.BLUE}{Style.BRIGHT}Fold {fold} | Train Score = {train_score:.5f} ({train_g:.4f}, {train_t4:.4f})\")\n",
    "#     print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | Val Score = {val_score:.5f} ({val_g:.4f}, {val_t4:.4f}){Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abae68b-4dcf-440f-8111-c5a7db50ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c41aa-f5fe-4508-aecf-91a81534081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_df = plot_feature_importance(model.feature_name_, model.feature_importances_, figsize=(16, 50), ascending=True, limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d227d4-762a-4266-8608-a12ff165fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df.loc[imp_df[\"feature\"] == \"dummy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ead564-f43e-4fbb-9abe-41f276d7ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imp_features = sorted(imp_df.loc[imp_df[\"feature_importance\"] == 0][\"feature\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc1ec5-291d-4b66-8d64-185da08601d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(zero_imp_features, name=\"feature\").to_csv(f\"{DROP_FEATURES_PATH}/noob_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0b275-8eb3-4f10-a06f-8f51e7193969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[\"target\"] = target\n",
    "# train.to_pickle(f\"{EXP_PATH}/lgbm_gbdt_exp2/train_val.pkl\")\n",
    "# joblib.dump(train_score_list, f'{EXP_PATH}/lgbm_gbdt_exp2/5_fold_train_scores.pkl')\n",
    "# joblib.dump(val_score_list, f'{EXP_PATH}/lgbm_gbdt_exp2/5_fold_val_scores.pkl')\n",
    "# joblib.dump(val_idx_list, f'{EXP_PATH}/lgbm_gbdt_exp2/5_fold_val_indices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4366dff-f9ec-49ab-ae29-3f047a13d504",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tune LGBM using Optuna (Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1ce3c-49b9-452c-9e71-7deeaac29eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"random_state\": 1,\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.001, 0.1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 15, 30, log=True),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.015, 0.03, log=True),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1500, 1600, 1700, 1800, 1900, 2000]),\n",
    "        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", np.arange(0.15, 0.4, 0.01)),\n",
    "        \"subsample\": trial.suggest_categorical(\"subsample\", np.arange(0.6, 0.8, 0.02)),\n",
    "        \"subsample_freq\": trial.suggest_categorical(\"subsample_freq\", [1, 2]),\n",
    "        \"min_child_samples\": trial.suggest_categorical(\"min_child_samples\", [2000, 2250, 2500]),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0.01, 450, log=True),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical(\"scale_pos_weight\", np.arange(1.25, 2.5, 0.05)),\n",
    "        \"max_bins\": trial.suggest_categorical(\"max_bins\", np.arange(400, 550, 25)),\n",
    "        \"num_leaves\": trial.suggest_categorical(\"num_leaves\", np.arange(70, 180, 10)),\n",
    "    }\n",
    "    print(params)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_agg, target, test_size=0.2)\n",
    "    model = LGBMClassifier(**params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val, y_val)], \n",
    "            eval_metric=[lgb_amex_metric],\n",
    "            callbacks=[log_evaluation(200)]\n",
    "        )\n",
    "    y_train_pred = model.predict_proba(X_train, raw_score=True)\n",
    "    train_score = amex_metric(y_train, y_train_pred)\n",
    "    y_val_pred = model.predict_proba(X_val, raw_score=True)\n",
    "    val_score = amex_metric(y_val, y_val_pred)\n",
    "    print(f\"Fold {fold} | Train Score = {train_score:.5f}\")\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | Val   Score = {val_score:.5f}{Style.RESET_ALL}\")\n",
    "    return val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae9081-fcba-492f-8978-4a6289a9ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1f1bd-4acf-4f70-a910-5f7d88248517",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

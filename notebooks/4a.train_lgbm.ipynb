{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd2ca34-3410-4078-aa48-7adbba211ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import joblib\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import repeat\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, fbeta_score, make_scorer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb17d64c-4cdb-4906-be84-1348484a4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import ListedColormap\n",
    "from cycler import cycler\n",
    "from IPython.display import display\n",
    "from colorama import Fore, Back, Style\n",
    "plt.rcParams['axes.facecolor'] = '#0057b8' # blue\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n",
    "                                         plt.rcParams['axes.prop_cycle'].by_key()['color'][1:])\n",
    "plt.rcParams['text.color'] = 'w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a084bef6-4434-40fb-bafc-d7d3e4c57a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common import (\n",
    "    sigmoid, pad_column_name\n",
    ")\n",
    "from utils.constants import (\n",
    "    RAW_DATA_PATH, PROCESSED_DATA_PATH\n",
    ")\n",
    "from utils.eval_helpers import (\n",
    "    plot_roc_curves, plot_feature_importance, \n",
    "    amex_metric, get_final_metric_df, amex_metric_np, lgb_amex_metric\n",
    ")\n",
    "from utils.eda_helpers import (\n",
    "    plot_missing_proportion_barchart, \n",
    "    get_cols\n",
    ")\n",
    "from utils.extraction_helpers import read_file\n",
    "from utils.feature_group import (\n",
    "    CATEGORY_COLUMNS, CONTINUOUS_COLUMNS, NON_FEATURE_COLUMNS,\n",
    "    MEAN_FEATURES, MIN_FEATURES, MAX_FEATURES, LAST_FEATURES, FIRST_FEATURES,\n",
    "    RANGE_FEATURES, VELOCITY_FEATURES, SPEED_FEATURES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08cce559-a615-41c7-9d81-0a5e7b981931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"../raw_data\"\n",
    "PROCESSED_DATA_PATH = \"../processed_data\"\n",
    "SUBMISSION_DATA_PATH = \"../submissions\"\n",
    "EVALUATION_DATA_PATH = \"../evaluation_data\"\n",
    "MODELS_PATH = \"../models\"\n",
    "EXP_PATH = \"../experiments\"\n",
    "DROP_FEATURES_PATH = \"../dropped_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67194602-57fc-4e92-9801-8d600e52a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885beac-e245-43b6-a2cc-73e9f871d132",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d46155-ea8e-4212-8c63-5b7ac8b08d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (458913, 4334)\n",
      "CPU times: user 3.24 s, sys: 8.6 s, total: 11.8 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = read_file(f\"{PROCESSED_DATA_PATH}/train_agg_complete2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c7632d-3cf9-4ff9-9467-9ebe9d2daecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (458913, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = read_file(f\"{RAW_DATA_PATH}/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1410d7ef-0d1e-4950-8d38-0e9e00030498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = plot_missing_proportion_barchart(train_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e33c5bb-d206-419d-8935-adb74be8117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 4334)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a258204-44db-49fc-9477-2b541992f334",
   "metadata": {},
   "source": [
    "### Pre-train Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b6202f-fd85-45df-854a-c63d2ce5afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_noob_features(feature_imp_df, threshold):\n",
    "    noob_features = []\n",
    "    for type_ in feature_imp_df.columns[1:]:\n",
    "        noob_features.extend(\n",
    "            (\n",
    "                feature_imp_df.loc[feature_imp_df[type_] < threshold][\"base_feature\"] + \"_\" + type_\n",
    "            ).tolist()\n",
    "        )\n",
    "    print(len(noob_features), feature_imp_df.shape[0] * (feature_imp_df.shape[1] - 1))\n",
    "    return noob_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b395be1-b942-47e1-bbc2-b4e4f610680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_imp_percentile(summary_df, p):\n",
    "    array = pd.Series(np.stack(summary_df.drop(columns=\"base_feature\", errors=\"ignore\").values).ravel()).dropna().values\n",
    "    return np.percentile(array, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1de3a03f-4567-43df-80ff-f60d65d8504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file 0\n",
      "Shape of data: (181, 49)\n",
      "3050 8688\n",
      "Threshold = 43.20, Dropping # of features 3050\n",
      "Read file 1\n",
      "Shape of data: (176, 25)\n",
      "1214 4224\n",
      "Threshold = 46.84, Dropping # of features 1214\n",
      "Read file 2\n",
      "Shape of data: (188, 25)\n",
      "1536 4512\n",
      "Threshold = 6.80, Dropping # of features 1536\n"
     ]
    }
   ],
   "source": [
    "features_to_drop = set()\n",
    "for i, threshold_percentile in zip(range(3), [70, 45, 40]):\n",
    "    print(f\"Read file {i}\")\n",
    "    summary_feature_imp = read_file(f\"{EXP_PATH}/feature_imp_summary{i}.csv\")\n",
    "    feature_imp_thr = get_feature_imp_percentile(summary_feature_imp, threshold_percentile)\n",
    "    drop_feature_subset = set(select_noob_features(summary_feature_imp, feature_imp_thr))\n",
    "    features_to_drop = features_to_drop.union(drop_feature_subset)\n",
    "    print(f\"Threshold = {feature_imp_thr:.2f}, Dropping # of features {len(drop_feature_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffab9376-a758-431a-90fd-fdc7ea94d3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4980"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c1a6a1c-ee4a-4bea-8ee6-674b22adcc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg = train_agg.drop(columns=list(features_to_drop), errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f96b66cc-0a45-4b1c-a495-2e305a05b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = labels[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46942b4a-fd5a-4bd0-9dbd-7ceb4b99f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 167 ms, sys: 581 ms, total: 748 ms\n",
      "Wall time: 747 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = train_agg.drop(columns=NON_FEATURE_COLUMNS + [\"target\"], errors=\"ignore\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffe8f01a-341d-4cbe-8c46-8ae026830c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = train_agg.select_dtypes(\"category\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12db292b-29da-444f-94b1-5ff8a49e6218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((458913, 1192), (458913,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b57517-b003-4331-9f6e-f3ae715139b0",
   "metadata": {},
   "source": [
    "### Oversampling / Undersampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5816cf12-f0e8-4b49-9625-856a3bafaaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=923)\n",
    "# X_res, y_res = sm.fit_resample(train_agg, target)\n",
    "# X_res.shape, y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b660cde2-e6c5-4179-8af7-4f15ebe7eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_missing_prop_df = plot_missing_proportion_barchart(train, top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ac926d9-26aa-4ece-9082-ca5380d8a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_missing_prop_df = plot_missing_proportion_barchart(train, top_n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65dddfc2-8c2b-4663-9f2e-05b8e39a47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_analysis = single_col_target_check(train, \"R_13\", q=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e92b40bf-3ff2-4663-9446-df8a45225143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_agg_analysis = single_col_target_check(train_agg, \"S_6_last\", q=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74cea420-b44b-40f8-8238-7481e66b44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_agg_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "842b8b78-44e6-4084-8d5e-4a5e098c47e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected_features = pd.read_csv(\"top_features.csv\")\n",
    "# selected_features = selected_features[\"feature\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b67830bc-5929-4084-a70a-f7c56dadcc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_agg = train_agg.loc[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0416ede7-1361-4de5-b1c3-4eca44b71fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_count_df = plot_missing_proportion_barchart(train_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "acce3c56-a3d2-4f2e-98e6-6f138e194162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_missing_columns = missing_count_df.loc[missing_count_df[\"missing_proportion\"] > 75, \"column\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0c95e34-f763-47ee-b398-0a07510ca7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Pre feature drop\", train.shape)\n",
    "# train_agg = train_agg.loc[:, set(feature_list).intersection(set(train_agg.columns))]\n",
    "# train_agg = train_agg.drop(columns=high_missing_columns, errors=\"ignore\")\n",
    "# print(\"Post feature drop\", train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f192c08-f251-4a63-b9bd-c84136bd52cb",
   "metadata": {},
   "source": [
    "### Tune LGBM using Optuna (KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72e4e9c4-e33a-40b0-aed5-9535bb8ea865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../experiments/lgbm_gbdt_exp'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_EXP_PATH = f\"{EXP_PATH}/lgbm_gbdt_exp\"\n",
    "CURRENT_EXP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b73d2a6-968c-4e53-a61f-6148f20eff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7955832525034824"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{CURRENT_EXP_PATH}/best_scores.json\", \"r+\") as outfile:\n",
    "    best_scores_json = json.load(outfile)\n",
    "np.mean(list(best_scores_json[\"validation\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6233e718-451c-40a4-a8e1-2504eb0a0eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    kf = StratifiedKFold(n_splits=5) # , shuffle=True, random_state=1020\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metrics\": \"custom\",\n",
    "        \"first_metric_only\": True, \n",
    "        \"boost_from_average\": False,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"random_state\": 1,\n",
    "        \"learning_rate\": 0.022,\n",
    "        \"n_estimators\": 7500,\n",
    "        \"max_bins\": 255,\n",
    "        \"subsample_freq\": 2,\n",
    "        \"min_child_samples\": 2000,\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.001, 0.2, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 10, 50, log=True),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.19, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.75),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1.5, 2.5),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 75, 125)\n",
    "    }\n",
    "    print(\n",
    "        \"alpha\", round(params[\"reg_alpha\"], 4), \n",
    "        \"lambda\", round(params[\"reg_lambda\"], 4),\n",
    "        \"colsample_bytree\", round(params[\"colsample_bytree\"], 3),\n",
    "        \"subsample\", round(params[\"subsample\"], 3), \n",
    "        \"scale_pos_weight\", round(params[\"scale_pos_weight\"], 3), \n",
    "        \"num_leaves\", round(params[\"num_leaves\"], 0)\n",
    "    )\n",
    "    train_score_list, val_score_list = [], []\n",
    "    for fold, (idx_tr, idx_va) in zip(range(1, 5+1), kf.split(train_agg, target)):\n",
    "        fold = str(fold)\n",
    "        X_train, y_train = train_agg.iloc[idx_tr], target[idx_tr]\n",
    "        train_data = lgb.Dataset(\n",
    "            X_train,\n",
    "            y_train\n",
    "        )\n",
    "        X_val, y_val = train_agg.iloc[idx_va], target[idx_va], \n",
    "        valid_data = lgb.Dataset(\n",
    "            X_val,\n",
    "            y_val,\n",
    "            reference=train_data\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', category=UserWarning)\n",
    "            model = lgb.train(\n",
    "                params=params,\n",
    "                train_set=train_data, \n",
    "                valid_sets=[valid_data, train_data], \n",
    "                feval=lgb_amex_metric, \n",
    "                early_stopping_rounds=250,\n",
    "                categorical_feature=cat_columns,\n",
    "                callbacks=[\n",
    "                    log_evaluation(100),\n",
    "                ]\n",
    "            )\n",
    "        y_train_pred = model.predict(X_train, raw_score=True)\n",
    "        train_score, train_g, train_t4 = amex_metric(y_train, y_train_pred)\n",
    "        train_data, X_train, y_train = None, None, None\n",
    "        y_val_pred = model.predict(X_val, raw_score=True)\n",
    "        val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)\n",
    "        valid_data, X_val, y_val = None, None, None\n",
    "        train_score_list.append(train_score)\n",
    "        val_score_list.append(val_score)\n",
    "        if val_score > best_scores_json[\"validation\"][fold]:\n",
    "            best_scores_json[\"train\"][fold] = train_score\n",
    "            best_scores_json[\"validation\"][fold] = val_score\n",
    "            with open(f'{CURRENT_EXP_PATH}/best_scores.json', \"w\") as outfile:\n",
    "                json.dump(best_scores_json, outfile)\n",
    "            joblib.dump(model, f'{CURRENT_EXP_PATH}/models/model{fold}.pkl')\n",
    "        elif np.mean(train_score_list) >= np.mean(list(best_scores_json[\"train\"].values())) + 0.02:\n",
    "            print(f\"Train score too high (overfitting), start a new trial\")\n",
    "            return np.mean(val_score_list)\n",
    "        print(f\"{Fore.BLUE}{Style.BRIGHT}Fold {fold} | Train Score = {train_score:.5f} ({train_g:.4f}, {train_t4:.4f})\")\n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | Val Score = {val_score:.5f} ({val_g:.4f}, {val_t4:.4f}){Style.RESET_ALL}\")\n",
    "        print(f\"Clear cache {gc.collect()}\")\n",
    "        \n",
    "    return np.mean(val_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9738158a-e0f5-4344-8cf2-d4c3dc11e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = joblib.load(f\"{CURRENT_EXP_PATH}/optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffd19460-172e-4ffc-a8e3-3fe3be8e6626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 09:27:49,097]\u001b[0m A new study created in memory with name: no-name-c650d067-4da7-41ca-b551-83e28873aaaf\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d43bc4e-0911-4e67-b930-37331162d034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.142 lambda 13.8791 colsample_bytree 0.236 subsample 0.721 scale_pos_weight 1.81 num_leaves 89\n",
      "[100]\ttraining's amex: 0.768002\tvalid_0's amex: 0.76055\n",
      "[200]\ttraining's amex: 0.787432\tvalid_0's amex: 0.776589\n",
      "[300]\ttraining's amex: 0.801677\tvalid_0's amex: 0.782908\n",
      "[400]\ttraining's amex: 0.813492\tvalid_0's amex: 0.786889\n",
      "[500]\ttraining's amex: 0.822602\tvalid_0's amex: 0.79047\n",
      "[600]\ttraining's amex: 0.831137\tvalid_0's amex: 0.791856\n",
      "[700]\ttraining's amex: 0.839705\tvalid_0's amex: 0.79268\n",
      "[800]\ttraining's amex: 0.848124\tvalid_0's amex: 0.793302\n",
      "[900]\ttraining's amex: 0.856168\tvalid_0's amex: 0.793491\n",
      "[1000]\ttraining's amex: 0.863909\tvalid_0's amex: 0.793903\n",
      "[1100]\ttraining's amex: 0.87173\tvalid_0's amex: 0.793784\n",
      "[1200]\ttraining's amex: 0.879484\tvalid_0's amex: 0.793931\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.86800 (0.9583, 0.7777)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79431 (0.9229, 0.6657)\u001b[0m\n",
      "Clear cache 14\n",
      "[100]\ttraining's amex: 0.767544\tvalid_0's amex: 0.758619\n",
      "[200]\ttraining's amex: 0.787401\tvalid_0's amex: 0.772696\n",
      "[300]\ttraining's amex: 0.802479\tvalid_0's amex: 0.783284\n",
      "[400]\ttraining's amex: 0.813539\tvalid_0's amex: 0.787262\n",
      "[500]\ttraining's amex: 0.823147\tvalid_0's amex: 0.789624\n",
      "[600]\ttraining's amex: 0.832223\tvalid_0's amex: 0.790325\n",
      "[700]\ttraining's amex: 0.840228\tvalid_0's amex: 0.79077\n",
      "[800]\ttraining's amex: 0.848267\tvalid_0's amex: 0.791414\n",
      "[900]\ttraining's amex: 0.856486\tvalid_0's amex: 0.792338\n",
      "[1000]\ttraining's amex: 0.863907\tvalid_0's amex: 0.792021\n",
      "[1100]\ttraining's amex: 0.871343\tvalid_0's amex: 0.792611\n",
      "[1200]\ttraining's amex: 0.879293\tvalid_0's amex: 0.793082\n",
      "[1300]\ttraining's amex: 0.886955\tvalid_0's amex: 0.793452\n",
      "[1400]\ttraining's amex: 0.894033\tvalid_0's amex: 0.793143\n",
      "[1500]\ttraining's amex: 0.901271\tvalid_0's amex: 0.793083\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.88995 (0.9664, 0.8135)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79346 (0.9235, 0.6634)\u001b[0m\n",
      "Clear cache 150\n",
      "[100]\ttraining's amex: 0.767243\tvalid_0's amex: 0.763639\n",
      "[200]\ttraining's amex: 0.786789\tvalid_0's amex: 0.778293\n",
      "[300]\ttraining's amex: 0.80245\tvalid_0's amex: 0.78401\n",
      "[400]\ttraining's amex: 0.814066\tvalid_0's amex: 0.786504\n",
      "[500]\ttraining's amex: 0.823237\tvalid_0's amex: 0.789803\n",
      "[600]\ttraining's amex: 0.831592\tvalid_0's amex: 0.790671\n",
      "[700]\ttraining's amex: 0.840213\tvalid_0's amex: 0.791772\n",
      "[800]\ttraining's amex: 0.848608\tvalid_0's amex: 0.792549\n",
      "[900]\ttraining's amex: 0.856572\tvalid_0's amex: 0.793017\n",
      "[1000]\ttraining's amex: 0.864723\tvalid_0's amex: 0.793624\n",
      "[1100]\ttraining's amex: 0.87242\tvalid_0's amex: 0.794263\n",
      "[1200]\ttraining's amex: 0.879941\tvalid_0's amex: 0.794088\n",
      "[1300]\ttraining's amex: 0.887007\tvalid_0's amex: 0.793794\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.87212 (0.9596, 0.7847)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79449 (0.9244, 0.6646)\u001b[0m\n",
      "Clear cache 62\n",
      "[100]\ttraining's amex: 0.766481\tvalid_0's amex: 0.763514\n",
      "[200]\ttraining's amex: 0.786671\tvalid_0's amex: 0.778328\n",
      "[300]\ttraining's amex: 0.801465\tvalid_0's amex: 0.78637\n",
      "[400]\ttraining's amex: 0.812834\tvalid_0's amex: 0.790368\n",
      "[500]\ttraining's amex: 0.822373\tvalid_0's amex: 0.791944\n",
      "[600]\ttraining's amex: 0.830856\tvalid_0's amex: 0.792905\n",
      "[700]\ttraining's amex: 0.839254\tvalid_0's amex: 0.793579\n",
      "[800]\ttraining's amex: 0.847335\tvalid_0's amex: 0.794501\n",
      "[900]\ttraining's amex: 0.85538\tvalid_0's amex: 0.794794\n",
      "[1000]\ttraining's amex: 0.863829\tvalid_0's amex: 0.794848\n",
      "[1100]\ttraining's amex: 0.871198\tvalid_0's amex: 0.794991\n",
      "[1200]\ttraining's amex: 0.879355\tvalid_0's amex: 0.794633\n",
      "[1300]\ttraining's amex: 0.88689\tvalid_0's amex: 0.795752\n",
      "[1400]\ttraining's amex: 0.893877\tvalid_0's amex: 0.796011\n",
      "[1500]\ttraining's amex: 0.900621\tvalid_0's amex: 0.796523\n",
      "[1600]\ttraining's amex: 0.907778\tvalid_0's amex: 0.796036\n",
      "[1700]\ttraining's amex: 0.914399\tvalid_0's amex: 0.796303\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.90128 (0.9703, 0.8323)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79672 (0.9260, 0.6674)\u001b[0m\n",
      "Clear cache 28\n",
      "[100]\ttraining's amex: 0.766119\tvalid_0's amex: 0.762596\n",
      "[200]\ttraining's amex: 0.786293\tvalid_0's amex: 0.777429\n",
      "[300]\ttraining's amex: 0.800831\tvalid_0's amex: 0.787062\n",
      "[400]\ttraining's amex: 0.81251\tvalid_0's amex: 0.791743\n",
      "[500]\ttraining's amex: 0.822339\tvalid_0's amex: 0.793469\n",
      "[600]\ttraining's amex: 0.830868\tvalid_0's amex: 0.794304\n",
      "[700]\ttraining's amex: 0.839449\tvalid_0's amex: 0.794885\n",
      "[800]\ttraining's amex: 0.848235\tvalid_0's amex: 0.795179\n",
      "[900]\ttraining's amex: 0.856105\tvalid_0's amex: 0.795773\n",
      "[1000]\ttraining's amex: 0.863714\tvalid_0's amex: 0.795646\n",
      "[1100]\ttraining's amex: 0.871234\tvalid_0's amex: 0.796062\n",
      "[1200]\ttraining's amex: 0.879453\tvalid_0's amex: 0.796852\n",
      "[1300]\ttraining's amex: 0.886665\tvalid_0's amex: 0.79659\n",
      "[1400]\ttraining's amex: 0.894081\tvalid_0's amex: 0.796183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 10:02:21,439]\u001b[0m Trial 0 finished with value: 0.7952085044600888 and parameters: {'reg_alpha': 0.14195949395754148, 'reg_lambda': 13.87907855038194, 'colsample_bytree': 0.23573096890297715, 'subsample': 0.7209649295061002, 'scale_pos_weight': 1.8103000600095478, 'num_leaves': 89}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.87930 (0.9624, 0.7962)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79705 (0.9253, 0.6688)\u001b[0m\n",
      "Clear cache 380\n",
      "alpha 0.0043 lambda 13.368 colsample_bytree 0.202 subsample 0.579 scale_pos_weight 2.374 num_leaves 102\n",
      "[100]\ttraining's amex: 0.763201\tvalid_0's amex: 0.757049\n",
      "[200]\ttraining's amex: 0.782807\tvalid_0's amex: 0.77422\n",
      "[300]\ttraining's amex: 0.797098\tvalid_0's amex: 0.783115\n",
      "[400]\ttraining's amex: 0.807319\tvalid_0's amex: 0.787494\n",
      "[500]\ttraining's amex: 0.815384\tvalid_0's amex: 0.789552\n",
      "[600]\ttraining's amex: 0.822882\tvalid_0's amex: 0.791009\n",
      "[700]\ttraining's amex: 0.829532\tvalid_0's amex: 0.791864\n",
      "[800]\ttraining's amex: 0.836178\tvalid_0's amex: 0.792099\n",
      "[900]\ttraining's amex: 0.84285\tvalid_0's amex: 0.792367\n",
      "[1000]\ttraining's amex: 0.849677\tvalid_0's amex: 0.792625\n",
      "[1100]\ttraining's amex: 0.856396\tvalid_0's amex: 0.792399\n",
      "[1200]\ttraining's amex: 0.862751\tvalid_0's amex: 0.792517\n",
      "[1300]\ttraining's amex: 0.869049\tvalid_0's amex: 0.792985\n",
      "[1400]\ttraining's amex: 0.874833\tvalid_0's amex: 0.793019\n",
      "[1500]\ttraining's amex: 0.880919\tvalid_0's amex: 0.792879\n",
      "[1600]\ttraining's amex: 0.887017\tvalid_0's amex: 0.793184\n",
      "[1700]\ttraining's amex: 0.893321\tvalid_0's amex: 0.793827\n",
      "[1800]\ttraining's amex: 0.899519\tvalid_0's amex: 0.793739\n",
      "[1900]\ttraining's amex: 0.905231\tvalid_0's amex: 0.793218\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.89784 (0.9704, 0.8253)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79386 (0.9228, 0.6649)\u001b[0m\n",
      "Clear cache 302\n",
      "[100]\ttraining's amex: 0.763412\tvalid_0's amex: 0.754259\n",
      "[200]\ttraining's amex: 0.783319\tvalid_0's amex: 0.77069\n",
      "[300]\ttraining's amex: 0.797146\tvalid_0's amex: 0.781892\n",
      "[400]\ttraining's amex: 0.806902\tvalid_0's amex: 0.786395\n",
      "[500]\ttraining's amex: 0.815095\tvalid_0's amex: 0.788125\n",
      "[600]\ttraining's amex: 0.823067\tvalid_0's amex: 0.788887\n",
      "[700]\ttraining's amex: 0.830172\tvalid_0's amex: 0.789634\n",
      "[800]\ttraining's amex: 0.83703\tvalid_0's amex: 0.78995\n",
      "[900]\ttraining's amex: 0.844163\tvalid_0's amex: 0.789906\n",
      "[1000]\ttraining's amex: 0.850657\tvalid_0's amex: 0.790602\n",
      "[1100]\ttraining's amex: 0.856724\tvalid_0's amex: 0.790741\n",
      "[1200]\ttraining's amex: 0.862955\tvalid_0's amex: 0.791127\n",
      "[1300]\ttraining's amex: 0.868925\tvalid_0's amex: 0.791363\n",
      "[1400]\ttraining's amex: 0.8753\tvalid_0's amex: 0.791846\n",
      "[1500]\ttraining's amex: 0.881324\tvalid_0's amex: 0.792266\n",
      "[1600]\ttraining's amex: 0.887185\tvalid_0's amex: 0.791934\n",
      "[1700]\ttraining's amex: 0.893392\tvalid_0's amex: 0.792066\n",
      "[1800]\ttraining's amex: 0.89944\tvalid_0's amex: 0.791533\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.89125 (0.9683, 0.8142)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79277 (0.9234, 0.6622)\u001b[0m\n",
      "Clear cache 10\n",
      "[100]\ttraining's amex: 0.762954\tvalid_0's amex: 0.759685\n",
      "[200]\ttraining's amex: 0.783137\tvalid_0's amex: 0.775905\n",
      "[300]\ttraining's amex: 0.797785\tvalid_0's amex: 0.783558\n",
      "[400]\ttraining's amex: 0.807847\tvalid_0's amex: 0.786835\n",
      "[500]\ttraining's amex: 0.81603\tvalid_0's amex: 0.789234\n",
      "[600]\ttraining's amex: 0.82364\tvalid_0's amex: 0.791284\n",
      "[700]\ttraining's amex: 0.830921\tvalid_0's amex: 0.791993\n",
      "[800]\ttraining's amex: 0.837395\tvalid_0's amex: 0.793135\n",
      "[900]\ttraining's amex: 0.843984\tvalid_0's amex: 0.793781\n",
      "[1000]\ttraining's amex: 0.850493\tvalid_0's amex: 0.793933\n",
      "[1100]\ttraining's amex: 0.856758\tvalid_0's amex: 0.794126\n",
      "[1200]\ttraining's amex: 0.86335\tvalid_0's amex: 0.794238\n",
      "[1300]\ttraining's amex: 0.869109\tvalid_0's amex: 0.794801\n",
      "[1400]\ttraining's amex: 0.875135\tvalid_0's amex: 0.793966\n",
      "[1500]\ttraining's amex: 0.881138\tvalid_0's amex: 0.793541\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.86939 (0.9602, 0.7786)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79497 (0.9243, 0.6656)\u001b[0m\n",
      "Clear cache 68\n",
      "[100]\ttraining's amex: 0.762176\tvalid_0's amex: 0.761364\n",
      "[200]\ttraining's amex: 0.781897\tvalid_0's amex: 0.777213\n",
      "[300]\ttraining's amex: 0.797117\tvalid_0's amex: 0.786084\n",
      "[400]\ttraining's amex: 0.806953\tvalid_0's amex: 0.790006\n",
      "[500]\ttraining's amex: 0.815406\tvalid_0's amex: 0.793168\n",
      "[600]\ttraining's amex: 0.822833\tvalid_0's amex: 0.794265\n",
      "[700]\ttraining's amex: 0.829424\tvalid_0's amex: 0.794801\n",
      "[800]\ttraining's amex: 0.835969\tvalid_0's amex: 0.79564\n",
      "[900]\ttraining's amex: 0.842399\tvalid_0's amex: 0.795767\n",
      "[1000]\ttraining's amex: 0.849286\tvalid_0's amex: 0.796362\n",
      "[1100]\ttraining's amex: 0.856103\tvalid_0's amex: 0.796572\n",
      "[1200]\ttraining's amex: 0.862357\tvalid_0's amex: 0.797166\n",
      "[1300]\ttraining's amex: 0.868615\tvalid_0's amex: 0.797616\n",
      "[1400]\ttraining's amex: 0.875211\tvalid_0's amex: 0.796989\n",
      "[1500]\ttraining's amex: 0.88141\tvalid_0's amex: 0.798009\n",
      "[1600]\ttraining's amex: 0.887177\tvalid_0's amex: 0.797761\n",
      "[1700]\ttraining's amex: 0.892788\tvalid_0's amex: 0.797297\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.88401 (0.9656, 0.8025)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79809 (0.9261, 0.6701)\u001b[0m\n",
      "Clear cache 160\n",
      "[100]\ttraining's amex: 0.76231\tvalid_0's amex: 0.759297\n",
      "[200]\ttraining's amex: 0.782325\tvalid_0's amex: 0.775898\n",
      "[300]\ttraining's amex: 0.79612\tvalid_0's amex: 0.785559\n",
      "[400]\ttraining's amex: 0.806477\tvalid_0's amex: 0.789497\n",
      "[500]\ttraining's amex: 0.814746\tvalid_0's amex: 0.791908\n",
      "[600]\ttraining's amex: 0.822845\tvalid_0's amex: 0.793054\n",
      "[700]\ttraining's amex: 0.829285\tvalid_0's amex: 0.794362\n",
      "[800]\ttraining's amex: 0.83641\tvalid_0's amex: 0.793518\n",
      "[900]\ttraining's amex: 0.843151\tvalid_0's amex: 0.793419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 10:35:34,525]\u001b[0m Trial 1 finished with value: 0.7948507507224912 and parameters: {'reg_alpha': 0.004344875208095323, 'reg_lambda': 13.367970202963486, 'colsample_bytree': 0.2015068223935415, 'subsample': 0.5792140288496583, 'scale_pos_weight': 2.3742522127674013, 'num_leaves': 102}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.83366 (0.9449, 0.7224)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79456 (0.9247, 0.6644)\u001b[0m\n",
      "Clear cache 132\n",
      "alpha 0.0068 lambda 16.3214 colsample_bytree 0.293 subsample 0.518 scale_pos_weight 1.769 num_leaves 86\n",
      "[100]\ttraining's amex: 0.762712\tvalid_0's amex: 0.75663\n",
      "[200]\ttraining's amex: 0.781934\tvalid_0's amex: 0.774284\n",
      "[300]\ttraining's amex: 0.795349\tvalid_0's amex: 0.782222\n",
      "[400]\ttraining's amex: 0.805168\tvalid_0's amex: 0.785783\n",
      "[500]\ttraining's amex: 0.813669\tvalid_0's amex: 0.788004\n",
      "[600]\ttraining's amex: 0.820821\tvalid_0's amex: 0.789767\n",
      "[700]\ttraining's amex: 0.828072\tvalid_0's amex: 0.79031\n",
      "[800]\ttraining's amex: 0.835304\tvalid_0's amex: 0.791779\n",
      "[900]\ttraining's amex: 0.841273\tvalid_0's amex: 0.791415\n",
      "[1000]\ttraining's amex: 0.848214\tvalid_0's amex: 0.791978\n",
      "[1100]\ttraining's amex: 0.854451\tvalid_0's amex: 0.79209\n",
      "[1200]\ttraining's amex: 0.860765\tvalid_0's amex: 0.792641\n",
      "[1300]\ttraining's amex: 0.866917\tvalid_0's amex: 0.792821\n",
      "[1400]\ttraining's amex: 0.873399\tvalid_0's amex: 0.793119\n",
      "[1500]\ttraining's amex: 0.879266\tvalid_0's amex: 0.793183\n",
      "[1600]\ttraining's amex: 0.885305\tvalid_0's amex: 0.793272\n",
      "[1700]\ttraining's amex: 0.890905\tvalid_0's amex: 0.793379\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.88023 (0.9627, 0.7978)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79385 (0.9227, 0.6650)\u001b[0m\n",
      "Clear cache 28\n",
      "[100]\ttraining's amex: 0.763064\tvalid_0's amex: 0.754476\n",
      "[200]\ttraining's amex: 0.7826\tvalid_0's amex: 0.77079\n",
      "[300]\ttraining's amex: 0.796509\tvalid_0's amex: 0.780548\n",
      "[400]\ttraining's amex: 0.806416\tvalid_0's amex: 0.784998\n",
      "[500]\ttraining's amex: 0.814056\tvalid_0's amex: 0.786939\n",
      "[600]\ttraining's amex: 0.822064\tvalid_0's amex: 0.788872\n",
      "[700]\ttraining's amex: 0.828978\tvalid_0's amex: 0.788995\n",
      "[800]\ttraining's amex: 0.835628\tvalid_0's amex: 0.790287\n",
      "[900]\ttraining's amex: 0.842217\tvalid_0's amex: 0.790807\n",
      "[1000]\ttraining's amex: 0.848553\tvalid_0's amex: 0.790263\n",
      "[1100]\ttraining's amex: 0.855063\tvalid_0's amex: 0.790672\n",
      "[1200]\ttraining's amex: 0.861567\tvalid_0's amex: 0.790578\n",
      "[1300]\ttraining's amex: 0.868178\tvalid_0's amex: 0.790274\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.85866 (0.9543, 0.7630)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79079 (0.9229, 0.6587)\u001b[0m\n",
      "Clear cache 156\n",
      "[100]\ttraining's amex: 0.762306\tvalid_0's amex: 0.758674\n",
      "[200]\ttraining's amex: 0.781926\tvalid_0's amex: 0.775498\n",
      "[300]\ttraining's amex: 0.796422\tvalid_0's amex: 0.781872\n",
      "[400]\ttraining's amex: 0.806991\tvalid_0's amex: 0.786121\n",
      "[500]\ttraining's amex: 0.814775\tvalid_0's amex: 0.788682\n",
      "[600]\ttraining's amex: 0.822646\tvalid_0's amex: 0.789233\n",
      "[700]\ttraining's amex: 0.829121\tvalid_0's amex: 0.789814\n",
      "[800]\ttraining's amex: 0.835815\tvalid_0's amex: 0.79043\n",
      "[900]\ttraining's amex: 0.842378\tvalid_0's amex: 0.79112\n",
      "[1000]\ttraining's amex: 0.848311\tvalid_0's amex: 0.791687\n",
      "[1100]\ttraining's amex: 0.854864\tvalid_0's amex: 0.792591\n",
      "[1200]\ttraining's amex: 0.861284\tvalid_0's amex: 0.792255\n",
      "[1300]\ttraining's amex: 0.867536\tvalid_0's amex: 0.793159\n",
      "[1400]\ttraining's amex: 0.873593\tvalid_0's amex: 0.793761\n",
      "[1500]\ttraining's amex: 0.879496\tvalid_0's amex: 0.793904\n",
      "[1600]\ttraining's amex: 0.885293\tvalid_0's amex: 0.793424\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.87297 (0.9598, 0.7862)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79389 (0.9242, 0.6636)\u001b[0m\n",
      "Clear cache 330\n",
      "[100]\ttraining's amex: 0.761011\tvalid_0's amex: 0.760235\n",
      "[200]\ttraining's amex: 0.780981\tvalid_0's amex: 0.77596\n",
      "[300]\ttraining's amex: 0.795331\tvalid_0's amex: 0.785189\n",
      "[400]\ttraining's amex: 0.805334\tvalid_0's amex: 0.789163\n",
      "[500]\ttraining's amex: 0.813412\tvalid_0's amex: 0.7914\n",
      "[600]\ttraining's amex: 0.820876\tvalid_0's amex: 0.792846\n",
      "[700]\ttraining's amex: 0.827602\tvalid_0's amex: 0.793431\n",
      "[800]\ttraining's amex: 0.834487\tvalid_0's amex: 0.794323\n",
      "[900]\ttraining's amex: 0.840937\tvalid_0's amex: 0.794735\n",
      "[1000]\ttraining's amex: 0.847487\tvalid_0's amex: 0.794634\n",
      "[1100]\ttraining's amex: 0.853666\tvalid_0's amex: 0.795267\n",
      "[1200]\ttraining's amex: 0.860434\tvalid_0's amex: 0.794947\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.85189 (0.9516, 0.7521)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79549 (0.9255, 0.6655)\u001b[0m\n",
      "Clear cache 16\n",
      "[100]\ttraining's amex: 0.762178\tvalid_0's amex: 0.759073\n",
      "[200]\ttraining's amex: 0.781043\tvalid_0's amex: 0.775358\n",
      "[300]\ttraining's amex: 0.794704\tvalid_0's amex: 0.785956\n",
      "[400]\ttraining's amex: 0.805014\tvalid_0's amex: 0.789955\n",
      "[500]\ttraining's amex: 0.813281\tvalid_0's amex: 0.792717\n",
      "[600]\ttraining's amex: 0.821203\tvalid_0's amex: 0.793561\n",
      "[700]\ttraining's amex: 0.828168\tvalid_0's amex: 0.794069\n",
      "[800]\ttraining's amex: 0.835018\tvalid_0's amex: 0.795291\n",
      "[900]\ttraining's amex: 0.841984\tvalid_0's amex: 0.795685\n",
      "[1000]\ttraining's amex: 0.848153\tvalid_0's amex: 0.795421\n",
      "[1100]\ttraining's amex: 0.854564\tvalid_0's amex: 0.795496\n",
      "[1200]\ttraining's amex: 0.860913\tvalid_0's amex: 0.796588\n",
      "[1300]\ttraining's amex: 0.867094\tvalid_0's amex: 0.796875\n",
      "[1400]\ttraining's amex: 0.873007\tvalid_0's amex: 0.796601\n",
      "[1500]\ttraining's amex: 0.879239\tvalid_0's amex: 0.795709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 11:11:20,784]\u001b[0m Trial 2 finished with value: 0.7941647404657786 and parameters: {'reg_alpha': 0.00682619040553603, 'reg_lambda': 16.321403614788384, 'colsample_bytree': 0.29268864791666566, 'subsample': 0.517669353938456, 'scale_pos_weight': 1.7687349931699574, 'num_leaves': 86}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.86871 (0.9582, 0.7792)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79681 (0.9251, 0.6685)\u001b[0m\n",
      "Clear cache 62\n",
      "alpha 0.0137 lambda 11.7739 colsample_bytree 0.206 subsample 0.654 scale_pos_weight 2.365 num_leaves 125\n",
      "[100]\ttraining's amex: 0.764747\tvalid_0's amex: 0.759451\n",
      "[200]\ttraining's amex: 0.784616\tvalid_0's amex: 0.775833\n",
      "[300]\ttraining's amex: 0.799183\tvalid_0's amex: 0.781822\n",
      "[400]\ttraining's amex: 0.810142\tvalid_0's amex: 0.787\n",
      "[500]\ttraining's amex: 0.819263\tvalid_0's amex: 0.789733\n",
      "[600]\ttraining's amex: 0.827637\tvalid_0's amex: 0.791632\n",
      "[700]\ttraining's amex: 0.835259\tvalid_0's amex: 0.791935\n",
      "[800]\ttraining's amex: 0.8431\tvalid_0's amex: 0.79251\n",
      "[900]\ttraining's amex: 0.851056\tvalid_0's amex: 0.792631\n",
      "[1000]\ttraining's amex: 0.858044\tvalid_0's amex: 0.792423\n",
      "[1100]\ttraining's amex: 0.865463\tvalid_0's amex: 0.792815\n",
      "[1200]\ttraining's amex: 0.872648\tvalid_0's amex: 0.792682\n",
      "[1300]\ttraining's amex: 0.879617\tvalid_0's amex: 0.792842\n",
      "[1400]\ttraining's amex: 0.886751\tvalid_0's amex: 0.793531\n",
      "[1500]\ttraining's amex: 0.893459\tvalid_0's amex: 0.794013\n",
      "[1600]\ttraining's amex: 0.900106\tvalid_0's amex: 0.792886\n",
      "[1700]\ttraining's amex: 0.906758\tvalid_0's amex: 0.793138\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.89518 (0.9697, 0.8207)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79403 (0.9230, 0.6651)\u001b[0m\n",
      "Clear cache 92\n",
      "[100]\ttraining's amex: 0.765335\tvalid_0's amex: 0.756824\n",
      "[200]\ttraining's amex: 0.785327\tvalid_0's amex: 0.771717\n",
      "[300]\ttraining's amex: 0.800175\tvalid_0's amex: 0.781342\n",
      "[400]\ttraining's amex: 0.810975\tvalid_0's amex: 0.786803\n",
      "[500]\ttraining's amex: 0.819807\tvalid_0's amex: 0.789078\n",
      "[600]\ttraining's amex: 0.828131\tvalid_0's amex: 0.790338\n",
      "[700]\ttraining's amex: 0.836506\tvalid_0's amex: 0.791167\n",
      "[800]\ttraining's amex: 0.84425\tvalid_0's amex: 0.790616\n",
      "[900]\ttraining's amex: 0.851905\tvalid_0's amex: 0.790953\n",
      "[1000]\ttraining's amex: 0.859638\tvalid_0's amex: 0.791624\n",
      "[1100]\ttraining's amex: 0.866713\tvalid_0's amex: 0.791939\n",
      "[1200]\ttraining's amex: 0.873335\tvalid_0's amex: 0.791566\n",
      "[1300]\ttraining's amex: 0.880208\tvalid_0's amex: 0.791716\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.86813 (0.9595, 0.7768)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79201 (0.9231, 0.6609)\u001b[0m\n",
      "Clear cache 33\n",
      "[100]\ttraining's amex: 0.764967\tvalid_0's amex: 0.76016\n",
      "[200]\ttraining's amex: 0.784804\tvalid_0's amex: 0.776866\n",
      "[300]\ttraining's amex: 0.800104\tvalid_0's amex: 0.78343\n",
      "[400]\ttraining's amex: 0.811491\tvalid_0's amex: 0.787223\n",
      "[500]\ttraining's amex: 0.820278\tvalid_0's amex: 0.789911\n",
      "[600]\ttraining's amex: 0.828181\tvalid_0's amex: 0.79076\n",
      "[700]\ttraining's amex: 0.835962\tvalid_0's amex: 0.791935\n",
      "[800]\ttraining's amex: 0.844067\tvalid_0's amex: 0.793142\n",
      "[900]\ttraining's amex: 0.851468\tvalid_0's amex: 0.793128\n",
      "[1000]\ttraining's amex: 0.858311\tvalid_0's amex: 0.793142\n",
      "[1100]\ttraining's amex: 0.865557\tvalid_0's amex: 0.793716\n",
      "[1200]\ttraining's amex: 0.872395\tvalid_0's amex: 0.793806\n",
      "[1300]\ttraining's amex: 0.879476\tvalid_0's amex: 0.794427\n",
      "[1400]\ttraining's amex: 0.886641\tvalid_0's amex: 0.794924\n",
      "[1500]\ttraining's amex: 0.893322\tvalid_0's amex: 0.7945\n",
      "[1600]\ttraining's amex: 0.900098\tvalid_0's amex: 0.794957\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.88778 (0.9671, 0.8085)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79502 (0.9246, 0.6654)\u001b[0m\n",
      "Clear cache 474\n",
      "[100]\ttraining's amex: 0.763595\tvalid_0's amex: 0.761511\n",
      "[200]\ttraining's amex: 0.784205\tvalid_0's amex: 0.77723\n",
      "[300]\ttraining's amex: 0.799189\tvalid_0's amex: 0.785019\n",
      "[400]\ttraining's amex: 0.81005\tvalid_0's amex: 0.789582\n",
      "[500]\ttraining's amex: 0.819447\tvalid_0's amex: 0.792385\n",
      "[600]\ttraining's amex: 0.827595\tvalid_0's amex: 0.793356\n",
      "[700]\ttraining's amex: 0.835204\tvalid_0's amex: 0.794801\n",
      "[800]\ttraining's amex: 0.842698\tvalid_0's amex: 0.794913\n",
      "[900]\ttraining's amex: 0.849908\tvalid_0's amex: 0.795758\n",
      "[1000]\ttraining's amex: 0.857965\tvalid_0's amex: 0.795874\n",
      "[1100]\ttraining's amex: 0.865585\tvalid_0's amex: 0.79597\n",
      "[1200]\ttraining's amex: 0.87274\tvalid_0's amex: 0.796127\n",
      "[1300]\ttraining's amex: 0.879606\tvalid_0's amex: 0.796343\n",
      "[1400]\ttraining's amex: 0.886748\tvalid_0's amex: 0.796902\n",
      "[1500]\ttraining's amex: 0.893528\tvalid_0's amex: 0.796315\n",
      "[1600]\ttraining's amex: 0.900286\tvalid_0's amex: 0.797672\n",
      "[1700]\ttraining's amex: 0.906905\tvalid_0's amex: 0.797413\n",
      "[1800]\ttraining's amex: 0.913637\tvalid_0's amex: 0.796453\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.90287 (0.9719, 0.8338)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79781 (0.9260, 0.6696)\u001b[0m\n",
      "Clear cache 10\n",
      "[100]\ttraining's amex: 0.763735\tvalid_0's amex: 0.760513\n",
      "[200]\ttraining's amex: 0.784031\tvalid_0's amex: 0.777539\n",
      "[300]\ttraining's amex: 0.798563\tvalid_0's amex: 0.786023\n",
      "[400]\ttraining's amex: 0.809813\tvalid_0's amex: 0.791024\n",
      "[500]\ttraining's amex: 0.818677\tvalid_0's amex: 0.794181\n",
      "[600]\ttraining's amex: 0.827389\tvalid_0's amex: 0.795061\n",
      "[700]\ttraining's amex: 0.835382\tvalid_0's amex: 0.794404\n",
      "[800]\ttraining's amex: 0.843475\tvalid_0's amex: 0.794886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 11:44:18,582]\u001b[0m Trial 3 finished with value: 0.7947849270640877 and parameters: {'reg_alpha': 0.013735943387196206, 'reg_lambda': 11.773907579038443, 'colsample_bytree': 0.20591222401921264, 'subsample': 0.6535906090218637, 'scale_pos_weight': 2.3648598908515357, 'num_leaves': 125}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.82949 (0.9428, 0.7162)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79505 (0.9243, 0.6658)\u001b[0m\n",
      "Clear cache 370\n",
      "alpha 0.0046 lambda 28.9785 colsample_bytree 0.286 subsample 0.533 scale_pos_weight 2.063 num_leaves 113\n",
      "[100]\ttraining's amex: 0.761444\tvalid_0's amex: 0.756014\n",
      "[200]\ttraining's amex: 0.78141\tvalid_0's amex: 0.77454\n",
      "[300]\ttraining's amex: 0.794781\tvalid_0's amex: 0.781001\n",
      "[400]\ttraining's amex: 0.804794\tvalid_0's amex: 0.785889\n",
      "[500]\ttraining's amex: 0.812371\tvalid_0's amex: 0.788406\n",
      "[600]\ttraining's amex: 0.819595\tvalid_0's amex: 0.790278\n",
      "[700]\ttraining's amex: 0.826395\tvalid_0's amex: 0.790462\n",
      "[800]\ttraining's amex: 0.832841\tvalid_0's amex: 0.790333\n",
      "[900]\ttraining's amex: 0.838439\tvalid_0's amex: 0.791262\n",
      "[1000]\ttraining's amex: 0.844922\tvalid_0's amex: 0.792056\n",
      "[1100]\ttraining's amex: 0.85101\tvalid_0's amex: 0.791943\n",
      "[1200]\ttraining's amex: 0.85678\tvalid_0's amex: 0.792484\n",
      "[1300]\ttraining's amex: 0.862908\tvalid_0's amex: 0.792737\n",
      "[1400]\ttraining's amex: 0.869353\tvalid_0's amex: 0.793868\n",
      "[1500]\ttraining's amex: 0.8751\tvalid_0's amex: 0.79376\n",
      "[1600]\ttraining's amex: 0.880478\tvalid_0's amex: 0.793556\n",
      "[1700]\ttraining's amex: 0.88621\tvalid_0's amex: 0.793092\n",
      "[1800]\ttraining's amex: 0.891476\tvalid_0's amex: 0.792824\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.88182 (0.9638, 0.7998)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79407 (0.9226, 0.6655)\u001b[0m\n",
      "Clear cache 440\n",
      "[100]\ttraining's amex: 0.762299\tvalid_0's amex: 0.75494\n",
      "[200]\ttraining's amex: 0.781762\tvalid_0's amex: 0.770604\n",
      "[300]\ttraining's amex: 0.795958\tvalid_0's amex: 0.77978\n",
      "[400]\ttraining's amex: 0.805634\tvalid_0's amex: 0.785496\n",
      "[500]\ttraining's amex: 0.812962\tvalid_0's amex: 0.787617\n",
      "[600]\ttraining's amex: 0.819949\tvalid_0's amex: 0.789345\n",
      "[700]\ttraining's amex: 0.827042\tvalid_0's amex: 0.789788\n",
      "[800]\ttraining's amex: 0.833594\tvalid_0's amex: 0.791095\n",
      "[900]\ttraining's amex: 0.839529\tvalid_0's amex: 0.790422\n",
      "[1000]\ttraining's amex: 0.845617\tvalid_0's amex: 0.791186\n",
      "[1100]\ttraining's amex: 0.851931\tvalid_0's amex: 0.792152\n",
      "[1200]\ttraining's amex: 0.858015\tvalid_0's amex: 0.791876\n",
      "[1300]\ttraining's amex: 0.86369\tvalid_0's amex: 0.791653\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.85460 (0.9531, 0.7561)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79262 (0.9231, 0.6621)\u001b[0m\n",
      "Clear cache 100\n",
      "[100]\ttraining's amex: 0.761692\tvalid_0's amex: 0.759642\n",
      "[200]\ttraining's amex: 0.781794\tvalid_0's amex: 0.775309\n",
      "[300]\ttraining's amex: 0.796052\tvalid_0's amex: 0.781481\n",
      "[400]\ttraining's amex: 0.805344\tvalid_0's amex: 0.785956\n",
      "[500]\ttraining's amex: 0.812997\tvalid_0's amex: 0.788017\n",
      "[600]\ttraining's amex: 0.820015\tvalid_0's amex: 0.789464\n",
      "[700]\ttraining's amex: 0.826673\tvalid_0's amex: 0.790681\n",
      "[800]\ttraining's amex: 0.833341\tvalid_0's amex: 0.790885\n",
      "[900]\ttraining's amex: 0.839173\tvalid_0's amex: 0.790305\n",
      "[1000]\ttraining's amex: 0.845376\tvalid_0's amex: 0.79078\n",
      "[1100]\ttraining's amex: 0.851316\tvalid_0's amex: 0.791238\n",
      "[1200]\ttraining's amex: 0.857481\tvalid_0's amex: 0.79212\n",
      "[1300]\ttraining's amex: 0.863368\tvalid_0's amex: 0.792189\n",
      "[1400]\ttraining's amex: 0.868912\tvalid_0's amex: 0.793365\n",
      "[1500]\ttraining's amex: 0.87453\tvalid_0's amex: 0.793055\n",
      "[1600]\ttraining's amex: 0.880239\tvalid_0's amex: 0.793179\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.87032 (0.9595, 0.7811)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79344 (0.9243, 0.6626)\u001b[0m\n",
      "Clear cache 458\n",
      "[100]\ttraining's amex: 0.760914\tvalid_0's amex: 0.760355\n",
      "[200]\ttraining's amex: 0.780609\tvalid_0's amex: 0.776717\n",
      "[300]\ttraining's amex: 0.794012\tvalid_0's amex: 0.783838\n",
      "[400]\ttraining's amex: 0.804368\tvalid_0's amex: 0.788906\n",
      "[500]\ttraining's amex: 0.812726\tvalid_0's amex: 0.791259\n",
      "[600]\ttraining's amex: 0.819491\tvalid_0's amex: 0.791891\n",
      "[700]\ttraining's amex: 0.826065\tvalid_0's amex: 0.793022\n",
      "[800]\ttraining's amex: 0.832964\tvalid_0's amex: 0.793688\n",
      "[900]\ttraining's amex: 0.838959\tvalid_0's amex: 0.794318\n",
      "[1000]\ttraining's amex: 0.84508\tvalid_0's amex: 0.794534\n",
      "[1100]\ttraining's amex: 0.850753\tvalid_0's amex: 0.794739\n",
      "[1200]\ttraining's amex: 0.856515\tvalid_0's amex: 0.795101\n",
      "[1300]\ttraining's amex: 0.862471\tvalid_0's amex: 0.795568\n",
      "[1400]\ttraining's amex: 0.868422\tvalid_0's amex: 0.795517\n",
      "[1500]\ttraining's amex: 0.874206\tvalid_0's amex: 0.795413\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.86549 (0.9578, 0.7731)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79585 (0.9256, 0.6661)\u001b[0m\n",
      "Clear cache 160\n",
      "[100]\ttraining's amex: 0.760307\tvalid_0's amex: 0.758118\n",
      "[200]\ttraining's amex: 0.780336\tvalid_0's amex: 0.775448\n",
      "[300]\ttraining's amex: 0.793641\tvalid_0's amex: 0.785581\n",
      "[400]\ttraining's amex: 0.803716\tvalid_0's amex: 0.790384\n",
      "[500]\ttraining's amex: 0.811589\tvalid_0's amex: 0.793062\n",
      "[600]\ttraining's amex: 0.818668\tvalid_0's amex: 0.794941\n",
      "[700]\ttraining's amex: 0.825545\tvalid_0's amex: 0.794659\n",
      "[800]\ttraining's amex: 0.832236\tvalid_0's amex: 0.796354\n",
      "[900]\ttraining's amex: 0.839325\tvalid_0's amex: 0.79656\n",
      "[1000]\ttraining's amex: 0.84537\tvalid_0's amex: 0.79672\n",
      "[1100]\ttraining's amex: 0.851355\tvalid_0's amex: 0.796467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 12:20:57,433]\u001b[0m Trial 4 finished with value: 0.7945693962572338 and parameters: {'reg_alpha': 0.004561843324945278, 'reg_lambda': 28.97846402858729, 'colsample_bytree': 0.2862883530798857, 'subsample': 0.5328527199528147, 'scale_pos_weight': 2.062590043199485, 'num_leaves': 113}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.84290 (0.9482, 0.7376)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79687 (0.9250, 0.6688)\u001b[0m\n",
      "Clear cache 146\n",
      "alpha 0.0247 lambda 24.8331 colsample_bytree 0.215 subsample 0.58 scale_pos_weight 1.611 num_leaves 85\n",
      "[100]\ttraining's amex: 0.763307\tvalid_0's amex: 0.757896\n",
      "[200]\ttraining's amex: 0.782223\tvalid_0's amex: 0.772897\n",
      "[300]\ttraining's amex: 0.796568\tvalid_0's amex: 0.781668\n",
      "[400]\ttraining's amex: 0.806858\tvalid_0's amex: 0.786136\n",
      "[500]\ttraining's amex: 0.815187\tvalid_0's amex: 0.787867\n",
      "[600]\ttraining's amex: 0.822889\tvalid_0's amex: 0.789965\n",
      "[700]\ttraining's amex: 0.829943\tvalid_0's amex: 0.791375\n",
      "[800]\ttraining's amex: 0.836885\tvalid_0's amex: 0.792368\n",
      "[900]\ttraining's amex: 0.843627\tvalid_0's amex: 0.79256\n",
      "[1000]\ttraining's amex: 0.850511\tvalid_0's amex: 0.791386\n",
      "[1100]\ttraining's amex: 0.857509\tvalid_0's amex: 0.792898\n",
      "[1200]\ttraining's amex: 0.86391\tvalid_0's amex: 0.792716\n",
      "[1300]\ttraining's amex: 0.870364\tvalid_0's amex: 0.792939\n",
      "[1400]\ttraining's amex: 0.876794\tvalid_0's amex: 0.792442\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.86756 (0.9575, 0.7776)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79289 (0.9227, 0.6631)\u001b[0m\n",
      "Clear cache 20\n",
      "[100]\ttraining's amex: 0.763573\tvalid_0's amex: 0.756136\n",
      "[200]\ttraining's amex: 0.783025\tvalid_0's amex: 0.77085\n",
      "[300]\ttraining's amex: 0.796937\tvalid_0's amex: 0.78003\n",
      "[400]\ttraining's amex: 0.807253\tvalid_0's amex: 0.784202\n",
      "[500]\ttraining's amex: 0.815438\tvalid_0's amex: 0.786979\n",
      "[600]\ttraining's amex: 0.822934\tvalid_0's amex: 0.788515\n",
      "[700]\ttraining's amex: 0.830637\tvalid_0's amex: 0.78915\n",
      "[800]\ttraining's amex: 0.838236\tvalid_0's amex: 0.790092\n",
      "[900]\ttraining's amex: 0.845063\tvalid_0's amex: 0.790388\n",
      "[1000]\ttraining's amex: 0.851392\tvalid_0's amex: 0.791296\n",
      "[1100]\ttraining's amex: 0.858015\tvalid_0's amex: 0.79139\n",
      "[1200]\ttraining's amex: 0.864736\tvalid_0's amex: 0.790599\n",
      "[1300]\ttraining's amex: 0.871249\tvalid_0's amex: 0.791294\n",
      "[1400]\ttraining's amex: 0.876998\tvalid_0's amex: 0.79181\n",
      "[1500]\ttraining's amex: 0.883143\tvalid_0's amex: 0.792119\n",
      "[1600]\ttraining's amex: 0.88837\tvalid_0's amex: 0.792295\n",
      "[1700]\ttraining's amex: 0.894744\tvalid_0's amex: 0.791685\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.88635 (0.9644, 0.8083)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79256 (0.9233, 0.6618)\u001b[0m\n",
      "Clear cache 216\n",
      "[100]\ttraining's amex: 0.763539\tvalid_0's amex: 0.760878\n",
      "[200]\ttraining's amex: 0.782766\tvalid_0's amex: 0.776039\n",
      "[300]\ttraining's amex: 0.797122\tvalid_0's amex: 0.783145\n",
      "[400]\ttraining's amex: 0.807378\tvalid_0's amex: 0.786299\n",
      "[500]\ttraining's amex: 0.815724\tvalid_0's amex: 0.789227\n",
      "[600]\ttraining's amex: 0.823535\tvalid_0's amex: 0.790829\n",
      "[700]\ttraining's amex: 0.830934\tvalid_0's amex: 0.791477\n",
      "[800]\ttraining's amex: 0.837962\tvalid_0's amex: 0.792193\n",
      "[900]\ttraining's amex: 0.84518\tvalid_0's amex: 0.793332\n",
      "[1000]\ttraining's amex: 0.851791\tvalid_0's amex: 0.794177\n",
      "[1100]\ttraining's amex: 0.858176\tvalid_0's amex: 0.794605\n",
      "[1200]\ttraining's amex: 0.864353\tvalid_0's amex: 0.794956\n",
      "[1300]\ttraining's amex: 0.870593\tvalid_0's amex: 0.794852\n",
      "[1400]\ttraining's amex: 0.876753\tvalid_0's amex: 0.794951\n",
      "[1500]\ttraining's amex: 0.882969\tvalid_0's amex: 0.796156\n",
      "[1600]\ttraining's amex: 0.889194\tvalid_0's amex: 0.795545\n",
      "[1700]\ttraining's amex: 0.895127\tvalid_0's amex: 0.795277\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.88459 (0.9636, 0.8055)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79592 (0.9245, 0.6673)\u001b[0m\n",
      "Clear cache 116\n",
      "[100]\ttraining's amex: 0.76335\tvalid_0's amex: 0.761968\n",
      "[200]\ttraining's amex: 0.781348\tvalid_0's amex: 0.776324\n",
      "[300]\ttraining's amex: 0.79605\tvalid_0's amex: 0.784428\n",
      "[400]\ttraining's amex: 0.806845\tvalid_0's amex: 0.788602\n",
      "[500]\ttraining's amex: 0.815292\tvalid_0's amex: 0.791245\n",
      "[600]\ttraining's amex: 0.822629\tvalid_0's amex: 0.793334\n",
      "[700]\ttraining's amex: 0.829229\tvalid_0's amex: 0.794463\n",
      "[800]\ttraining's amex: 0.836574\tvalid_0's amex: 0.794987\n",
      "[900]\ttraining's amex: 0.843392\tvalid_0's amex: 0.795417\n",
      "[1000]\ttraining's amex: 0.849758\tvalid_0's amex: 0.795663\n",
      "[1100]\ttraining's amex: 0.856596\tvalid_0's amex: 0.796021\n",
      "[1200]\ttraining's amex: 0.863392\tvalid_0's amex: 0.796404\n",
      "[1300]\ttraining's amex: 0.870011\tvalid_0's amex: 0.796272\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.86096 (0.9549, 0.7670)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79695 (0.9258, 0.6681)\u001b[0m\n",
      "Clear cache 204\n",
      "[100]\ttraining's amex: 0.762755\tvalid_0's amex: 0.759547\n",
      "[200]\ttraining's amex: 0.782028\tvalid_0's amex: 0.776624\n",
      "[300]\ttraining's amex: 0.796\tvalid_0's amex: 0.785738\n",
      "[400]\ttraining's amex: 0.805846\tvalid_0's amex: 0.790119\n",
      "[500]\ttraining's amex: 0.814371\tvalid_0's amex: 0.793174\n",
      "[600]\ttraining's amex: 0.821946\tvalid_0's amex: 0.794818\n",
      "[700]\ttraining's amex: 0.82986\tvalid_0's amex: 0.794898\n",
      "[800]\ttraining's amex: 0.836577\tvalid_0's amex: 0.795274\n",
      "[900]\ttraining's amex: 0.843616\tvalid_0's amex: 0.795831\n",
      "[1000]\ttraining's amex: 0.850647\tvalid_0's amex: 0.796179\n",
      "[1100]\ttraining's amex: 0.857945\tvalid_0's amex: 0.796372\n",
      "[1200]\ttraining's amex: 0.864456\tvalid_0's amex: 0.796433\n",
      "[1300]\ttraining's amex: 0.870591\tvalid_0's amex: 0.796418\n",
      "[1400]\ttraining's amex: 0.87683\tvalid_0's amex: 0.796668\n",
      "[1500]\ttraining's amex: 0.883235\tvalid_0's amex: 0.796724\n",
      "[1600]\ttraining's amex: 0.889246\tvalid_0's amex: 0.796916\n",
      "[1700]\ttraining's amex: 0.895333\tvalid_0's amex: 0.796518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 12:57:20,919]\u001b[0m Trial 5 finished with value: 0.7950933487679958 and parameters: {'reg_alpha': 0.024673524959861647, 'reg_lambda': 24.83313476698991, 'colsample_bytree': 0.21450030795596026, 'subsample': 0.5803171852926325, 'scale_pos_weight': 1.6106469264772851, 'num_leaves': 85}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.88577 (0.9639, 0.8076)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79715 (0.9253, 0.6690)\u001b[0m\n",
      "Clear cache 172\n",
      "alpha 0.004 lambda 15.3616 colsample_bytree 0.288 subsample 0.574 scale_pos_weight 1.747 num_leaves 87\n",
      "[100]\ttraining's amex: 0.764517\tvalid_0's amex: 0.758766\n",
      "[200]\ttraining's amex: 0.783273\tvalid_0's amex: 0.774545\n",
      "[300]\ttraining's amex: 0.797446\tvalid_0's amex: 0.781992\n",
      "[400]\ttraining's amex: 0.808416\tvalid_0's amex: 0.786469\n",
      "[500]\ttraining's amex: 0.817394\tvalid_0's amex: 0.788423\n",
      "[600]\ttraining's amex: 0.825256\tvalid_0's amex: 0.790768\n",
      "[700]\ttraining's amex: 0.832682\tvalid_0's amex: 0.791839\n",
      "[800]\ttraining's amex: 0.84014\tvalid_0's amex: 0.792269\n",
      "[900]\ttraining's amex: 0.847649\tvalid_0's amex: 0.791807\n",
      "[1000]\ttraining's amex: 0.855093\tvalid_0's amex: 0.79315\n",
      "[1100]\ttraining's amex: 0.862168\tvalid_0's amex: 0.791887\n",
      "[1200]\ttraining's amex: 0.869264\tvalid_0's amex: 0.79245\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.85669 (0.9537, 0.7596)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79291 (0.9225, 0.6633)\u001b[0m\n",
      "Clear cache 408\n",
      "[100]\ttraining's amex: 0.765172\tvalid_0's amex: 0.756544\n",
      "[200]\ttraining's amex: 0.784486\tvalid_0's amex: 0.771367\n",
      "[300]\ttraining's amex: 0.798662\tvalid_0's amex: 0.779925\n",
      "[400]\ttraining's amex: 0.809411\tvalid_0's amex: 0.786616\n",
      "[500]\ttraining's amex: 0.817585\tvalid_0's amex: 0.788869\n",
      "[600]\ttraining's amex: 0.825629\tvalid_0's amex: 0.789964\n",
      "[700]\ttraining's amex: 0.832633\tvalid_0's amex: 0.790745\n",
      "[800]\ttraining's amex: 0.840435\tvalid_0's amex: 0.791407\n",
      "[900]\ttraining's amex: 0.847978\tvalid_0's amex: 0.791945\n",
      "[1000]\ttraining's amex: 0.855708\tvalid_0's amex: 0.791595\n",
      "[1100]\ttraining's amex: 0.86276\tvalid_0's amex: 0.791615\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.85228 (0.9517, 0.7529)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79226 (0.9228, 0.6617)\u001b[0m\n",
      "Clear cache 142\n",
      "[100]\ttraining's amex: 0.763667\tvalid_0's amex: 0.760388\n",
      "[200]\ttraining's amex: 0.78388\tvalid_0's amex: 0.775979\n",
      "[300]\ttraining's amex: 0.797839\tvalid_0's amex: 0.782617\n",
      "[400]\ttraining's amex: 0.808781\tvalid_0's amex: 0.786967\n",
      "[500]\ttraining's amex: 0.817402\tvalid_0's amex: 0.788403\n",
      "[600]\ttraining's amex: 0.826013\tvalid_0's amex: 0.789918\n",
      "[700]\ttraining's amex: 0.83312\tvalid_0's amex: 0.790587\n",
      "[800]\ttraining's amex: 0.841164\tvalid_0's amex: 0.792351\n",
      "[900]\ttraining's amex: 0.848409\tvalid_0's amex: 0.792462\n",
      "[1000]\ttraining's amex: 0.855261\tvalid_0's amex: 0.792916\n",
      "[1100]\ttraining's amex: 0.861888\tvalid_0's amex: 0.793707\n",
      "[1200]\ttraining's amex: 0.868953\tvalid_0's amex: 0.793995\n",
      "[1300]\ttraining's amex: 0.87552\tvalid_0's amex: 0.794146\n",
      "[1400]\ttraining's amex: 0.881887\tvalid_0's amex: 0.793796\n",
      "[1500]\ttraining's amex: 0.888512\tvalid_0's amex: 0.793967\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.87593 (0.9610, 0.7908)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79411 (0.9241, 0.6641)\u001b[0m\n",
      "Clear cache 18\n",
      "[100]\ttraining's amex: 0.762709\tvalid_0's amex: 0.761217\n",
      "[200]\ttraining's amex: 0.783116\tvalid_0's amex: 0.77742\n",
      "[300]\ttraining's amex: 0.797526\tvalid_0's amex: 0.785987\n",
      "[400]\ttraining's amex: 0.808196\tvalid_0's amex: 0.790408\n",
      "[500]\ttraining's amex: 0.816873\tvalid_0's amex: 0.79254\n",
      "[600]\ttraining's amex: 0.825106\tvalid_0's amex: 0.794137\n",
      "[700]\ttraining's amex: 0.832293\tvalid_0's amex: 0.794994\n",
      "[800]\ttraining's amex: 0.839349\tvalid_0's amex: 0.795507\n",
      "[900]\ttraining's amex: 0.846502\tvalid_0's amex: 0.795907\n",
      "[1000]\ttraining's amex: 0.854352\tvalid_0's amex: 0.796203\n",
      "[1100]\ttraining's amex: 0.861394\tvalid_0's amex: 0.795807\n",
      "[1200]\ttraining's amex: 0.868476\tvalid_0's amex: 0.796617\n",
      "[1300]\ttraining's amex: 0.87522\tvalid_0's amex: 0.796699\n",
      "[1400]\ttraining's amex: 0.882024\tvalid_0's amex: 0.796503\n",
      "[1500]\ttraining's amex: 0.888574\tvalid_0's amex: 0.796731\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.87626 (0.9612, 0.7913)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79692 (0.9256, 0.6682)\u001b[0m\n",
      "Clear cache 38\n",
      "[100]\ttraining's amex: 0.762811\tvalid_0's amex: 0.760379\n",
      "[200]\ttraining's amex: 0.782606\tvalid_0's amex: 0.776773\n",
      "[300]\ttraining's amex: 0.796558\tvalid_0's amex: 0.786288\n",
      "[400]\ttraining's amex: 0.807477\tvalid_0's amex: 0.790022\n",
      "[500]\ttraining's amex: 0.817089\tvalid_0's amex: 0.792454\n",
      "[600]\ttraining's amex: 0.825074\tvalid_0's amex: 0.794214\n",
      "[700]\ttraining's amex: 0.832628\tvalid_0's amex: 0.794495\n",
      "[800]\ttraining's amex: 0.839902\tvalid_0's amex: 0.795292\n",
      "[900]\ttraining's amex: 0.847095\tvalid_0's amex: 0.795556\n",
      "[1000]\ttraining's amex: 0.854149\tvalid_0's amex: 0.795624\n",
      "[1100]\ttraining's amex: 0.861019\tvalid_0's amex: 0.796263\n",
      "[1200]\ttraining's amex: 0.86817\tvalid_0's amex: 0.796588\n",
      "[1300]\ttraining's amex: 0.875018\tvalid_0's amex: 0.795931\n",
      "[1400]\ttraining's amex: 0.881515\tvalid_0's amex: 0.795868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 13:33:24,908]\u001b[0m Trial 6 finished with value: 0.7946046446904111 and parameters: {'reg_alpha': 0.003956261404348788, 'reg_lambda': 15.361582230447409, 'colsample_bytree': 0.2881080603651867, 'subsample': 0.5744499164596265, 'scale_pos_weight': 1.7472675568959946, 'num_leaves': 87}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.86923 (0.9587, 0.7798)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79682 (0.9253, 0.6684)\u001b[0m\n",
      "Clear cache 406\n",
      "alpha 0.0906 lambda 23.2388 colsample_bytree 0.24 subsample 0.67 scale_pos_weight 2.214 num_leaves 91\n",
      "[100]\ttraining's amex: 0.76486\tvalid_0's amex: 0.758656\n",
      "[200]\ttraining's amex: 0.784486\tvalid_0's amex: 0.775373\n",
      "[300]\ttraining's amex: 0.79897\tvalid_0's amex: 0.78361\n",
      "[400]\ttraining's amex: 0.809585\tvalid_0's amex: 0.787436\n",
      "[500]\ttraining's amex: 0.819161\tvalid_0's amex: 0.789376\n",
      "[600]\ttraining's amex: 0.827116\tvalid_0's amex: 0.790933\n",
      "[700]\ttraining's amex: 0.834823\tvalid_0's amex: 0.79156\n",
      "[800]\ttraining's amex: 0.842661\tvalid_0's amex: 0.792644\n",
      "[900]\ttraining's amex: 0.849972\tvalid_0's amex: 0.792668\n",
      "[1000]\ttraining's amex: 0.857163\tvalid_0's amex: 0.793016\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.84787 (0.9510, 0.7447)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79332 (0.9225, 0.6641)\u001b[0m\n",
      "Clear cache 16\n",
      "[100]\ttraining's amex: 0.765272\tvalid_0's amex: 0.756478\n",
      "[200]\ttraining's amex: 0.785428\tvalid_0's amex: 0.772386\n",
      "[300]\ttraining's amex: 0.800537\tvalid_0's amex: 0.782525\n",
      "[400]\ttraining's amex: 0.810709\tvalid_0's amex: 0.787502\n",
      "[500]\ttraining's amex: 0.819277\tvalid_0's amex: 0.78947\n",
      "[600]\ttraining's amex: 0.828051\tvalid_0's amex: 0.790294\n",
      "[700]\ttraining's amex: 0.836286\tvalid_0's amex: 0.791603\n",
      "[800]\ttraining's amex: 0.843499\tvalid_0's amex: 0.791619\n",
      "[900]\ttraining's amex: 0.851105\tvalid_0's amex: 0.791536\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.83864 (0.9464, 0.7309)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79182 (0.9225, 0.6611)\u001b[0m\n",
      "Clear cache 31\n",
      "[100]\ttraining's amex: 0.764382\tvalid_0's amex: 0.760354\n",
      "[200]\ttraining's amex: 0.785019\tvalid_0's amex: 0.776408\n",
      "[300]\ttraining's amex: 0.800077\tvalid_0's amex: 0.78332\n",
      "[400]\ttraining's amex: 0.810535\tvalid_0's amex: 0.786856\n",
      "[500]\ttraining's amex: 0.819597\tvalid_0's amex: 0.788541\n",
      "[600]\ttraining's amex: 0.828072\tvalid_0's amex: 0.791164\n",
      "[700]\ttraining's amex: 0.835422\tvalid_0's amex: 0.791688\n",
      "[800]\ttraining's amex: 0.843197\tvalid_0's amex: 0.792123\n",
      "[900]\ttraining's amex: 0.851126\tvalid_0's amex: 0.793194\n",
      "[1000]\ttraining's amex: 0.857893\tvalid_0's amex: 0.793001\n",
      "[1100]\ttraining's amex: 0.864816\tvalid_0's amex: 0.793422\n",
      "[1200]\ttraining's amex: 0.872323\tvalid_0's amex: 0.793839\n",
      "[1300]\ttraining's amex: 0.879046\tvalid_0's amex: 0.794284\n",
      "[1400]\ttraining's amex: 0.885925\tvalid_0's amex: 0.794151\n",
      "[1500]\ttraining's amex: 0.892713\tvalid_0's amex: 0.794033\n",
      "[1600]\ttraining's amex: 0.898838\tvalid_0's amex: 0.794752\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.88946 (0.9670, 0.8119)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79472 (0.9245, 0.6649)\u001b[0m\n",
      "Clear cache 8\n",
      "[100]\ttraining's amex: 0.763898\tvalid_0's amex: 0.762587\n",
      "[200]\ttraining's amex: 0.784268\tvalid_0's amex: 0.777778\n",
      "[300]\ttraining's amex: 0.799211\tvalid_0's amex: 0.785709\n",
      "[400]\ttraining's amex: 0.810066\tvalid_0's amex: 0.789236\n",
      "[500]\ttraining's amex: 0.819165\tvalid_0's amex: 0.791748\n",
      "[600]\ttraining's amex: 0.827094\tvalid_0's amex: 0.792664\n",
      "[700]\ttraining's amex: 0.834697\tvalid_0's amex: 0.793989\n",
      "[800]\ttraining's amex: 0.842247\tvalid_0's amex: 0.794236\n",
      "[900]\ttraining's amex: 0.849602\tvalid_0's amex: 0.79444\n",
      "[1000]\ttraining's amex: 0.857024\tvalid_0's amex: 0.795489\n",
      "[1100]\ttraining's amex: 0.864155\tvalid_0's amex: 0.796372\n",
      "[1200]\ttraining's amex: 0.871457\tvalid_0's amex: 0.79667\n",
      "[1300]\ttraining's amex: 0.878745\tvalid_0's amex: 0.79745\n",
      "[1400]\ttraining's amex: 0.885471\tvalid_0's amex: 0.796749\n",
      "[1500]\ttraining's amex: 0.892331\tvalid_0's amex: 0.797324\n",
      "[1600]\ttraining's amex: 0.898878\tvalid_0's amex: 0.797604\n",
      "[1700]\ttraining's amex: 0.905377\tvalid_0's amex: 0.797394\n",
      "[1800]\ttraining's amex: 0.911765\tvalid_0's amex: 0.797707\n",
      "[1900]\ttraining's amex: 0.918287\tvalid_0's amex: 0.797088\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.90496 (0.9721, 0.8379)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79793 (0.9261, 0.6697)\u001b[0m\n",
      "Clear cache 10\n",
      "[100]\ttraining's amex: 0.764326\tvalid_0's amex: 0.760624\n",
      "[200]\ttraining's amex: 0.784087\tvalid_0's amex: 0.777854\n",
      "[300]\ttraining's amex: 0.799292\tvalid_0's amex: 0.787389\n",
      "[400]\ttraining's amex: 0.809067\tvalid_0's amex: 0.791683\n",
      "[500]\ttraining's amex: 0.818472\tvalid_0's amex: 0.793644\n",
      "[600]\ttraining's amex: 0.827085\tvalid_0's amex: 0.795581\n",
      "[700]\ttraining's amex: 0.834794\tvalid_0's amex: 0.796085\n",
      "[800]\ttraining's amex: 0.842738\tvalid_0's amex: 0.795182\n",
      "[900]\ttraining's amex: 0.850361\tvalid_0's amex: 0.795819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 14:07:45,064]\u001b[0m Trial 7 finished with value: 0.794781581802604 and parameters: {'reg_alpha': 0.09064779843182409, 'reg_lambda': 23.238802372290184, 'colsample_bytree': 0.2399693344584639, 'subsample': 0.67032329788918, 'scale_pos_weight': 2.2143401491534527, 'num_leaves': 91}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.83616 (0.9455, 0.7268)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79612 (0.9247, 0.6675)\u001b[0m\n",
      "Clear cache 12\n",
      "alpha 0.0019 lambda 26.293 colsample_bytree 0.258 subsample 0.508 scale_pos_weight 1.593 num_leaves 78\n",
      "[100]\ttraining's amex: 0.762207\tvalid_0's amex: 0.756702\n",
      "[200]\ttraining's amex: 0.7809\tvalid_0's amex: 0.77323\n",
      "[300]\ttraining's amex: 0.793991\tvalid_0's amex: 0.781333\n",
      "[400]\ttraining's amex: 0.803712\tvalid_0's amex: 0.786247\n",
      "[500]\ttraining's amex: 0.811843\tvalid_0's amex: 0.788127\n",
      "[600]\ttraining's amex: 0.819585\tvalid_0's amex: 0.790437\n",
      "[700]\ttraining's amex: 0.825945\tvalid_0's amex: 0.791287\n",
      "[800]\ttraining's amex: 0.831931\tvalid_0's amex: 0.791892\n",
      "[900]\ttraining's amex: 0.838181\tvalid_0's amex: 0.792329\n",
      "[1000]\ttraining's amex: 0.844235\tvalid_0's amex: 0.792594\n",
      "[1100]\ttraining's amex: 0.850409\tvalid_0's amex: 0.792704\n",
      "[1200]\ttraining's amex: 0.856383\tvalid_0's amex: 0.791958\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.84441 (0.9482, 0.7407)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79304 (0.9223, 0.6638)\u001b[0m\n",
      "Clear cache 316\n",
      "[100]\ttraining's amex: 0.76227\tvalid_0's amex: 0.755344\n",
      "[200]\ttraining's amex: 0.781767\tvalid_0's amex: 0.77073\n",
      "[300]\ttraining's amex: 0.795207\tvalid_0's amex: 0.779475\n",
      "[400]\ttraining's amex: 0.805436\tvalid_0's amex: 0.784783\n",
      "[500]\ttraining's amex: 0.812846\tvalid_0's amex: 0.788165\n",
      "[600]\ttraining's amex: 0.819836\tvalid_0's amex: 0.789466\n",
      "[700]\ttraining's amex: 0.826679\tvalid_0's amex: 0.790045\n",
      "[800]\ttraining's amex: 0.832876\tvalid_0's amex: 0.790279\n",
      "[900]\ttraining's amex: 0.839389\tvalid_0's amex: 0.790172\n",
      "[1000]\ttraining's amex: 0.845657\tvalid_0's amex: 0.790257\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.83338 (0.9430, 0.7238)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79065 (0.9225, 0.6588)\u001b[0m\n",
      "Clear cache 312\n",
      "[100]\ttraining's amex: 0.762231\tvalid_0's amex: 0.759322\n",
      "[200]\ttraining's amex: 0.780616\tvalid_0's amex: 0.774673\n",
      "[300]\ttraining's amex: 0.795043\tvalid_0's amex: 0.782393\n",
      "[400]\ttraining's amex: 0.804648\tvalid_0's amex: 0.786\n",
      "[500]\ttraining's amex: 0.812911\tvalid_0's amex: 0.78905\n",
      "[600]\ttraining's amex: 0.820163\tvalid_0's amex: 0.788812\n",
      "[700]\ttraining's amex: 0.826735\tvalid_0's amex: 0.790912\n",
      "[800]\ttraining's amex: 0.833026\tvalid_0's amex: 0.792128\n",
      "[900]\ttraining's amex: 0.839026\tvalid_0's amex: 0.791934\n",
      "[1000]\ttraining's amex: 0.845101\tvalid_0's amex: 0.792483\n",
      "[1100]\ttraining's amex: 0.850972\tvalid_0's amex: 0.791965\n",
      "[1200]\ttraining's amex: 0.856902\tvalid_0's amex: 0.793438\n",
      "[1300]\ttraining's amex: 0.862552\tvalid_0's amex: 0.793032\n",
      "[1400]\ttraining's amex: 0.867975\tvalid_0's amex: 0.793762\n",
      "[1500]\ttraining's amex: 0.873811\tvalid_0's amex: 0.79339\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.86618 (0.9566, 0.7757)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79397 (0.9243, 0.6636)\u001b[0m\n",
      "Clear cache 242\n",
      "[100]\ttraining's amex: 0.76108\tvalid_0's amex: 0.759881\n",
      "[200]\ttraining's amex: 0.779902\tvalid_0's amex: 0.774649\n",
      "[300]\ttraining's amex: 0.793671\tvalid_0's amex: 0.78438\n",
      "[400]\ttraining's amex: 0.803563\tvalid_0's amex: 0.788868\n",
      "[500]\ttraining's amex: 0.811814\tvalid_0's amex: 0.791232\n",
      "[600]\ttraining's amex: 0.819311\tvalid_0's amex: 0.792289\n",
      "[700]\ttraining's amex: 0.825506\tvalid_0's amex: 0.792411\n",
      "[800]\ttraining's amex: 0.831971\tvalid_0's amex: 0.79299\n",
      "[900]\ttraining's amex: 0.838308\tvalid_0's amex: 0.793854\n",
      "[1000]\ttraining's amex: 0.844235\tvalid_0's amex: 0.79411\n",
      "[1100]\ttraining's amex: 0.850649\tvalid_0's amex: 0.793731\n",
      "[1200]\ttraining's amex: 0.856577\tvalid_0's amex: 0.794741\n",
      "[1300]\ttraining's amex: 0.863093\tvalid_0's amex: 0.794491\n",
      "[1400]\ttraining's amex: 0.868632\tvalid_0's amex: 0.79506\n",
      "[1500]\ttraining's amex: 0.874636\tvalid_0's amex: 0.795535\n",
      "[1600]\ttraining's amex: 0.879935\tvalid_0's amex: 0.795916\n",
      "[1700]\ttraining's amex: 0.88515\tvalid_0's amex: 0.795696\n",
      "[1800]\ttraining's amex: 0.890174\tvalid_0's amex: 0.795918\n",
      "[1900]\ttraining's amex: 0.89492\tvalid_0's amex: 0.795856\n",
      "[2000]\ttraining's amex: 0.900596\tvalid_0's amex: 0.796622\n",
      "[2100]\ttraining's amex: 0.905757\tvalid_0's amex: 0.796293\n",
      "[2200]\ttraining's amex: 0.910801\tvalid_0's amex: 0.796372\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.90114 (0.9692, 0.8331)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79644 (0.9258, 0.6670)\u001b[0m\n",
      "Clear cache 472\n",
      "[100]\ttraining's amex: 0.761381\tvalid_0's amex: 0.759813\n",
      "[200]\ttraining's amex: 0.780001\tvalid_0's amex: 0.774763\n",
      "[300]\ttraining's amex: 0.792803\tvalid_0's amex: 0.784122\n",
      "[400]\ttraining's amex: 0.802564\tvalid_0's amex: 0.789655\n",
      "[500]\ttraining's amex: 0.810936\tvalid_0's amex: 0.792329\n",
      "[600]\ttraining's amex: 0.818072\tvalid_0's amex: 0.793195\n",
      "[700]\ttraining's amex: 0.824153\tvalid_0's amex: 0.792599\n",
      "[800]\ttraining's amex: 0.831301\tvalid_0's amex: 0.794417\n",
      "[900]\ttraining's amex: 0.837955\tvalid_0's amex: 0.794631\n",
      "[1000]\ttraining's amex: 0.843758\tvalid_0's amex: 0.794772\n",
      "[1100]\ttraining's amex: 0.850148\tvalid_0's amex: 0.794973\n",
      "[1200]\ttraining's amex: 0.855889\tvalid_0's amex: 0.795446\n",
      "[1300]\ttraining's amex: 0.861593\tvalid_0's amex: 0.795606\n",
      "[1400]\ttraining's amex: 0.867315\tvalid_0's amex: 0.795945\n",
      "[1500]\ttraining's amex: 0.873222\tvalid_0's amex: 0.796679\n",
      "[1600]\ttraining's amex: 0.878459\tvalid_0's amex: 0.796879\n",
      "[1700]\ttraining's amex: 0.884236\tvalid_0's amex: 0.796386\n",
      "[1800]\ttraining's amex: 0.889649\tvalid_0's amex: 0.796014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 14:43:15,564]\u001b[0m Trial 8 finished with value: 0.794199122948363 and parameters: {'reg_alpha': 0.0019031909190948342, 'reg_lambda': 26.293033759591466, 'colsample_bytree': 0.25841822696595285, 'subsample': 0.5078566497557158, 'scale_pos_weight': 1.5927608661531523, 'num_leaves': 78}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.88120 (0.9624, 0.8000)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79690 (0.9252, 0.6686)\u001b[0m\n",
      "Clear cache 10\n",
      "alpha 0.004 lambda 32.9865 colsample_bytree 0.202 subsample 0.577 scale_pos_weight 2.255 num_leaves 117\n",
      "[100]\ttraining's amex: 0.761742\tvalid_0's amex: 0.756204\n",
      "[200]\ttraining's amex: 0.781468\tvalid_0's amex: 0.774111\n",
      "[300]\ttraining's amex: 0.795281\tvalid_0's amex: 0.781753\n",
      "[400]\ttraining's amex: 0.804759\tvalid_0's amex: 0.785085\n",
      "[500]\ttraining's amex: 0.812848\tvalid_0's amex: 0.788011\n",
      "[600]\ttraining's amex: 0.819943\tvalid_0's amex: 0.790112\n",
      "[700]\ttraining's amex: 0.826686\tvalid_0's amex: 0.791566\n",
      "[800]\ttraining's amex: 0.832773\tvalid_0's amex: 0.792864\n",
      "[900]\ttraining's amex: 0.83926\tvalid_0's amex: 0.792428\n",
      "[1000]\ttraining's amex: 0.845749\tvalid_0's amex: 0.792705\n",
      "[1100]\ttraining's amex: 0.851183\tvalid_0's amex: 0.792712\n",
      "[1200]\ttraining's amex: 0.857502\tvalid_0's amex: 0.792\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.84865 (0.9513, 0.7460)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79287 (0.9224, 0.6633)\u001b[0m\n",
      "Clear cache 18\n",
      "[100]\ttraining's amex: 0.762487\tvalid_0's amex: 0.75387\n",
      "[200]\ttraining's amex: 0.781742\tvalid_0's amex: 0.770203\n",
      "[300]\ttraining's amex: 0.795709\tvalid_0's amex: 0.78018\n",
      "[400]\ttraining's amex: 0.80529\tvalid_0's amex: 0.784522\n",
      "[500]\ttraining's amex: 0.813481\tvalid_0's amex: 0.787458\n",
      "[600]\ttraining's amex: 0.820544\tvalid_0's amex: 0.789017\n",
      "[700]\ttraining's amex: 0.827482\tvalid_0's amex: 0.789346\n",
      "[800]\ttraining's amex: 0.83379\tvalid_0's amex: 0.790055\n",
      "[900]\ttraining's amex: 0.839539\tvalid_0's amex: 0.790188\n",
      "[1000]\ttraining's amex: 0.846084\tvalid_0's amex: 0.790306\n",
      "[1100]\ttraining's amex: 0.851562\tvalid_0's amex: 0.791116\n",
      "[1200]\ttraining's amex: 0.857951\tvalid_0's amex: 0.790574\n",
      "[1300]\ttraining's amex: 0.863203\tvalid_0's amex: 0.790653\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.85183 (0.9526, 0.7511)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79160 (0.9230, 0.6602)\u001b[0m\n",
      "Clear cache 16\n",
      "[100]\ttraining's amex: 0.761756\tvalid_0's amex: 0.758442\n",
      "[200]\ttraining's amex: 0.781705\tvalid_0's amex: 0.77555\n",
      "[300]\ttraining's amex: 0.796052\tvalid_0's amex: 0.781765\n",
      "[400]\ttraining's amex: 0.806169\tvalid_0's amex: 0.785402\n",
      "[500]\ttraining's amex: 0.814215\tvalid_0's amex: 0.788322\n",
      "[600]\ttraining's amex: 0.821134\tvalid_0's amex: 0.789648\n",
      "[700]\ttraining's amex: 0.828074\tvalid_0's amex: 0.79025\n",
      "[800]\ttraining's amex: 0.834419\tvalid_0's amex: 0.791209\n",
      "[900]\ttraining's amex: 0.840684\tvalid_0's amex: 0.791227\n",
      "[1000]\ttraining's amex: 0.846765\tvalid_0's amex: 0.791824\n",
      "[1100]\ttraining's amex: 0.852871\tvalid_0's amex: 0.792634\n",
      "[1200]\ttraining's amex: 0.8588\tvalid_0's amex: 0.793004\n",
      "[1300]\ttraining's amex: 0.864655\tvalid_0's amex: 0.792574\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.85703 (0.9542, 0.7599)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79323 (0.9241, 0.6624)\u001b[0m\n",
      "Clear cache 204\n",
      "[100]\ttraining's amex: 0.761191\tvalid_0's amex: 0.760718\n",
      "[200]\ttraining's amex: 0.780611\tvalid_0's amex: 0.776127\n",
      "[300]\ttraining's amex: 0.794331\tvalid_0's amex: 0.784902\n",
      "[400]\ttraining's amex: 0.804709\tvalid_0's amex: 0.788383\n",
      "[500]\ttraining's amex: 0.813027\tvalid_0's amex: 0.790929\n",
      "[600]\ttraining's amex: 0.820177\tvalid_0's amex: 0.793386\n",
      "[700]\ttraining's amex: 0.826785\tvalid_0's amex: 0.793784\n",
      "[800]\ttraining's amex: 0.83314\tvalid_0's amex: 0.794077\n",
      "[900]\ttraining's amex: 0.839156\tvalid_0's amex: 0.795046\n",
      "[1000]\ttraining's amex: 0.845419\tvalid_0's amex: 0.795104\n",
      "[1100]\ttraining's amex: 0.850967\tvalid_0's amex: 0.794978\n",
      "[1200]\ttraining's amex: 0.857198\tvalid_0's amex: 0.79501\n",
      "[1300]\ttraining's amex: 0.863297\tvalid_0's amex: 0.795902\n",
      "[1400]\ttraining's amex: 0.869419\tvalid_0's amex: 0.795678\n",
      "[1500]\ttraining's amex: 0.874912\tvalid_0's amex: 0.795436\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.86478 (0.9578, 0.7718)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79584 (0.9258, 0.6659)\u001b[0m\n",
      "Clear cache 62\n",
      "[100]\ttraining's amex: 0.761318\tvalid_0's amex: 0.759856\n",
      "[200]\ttraining's amex: 0.780752\tvalid_0's amex: 0.775534\n",
      "[300]\ttraining's amex: 0.794264\tvalid_0's amex: 0.785397\n",
      "[400]\ttraining's amex: 0.804249\tvalid_0's amex: 0.789498\n",
      "[500]\ttraining's amex: 0.81215\tvalid_0's amex: 0.792347\n",
      "[600]\ttraining's amex: 0.819496\tvalid_0's amex: 0.793777\n",
      "[700]\ttraining's amex: 0.826066\tvalid_0's amex: 0.794758\n",
      "[800]\ttraining's amex: 0.832672\tvalid_0's amex: 0.795559\n",
      "[900]\ttraining's amex: 0.839205\tvalid_0's amex: 0.795649\n",
      "[1000]\ttraining's amex: 0.844866\tvalid_0's amex: 0.795738\n",
      "[1100]\ttraining's amex: 0.850988\tvalid_0's amex: 0.795913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 15:12:39,722]\u001b[0m Trial 9 finished with value: 0.7938940945547931 and parameters: {'reg_alpha': 0.004029206444037598, 'reg_lambda': 32.986504565621644, 'colsample_bytree': 0.20166245200864277, 'subsample': 0.576872571006921, 'scale_pos_weight': 2.25461477553871, 'num_leaves': 117}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.84241 (0.9483, 0.7365)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79594 (0.9249, 0.6669)\u001b[0m\n",
      "Clear cache 106\n",
      "alpha 0.1906 lambda 43.4193 colsample_bytree 0.235 subsample 0.74 scale_pos_weight 1.901 num_leaves 100\n",
      "[100]\ttraining's amex: 0.765656\tvalid_0's amex: 0.758391\n",
      "[200]\ttraining's amex: 0.784941\tvalid_0's amex: 0.774688\n",
      "[300]\ttraining's amex: 0.799801\tvalid_0's amex: 0.782341\n",
      "[400]\ttraining's amex: 0.810352\tvalid_0's amex: 0.786083\n",
      "[500]\ttraining's amex: 0.819828\tvalid_0's amex: 0.788586\n",
      "[600]\ttraining's amex: 0.828312\tvalid_0's amex: 0.789956\n",
      "[700]\ttraining's amex: 0.836457\tvalid_0's amex: 0.791001\n",
      "[800]\ttraining's amex: 0.84431\tvalid_0's amex: 0.791701\n",
      "[900]\ttraining's amex: 0.852232\tvalid_0's amex: 0.792155\n",
      "[1000]\ttraining's amex: 0.860112\tvalid_0's amex: 0.792398\n",
      "[1100]\ttraining's amex: 0.867229\tvalid_0's amex: 0.792902\n",
      "[1200]\ttraining's amex: 0.874859\tvalid_0's amex: 0.792473\n",
      "[1300]\ttraining's amex: 0.882022\tvalid_0's amex: 0.792374\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.87198 (0.9601, 0.7839)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79287 (0.9227, 0.6630)\u001b[0m\n",
      "Clear cache 214\n",
      "[100]\ttraining's amex: 0.766248\tvalid_0's amex: 0.757254\n",
      "[200]\ttraining's amex: 0.785668\tvalid_0's amex: 0.771618\n",
      "[300]\ttraining's amex: 0.800225\tvalid_0's amex: 0.78213\n",
      "[400]\ttraining's amex: 0.811224\tvalid_0's amex: 0.787029\n",
      "[500]\ttraining's amex: 0.82087\tvalid_0's amex: 0.789107\n",
      "[600]\ttraining's amex: 0.829218\tvalid_0's amex: 0.790313\n",
      "[700]\ttraining's amex: 0.837498\tvalid_0's amex: 0.790941\n",
      "[800]\ttraining's amex: 0.845021\tvalid_0's amex: 0.791465\n",
      "[900]\ttraining's amex: 0.852635\tvalid_0's amex: 0.791479\n",
      "[1000]\ttraining's amex: 0.860423\tvalid_0's amex: 0.792865\n",
      "[1100]\ttraining's amex: 0.867873\tvalid_0's amex: 0.792349\n",
      "[1200]\ttraining's amex: 0.875322\tvalid_0's amex: 0.79316\n",
      "[1300]\ttraining's amex: 0.882597\tvalid_0's amex: 0.793139\n",
      "[1400]\ttraining's amex: 0.889559\tvalid_0's amex: 0.792566\n",
      "[1500]\ttraining's amex: 0.89622\tvalid_0's amex: 0.792477\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.88278 (0.9638, 0.8018)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79335 (0.9235, 0.6632)\u001b[0m\n",
      "Clear cache 18\n",
      "[100]\ttraining's amex: 0.765463\tvalid_0's amex: 0.761286\n",
      "[200]\ttraining's amex: 0.785164\tvalid_0's amex: 0.777041\n",
      "[300]\ttraining's amex: 0.800601\tvalid_0's amex: 0.784255\n",
      "[400]\ttraining's amex: 0.812339\tvalid_0's amex: 0.78679\n",
      "[500]\ttraining's amex: 0.821403\tvalid_0's amex: 0.789212\n",
      "[600]\ttraining's amex: 0.829786\tvalid_0's amex: 0.790591\n",
      "[700]\ttraining's amex: 0.837961\tvalid_0's amex: 0.791868\n",
      "[800]\ttraining's amex: 0.845622\tvalid_0's amex: 0.792258\n",
      "[900]\ttraining's amex: 0.853216\tvalid_0's amex: 0.793\n",
      "[1000]\ttraining's amex: 0.860998\tvalid_0's amex: 0.793382\n",
      "[1100]\ttraining's amex: 0.868607\tvalid_0's amex: 0.793965\n",
      "[1200]\ttraining's amex: 0.875701\tvalid_0's amex: 0.795158\n",
      "[1300]\ttraining's amex: 0.883373\tvalid_0's amex: 0.794518\n",
      "[1400]\ttraining's amex: 0.890069\tvalid_0's amex: 0.794741\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.87766 (0.9617, 0.7936)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79519 (0.9245, 0.6659)\u001b[0m\n",
      "Clear cache 456\n",
      "[100]\ttraining's amex: 0.764548\tvalid_0's amex: 0.7621\n",
      "[200]\ttraining's amex: 0.784377\tvalid_0's amex: 0.777171\n",
      "[300]\ttraining's amex: 0.799335\tvalid_0's amex: 0.785445\n",
      "[400]\ttraining's amex: 0.810153\tvalid_0's amex: 0.789297\n",
      "[500]\ttraining's amex: 0.819594\tvalid_0's amex: 0.79121\n",
      "[600]\ttraining's amex: 0.828237\tvalid_0's amex: 0.793683\n",
      "[700]\ttraining's amex: 0.836514\tvalid_0's amex: 0.794041\n",
      "[800]\ttraining's amex: 0.844518\tvalid_0's amex: 0.794253\n",
      "[900]\ttraining's amex: 0.852029\tvalid_0's amex: 0.794674\n",
      "[1000]\ttraining's amex: 0.859605\tvalid_0's amex: 0.794992\n",
      "[1100]\ttraining's amex: 0.866991\tvalid_0's amex: 0.795501\n",
      "[1200]\ttraining's amex: 0.874666\tvalid_0's amex: 0.795703\n",
      "[1300]\ttraining's amex: 0.882376\tvalid_0's amex: 0.795614\n",
      "[1400]\ttraining's amex: 0.889135\tvalid_0's amex: 0.796043\n",
      "[1500]\ttraining's amex: 0.895996\tvalid_0's amex: 0.795437\n",
      "[1600]\ttraining's amex: 0.902983\tvalid_0's amex: 0.795142\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.88910 (0.9660, 0.8122)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79631 (0.9260, 0.6666)\u001b[0m\n",
      "Clear cache 366\n",
      "[100]\ttraining's amex: 0.764664\tvalid_0's amex: 0.760701\n",
      "[200]\ttraining's amex: 0.784753\tvalid_0's amex: 0.776666\n",
      "[300]\ttraining's amex: 0.79859\tvalid_0's amex: 0.785183\n",
      "[400]\ttraining's amex: 0.810299\tvalid_0's amex: 0.789426\n",
      "[500]\ttraining's amex: 0.819722\tvalid_0's amex: 0.792183\n",
      "[600]\ttraining's amex: 0.828201\tvalid_0's amex: 0.793884\n",
      "[700]\ttraining's amex: 0.836235\tvalid_0's amex: 0.793995\n",
      "[800]\ttraining's amex: 0.844742\tvalid_0's amex: 0.794171\n",
      "[900]\ttraining's amex: 0.852123\tvalid_0's amex: 0.794729\n",
      "[1000]\ttraining's amex: 0.859729\tvalid_0's amex: 0.795013\n",
      "[1100]\ttraining's amex: 0.867592\tvalid_0's amex: 0.795483\n",
      "[1200]\ttraining's amex: 0.874973\tvalid_0's amex: 0.796019\n",
      "[1300]\ttraining's amex: 0.881976\tvalid_0's amex: 0.796361\n",
      "[1400]\ttraining's amex: 0.889173\tvalid_0's amex: 0.796082\n",
      "[1500]\ttraining's amex: 0.896629\tvalid_0's amex: 0.796122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 15:53:21,174]\u001b[0m Trial 10 finished with value: 0.7948044258729209 and parameters: {'reg_alpha': 0.19059460392332186, 'reg_lambda': 43.419289343981696, 'colsample_bytree': 0.23491110563801806, 'subsample': 0.7401012506848796, 'scale_pos_weight': 1.9005989811845994, 'num_leaves': 100}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.88191 (0.9634, 0.8004)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79630 (0.9253, 0.6673)\u001b[0m\n",
      "Clear cache 18\n",
      "alpha 0.0429 lambda 19.2216 colsample_bytree 0.225 subsample 0.732 scale_pos_weight 1.502 num_leaves 76\n",
      "[100]\ttraining's amex: 0.767761\tvalid_0's amex: 0.759449\n",
      "[200]\ttraining's amex: 0.787043\tvalid_0's amex: 0.775117\n",
      "[300]\ttraining's amex: 0.800839\tvalid_0's amex: 0.782944\n",
      "[400]\ttraining's amex: 0.811857\tvalid_0's amex: 0.787428\n",
      "[500]\ttraining's amex: 0.820655\tvalid_0's amex: 0.79013\n",
      "[600]\ttraining's amex: 0.828449\tvalid_0's amex: 0.792756\n",
      "[700]\ttraining's amex: 0.836603\tvalid_0's amex: 0.792958\n",
      "[800]\ttraining's amex: 0.843954\tvalid_0's amex: 0.79389\n",
      "[900]\ttraining's amex: 0.851263\tvalid_0's amex: 0.792955\n",
      "[1000]\ttraining's amex: 0.858384\tvalid_0's amex: 0.793148\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.84530 (0.9479, 0.7427)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79400 (0.9224, 0.6656)\u001b[0m\n",
      "Clear cache 358\n",
      "[100]\ttraining's amex: 0.767402\tvalid_0's amex: 0.758758\n",
      "[200]\ttraining's amex: 0.787392\tvalid_0's amex: 0.773331\n",
      "[300]\ttraining's amex: 0.801901\tvalid_0's amex: 0.782399\n",
      "[400]\ttraining's amex: 0.811847\tvalid_0's amex: 0.78641\n",
      "[500]\ttraining's amex: 0.820544\tvalid_0's amex: 0.788976\n",
      "[600]\ttraining's amex: 0.828483\tvalid_0's amex: 0.79106\n",
      "[700]\ttraining's amex: 0.836702\tvalid_0's amex: 0.791313\n",
      "[800]\ttraining's amex: 0.844107\tvalid_0's amex: 0.791823\n",
      "[900]\ttraining's amex: 0.850917\tvalid_0's amex: 0.792614\n",
      "[1000]\ttraining's amex: 0.85827\tvalid_0's amex: 0.79299\n",
      "[1100]\ttraining's amex: 0.865403\tvalid_0's amex: 0.792607\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.85492 (0.9518, 0.7580)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79311 (0.9233, 0.6629)\u001b[0m\n",
      "Clear cache 126\n",
      "[100]\ttraining's amex: 0.767608\tvalid_0's amex: 0.761935\n",
      "[200]\ttraining's amex: 0.787158\tvalid_0's amex: 0.777362\n",
      "[300]\ttraining's amex: 0.801916\tvalid_0's amex: 0.783556\n",
      "[400]\ttraining's amex: 0.8124\tvalid_0's amex: 0.787126\n",
      "[500]\ttraining's amex: 0.821229\tvalid_0's amex: 0.789128\n",
      "[600]\ttraining's amex: 0.829342\tvalid_0's amex: 0.79036\n",
      "[700]\ttraining's amex: 0.837174\tvalid_0's amex: 0.791275\n",
      "[800]\ttraining's amex: 0.844652\tvalid_0's amex: 0.792014\n",
      "[900]\ttraining's amex: 0.852097\tvalid_0's amex: 0.791753\n",
      "[1000]\ttraining's amex: 0.858883\tvalid_0's amex: 0.793113\n",
      "[1100]\ttraining's amex: 0.866229\tvalid_0's amex: 0.793288\n",
      "[1200]\ttraining's amex: 0.872877\tvalid_0's amex: 0.792748\n",
      "[1300]\ttraining's amex: 0.87932\tvalid_0's amex: 0.792909\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.87000 (0.9574, 0.7826)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79339 (0.9244, 0.6623)\u001b[0m\n",
      "Clear cache 172\n",
      "[100]\ttraining's amex: 0.767132\tvalid_0's amex: 0.763252\n",
      "[200]\ttraining's amex: 0.786595\tvalid_0's amex: 0.777945\n",
      "[300]\ttraining's amex: 0.800775\tvalid_0's amex: 0.786488\n",
      "[400]\ttraining's amex: 0.811185\tvalid_0's amex: 0.790194\n",
      "[500]\ttraining's amex: 0.819846\tvalid_0's amex: 0.79201\n",
      "[600]\ttraining's amex: 0.82814\tvalid_0's amex: 0.792848\n",
      "[700]\ttraining's amex: 0.835707\tvalid_0's amex: 0.793583\n",
      "[800]\ttraining's amex: 0.84318\tvalid_0's amex: 0.794017\n",
      "[900]\ttraining's amex: 0.850619\tvalid_0's amex: 0.794874\n",
      "[1000]\ttraining's amex: 0.857668\tvalid_0's amex: 0.795195\n",
      "[1100]\ttraining's amex: 0.864584\tvalid_0's amex: 0.795897\n",
      "[1200]\ttraining's amex: 0.872037\tvalid_0's amex: 0.796216\n",
      "[1300]\ttraining's amex: 0.878483\tvalid_0's amex: 0.796708\n",
      "[1400]\ttraining's amex: 0.884901\tvalid_0's amex: 0.797123\n",
      "[1500]\ttraining's amex: 0.891038\tvalid_0's amex: 0.797123\n",
      "[1600]\ttraining's amex: 0.897335\tvalid_0's amex: 0.797583\n",
      "[1700]\ttraining's amex: 0.903675\tvalid_0's amex: 0.797439\n",
      "[1800]\ttraining's amex: 0.909981\tvalid_0's amex: 0.797596\n",
      "[1900]\ttraining's amex: 0.915896\tvalid_0's amex: 0.79769\n",
      "[2000]\ttraining's amex: 0.921589\tvalid_0's amex: 0.79712\n",
      "[2100]\ttraining's amex: 0.927403\tvalid_0's amex: 0.79709\n",
      "[2200]\ttraining's amex: 0.932245\tvalid_0's amex: 0.796858\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.92126 (0.9754, 0.8671)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79781 (0.9260, 0.6696)\u001b[0m\n",
      "Clear cache 404\n",
      "[100]\ttraining's amex: 0.766433\tvalid_0's amex: 0.763129\n",
      "[200]\ttraining's amex: 0.786732\tvalid_0's amex: 0.77766\n",
      "[300]\ttraining's amex: 0.80041\tvalid_0's amex: 0.786927\n",
      "[400]\ttraining's amex: 0.811397\tvalid_0's amex: 0.790549\n",
      "[500]\ttraining's amex: 0.819922\tvalid_0's amex: 0.793125\n",
      "[600]\ttraining's amex: 0.827921\tvalid_0's amex: 0.794466\n",
      "[700]\ttraining's amex: 0.83575\tvalid_0's amex: 0.795703\n",
      "[800]\ttraining's amex: 0.843439\tvalid_0's amex: 0.795548\n",
      "[900]\ttraining's amex: 0.850795\tvalid_0's amex: 0.795327\n",
      "[1000]\ttraining's amex: 0.857888\tvalid_0's amex: 0.79607\n",
      "[1100]\ttraining's amex: 0.865008\tvalid_0's amex: 0.795606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 16:29:06,034]\u001b[0m Trial 11 finished with value: 0.79497393188621 and parameters: {'reg_alpha': 0.04292312830446852, 'reg_lambda': 19.221577728163155, 'colsample_bytree': 0.22512502360046172, 'subsample': 0.7323553383428499, 'scale_pos_weight': 1.5017473274015127, 'num_leaves': 76}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.85550 (0.9519, 0.7591)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79656 (0.9251, 0.6680)\u001b[0m\n",
      "Clear cache 174\n",
      "alpha 0.034 lambda 19.4799 colsample_bytree 0.259 subsample 0.68 scale_pos_weight 1.706 num_leaves 97\n",
      "[100]\ttraining's amex: 0.765936\tvalid_0's amex: 0.759358\n",
      "[200]\ttraining's amex: 0.786004\tvalid_0's amex: 0.77548\n",
      "[300]\ttraining's amex: 0.800221\tvalid_0's amex: 0.783308\n",
      "[400]\ttraining's amex: 0.811943\tvalid_0's amex: 0.787511\n",
      "[500]\ttraining's amex: 0.821396\tvalid_0's amex: 0.789906\n",
      "[600]\ttraining's amex: 0.830489\tvalid_0's amex: 0.790335\n",
      "[700]\ttraining's amex: 0.83872\tvalid_0's amex: 0.791518\n",
      "[800]\ttraining's amex: 0.847144\tvalid_0's amex: 0.792107\n",
      "[900]\ttraining's amex: 0.855588\tvalid_0's amex: 0.792635\n",
      "[1000]\ttraining's amex: 0.86378\tvalid_0's amex: 0.792452\n",
      "[1100]\ttraining's amex: 0.871768\tvalid_0's amex: 0.793428\n",
      "[1200]\ttraining's amex: 0.879467\tvalid_0's amex: 0.793543\n",
      "[1300]\ttraining's amex: 0.886701\tvalid_0's amex: 0.79304\n",
      "[1400]\ttraining's amex: 0.894415\tvalid_0's amex: 0.793583\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.87747 (0.9617, 0.7933)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79381 (0.9228, 0.6648)\u001b[0m\n",
      "Clear cache 246\n",
      "[100]\ttraining's amex: 0.766678\tvalid_0's amex: 0.758137\n",
      "[200]\ttraining's amex: 0.786565\tvalid_0's amex: 0.773431\n",
      "[300]\ttraining's amex: 0.800987\tvalid_0's amex: 0.781878\n",
      "[400]\ttraining's amex: 0.812593\tvalid_0's amex: 0.786022\n",
      "[500]\ttraining's amex: 0.821831\tvalid_0's amex: 0.789231\n",
      "[600]\ttraining's amex: 0.83087\tvalid_0's amex: 0.789572\n",
      "[700]\ttraining's amex: 0.83953\tvalid_0's amex: 0.789575\n",
      "[800]\ttraining's amex: 0.847828\tvalid_0's amex: 0.78923\n",
      "[900]\ttraining's amex: 0.856085\tvalid_0's amex: 0.789788\n",
      "[1000]\ttraining's amex: 0.864568\tvalid_0's amex: 0.790356\n",
      "[1100]\ttraining's amex: 0.872459\tvalid_0's amex: 0.790227\n",
      "[1200]\ttraining's amex: 0.87977\tvalid_0's amex: 0.790343\n",
      "[1300]\ttraining's amex: 0.88752\tvalid_0's amex: 0.790474\n",
      "[1400]\ttraining's amex: 0.894868\tvalid_0's amex: 0.791041\n",
      "[1500]\ttraining's amex: 0.90183\tvalid_0's amex: 0.791939\n",
      "[1600]\ttraining's amex: 0.908878\tvalid_0's amex: 0.791618\n",
      "[1700]\ttraining's amex: 0.915434\tvalid_0's amex: 0.791364\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.90297 (0.9706, 0.8354)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79205 (0.9233, 0.6608)\u001b[0m\n",
      "Clear cache 60\n",
      "[100]\ttraining's amex: 0.766272\tvalid_0's amex: 0.76155\n",
      "[200]\ttraining's amex: 0.784916\tvalid_0's amex: 0.77652\n",
      "[300]\ttraining's amex: 0.801155\tvalid_0's amex: 0.782948\n",
      "[400]\ttraining's amex: 0.813034\tvalid_0's amex: 0.786962\n",
      "[500]\ttraining's amex: 0.822371\tvalid_0's amex: 0.788871\n",
      "[600]\ttraining's amex: 0.830859\tvalid_0's amex: 0.789211\n",
      "[700]\ttraining's amex: 0.8393\tvalid_0's amex: 0.790297\n",
      "[800]\ttraining's amex: 0.847466\tvalid_0's amex: 0.791357\n",
      "[900]\ttraining's amex: 0.855584\tvalid_0's amex: 0.791879\n",
      "[1000]\ttraining's amex: 0.863715\tvalid_0's amex: 0.791893\n",
      "[1100]\ttraining's amex: 0.871852\tvalid_0's amex: 0.793018\n",
      "[1200]\ttraining's amex: 0.879349\tvalid_0's amex: 0.793002\n",
      "[1300]\ttraining's amex: 0.886843\tvalid_0's amex: 0.792852\n",
      "[1400]\ttraining's amex: 0.89413\tvalid_0's amex: 0.79405\n",
      "[1500]\ttraining's amex: 0.901547\tvalid_0's amex: 0.794514\n",
      "[1600]\ttraining's amex: 0.908508\tvalid_0's amex: 0.794085\n",
      "[1700]\ttraining's amex: 0.915396\tvalid_0's amex: 0.793722\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.90378 (0.9708, 0.8368)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79461 (0.9247, 0.6645)\u001b[0m\n",
      "Clear cache 116\n",
      "[100]\ttraining's amex: 0.765814\tvalid_0's amex: 0.763225\n",
      "[200]\ttraining's amex: 0.785396\tvalid_0's amex: 0.77787\n",
      "[300]\ttraining's amex: 0.800792\tvalid_0's amex: 0.786233\n",
      "[400]\ttraining's amex: 0.811348\tvalid_0's amex: 0.789679\n",
      "[500]\ttraining's amex: 0.821324\tvalid_0's amex: 0.791917\n",
      "[600]\ttraining's amex: 0.829694\tvalid_0's amex: 0.793185\n",
      "[700]\ttraining's amex: 0.838642\tvalid_0's amex: 0.794135\n",
      "[800]\ttraining's amex: 0.846927\tvalid_0's amex: 0.794279\n",
      "[900]\ttraining's amex: 0.855038\tvalid_0's amex: 0.795711\n",
      "[1000]\ttraining's amex: 0.863332\tvalid_0's amex: 0.795539\n",
      "[1100]\ttraining's amex: 0.871175\tvalid_0's amex: 0.796341\n",
      "[1200]\ttraining's amex: 0.878714\tvalid_0's amex: 0.796265\n",
      "[1300]\ttraining's amex: 0.886769\tvalid_0's amex: 0.796149\n",
      "[1400]\ttraining's amex: 0.894246\tvalid_0's amex: 0.795967\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.87784 (0.9617, 0.7940)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79659 (0.9258, 0.6674)\u001b[0m\n",
      "Clear cache 288\n",
      "[100]\ttraining's amex: 0.765675\tvalid_0's amex: 0.761719\n",
      "[200]\ttraining's amex: 0.7851\tvalid_0's amex: 0.777396\n",
      "[300]\ttraining's amex: 0.79947\tvalid_0's amex: 0.786867\n",
      "[400]\ttraining's amex: 0.811187\tvalid_0's amex: 0.791139\n",
      "[500]\ttraining's amex: 0.820775\tvalid_0's amex: 0.794304\n",
      "[600]\ttraining's amex: 0.830042\tvalid_0's amex: 0.795441\n",
      "[700]\ttraining's amex: 0.838936\tvalid_0's amex: 0.796571\n",
      "[800]\ttraining's amex: 0.847084\tvalid_0's amex: 0.796261\n",
      "[900]\ttraining's amex: 0.855547\tvalid_0's amex: 0.796479\n",
      "[1000]\ttraining's amex: 0.863353\tvalid_0's amex: 0.796292\n",
      "[1100]\ttraining's amex: 0.871418\tvalid_0's amex: 0.796611\n",
      "[1200]\ttraining's amex: 0.87919\tvalid_0's amex: 0.79685\n",
      "[1300]\ttraining's amex: 0.887219\tvalid_0's amex: 0.797047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 17:10:17,948]\u001b[0m Trial 12 finished with value: 0.7948627087516043 and parameters: {'reg_alpha': 0.0339615885821029, 'reg_lambda': 19.479918239281048, 'colsample_bytree': 0.25874548912275547, 'subsample': 0.6804027678742768, 'scale_pos_weight': 1.7060629283321302, 'num_leaves': 97}. Best is trial 0 with value: 0.7952085044600888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.86914 (0.9584, 0.7799)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79726 (0.9252, 0.6693)\u001b[0m\n",
      "Clear cache 66\n",
      "alpha 0.0342 lambda 10.1368 colsample_bytree 0.218 subsample 0.625 scale_pos_weight 1.934 num_leaves 83\n",
      "[100]\ttraining's amex: 0.765357\tvalid_0's amex: 0.758863\n",
      "[200]\ttraining's amex: 0.785182\tvalid_0's amex: 0.775391\n",
      "[300]\ttraining's amex: 0.799267\tvalid_0's amex: 0.783184\n",
      "[400]\ttraining's amex: 0.809578\tvalid_0's amex: 0.787917\n",
      "[500]\ttraining's amex: 0.818224\tvalid_0's amex: 0.789398\n",
      "[600]\ttraining's amex: 0.826155\tvalid_0's amex: 0.791237\n",
      "[700]\ttraining's amex: 0.833938\tvalid_0's amex: 0.791385\n",
      "[800]\ttraining's amex: 0.841951\tvalid_0's amex: 0.792378\n",
      "[900]\ttraining's amex: 0.849353\tvalid_0's amex: 0.79291\n",
      "[1000]\ttraining's amex: 0.856792\tvalid_0's amex: 0.79262\n",
      "[1100]\ttraining's amex: 0.863488\tvalid_0's amex: 0.792871\n",
      "[1200]\ttraining's amex: 0.870368\tvalid_0's amex: 0.793733\n",
      "[1300]\ttraining's amex: 0.877242\tvalid_0's amex: 0.793893\n",
      "[1400]\ttraining's amex: 0.883838\tvalid_0's amex: 0.793763\n",
      "[1500]\ttraining's amex: 0.890842\tvalid_0's amex: 0.79337\n",
      "[1600]\ttraining's amex: 0.897276\tvalid_0's amex: 0.793659\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.88696 (0.9659, 0.8081)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79421 (0.9229, 0.6655)\u001b[0m\n",
      "Clear cache 8\n",
      "[100]\ttraining's amex: 0.765581\tvalid_0's amex: 0.756419\n",
      "[200]\ttraining's amex: 0.78522\tvalid_0's amex: 0.772531\n",
      "[300]\ttraining's amex: 0.799873\tvalid_0's amex: 0.781785\n",
      "[400]\ttraining's amex: 0.810017\tvalid_0's amex: 0.78658\n",
      "[500]\ttraining's amex: 0.818647\tvalid_0's amex: 0.789228\n",
      "[600]\ttraining's amex: 0.827473\tvalid_0's amex: 0.790109\n",
      "[700]\ttraining's amex: 0.835083\tvalid_0's amex: 0.790668\n",
      "[800]\ttraining's amex: 0.842004\tvalid_0's amex: 0.791051\n",
      "[900]\ttraining's amex: 0.84952\tvalid_0's amex: 0.791356\n",
      "[1000]\ttraining's amex: 0.856963\tvalid_0's amex: 0.792273\n",
      "[1100]\ttraining's amex: 0.864119\tvalid_0's amex: 0.791981\n",
      "[1200]\ttraining's amex: 0.871126\tvalid_0's amex: 0.792631\n",
      "[1300]\ttraining's amex: 0.877907\tvalid_0's amex: 0.792673\n",
      "[1400]\ttraining's amex: 0.884419\tvalid_0's amex: 0.79345\n",
      "[1500]\ttraining's amex: 0.890681\tvalid_0's amex: 0.793107\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.88222 (0.9639, 0.8006)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79357 (0.9233, 0.6638)\u001b[0m\n",
      "Clear cache 230\n",
      "[100]\ttraining's amex: 0.765104\tvalid_0's amex: 0.761569\n",
      "[200]\ttraining's amex: 0.784998\tvalid_0's amex: 0.777326\n",
      "[300]\ttraining's amex: 0.7998\tvalid_0's amex: 0.78405\n",
      "[400]\ttraining's amex: 0.81107\tvalid_0's amex: 0.787403\n",
      "[500]\ttraining's amex: 0.819716\tvalid_0's amex: 0.789502\n",
      "[600]\ttraining's amex: 0.827757\tvalid_0's amex: 0.791295\n",
      "[700]\ttraining's amex: 0.835589\tvalid_0's amex: 0.791646\n",
      "[800]\ttraining's amex: 0.842882\tvalid_0's amex: 0.792695\n",
      "[900]\ttraining's amex: 0.850173\tvalid_0's amex: 0.792941\n",
      "[1000]\ttraining's amex: 0.857146\tvalid_0's amex: 0.79357\n",
      "[1100]\ttraining's amex: 0.864366\tvalid_0's amex: 0.79322\n",
      "[1200]\ttraining's amex: 0.871222\tvalid_0's amex: 0.793366\n",
      "[1300]\ttraining's amex: 0.877842\tvalid_0's amex: 0.794424\n",
      "[1400]\ttraining's amex: 0.884298\tvalid_0's amex: 0.794171\n",
      "[1500]\ttraining's amex: 0.891089\tvalid_0's amex: 0.794643\n",
      "[1600]\ttraining's amex: 0.89772\tvalid_0's amex: 0.794658\n",
      "[1700]\ttraining's amex: 0.904302\tvalid_0's amex: 0.794882\n",
      "[1800]\ttraining's amex: 0.91065\tvalid_0's amex: 0.794554\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.90198 (0.9706, 0.8334)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79515 (0.9246, 0.6657)\u001b[0m\n",
      "Clear cache 10\n",
      "[100]\ttraining's amex: 0.764321\tvalid_0's amex: 0.761989\n",
      "[200]\ttraining's amex: 0.784111\tvalid_0's amex: 0.778159\n",
      "[300]\ttraining's amex: 0.79908\tvalid_0's amex: 0.78556\n",
      "[400]\ttraining's amex: 0.809855\tvalid_0's amex: 0.79113\n",
      "[500]\ttraining's amex: 0.818466\tvalid_0's amex: 0.792628\n",
      "[600]\ttraining's amex: 0.826687\tvalid_0's amex: 0.793593\n",
      "[700]\ttraining's amex: 0.834205\tvalid_0's amex: 0.794537\n",
      "[800]\ttraining's amex: 0.841903\tvalid_0's amex: 0.796247\n",
      "[900]\ttraining's amex: 0.84922\tvalid_0's amex: 0.796599\n",
      "[1000]\ttraining's amex: 0.85604\tvalid_0's amex: 0.797018\n",
      "[1100]\ttraining's amex: 0.863243\tvalid_0's amex: 0.797171\n",
      "[1200]\ttraining's amex: 0.870302\tvalid_0's amex: 0.797667\n",
      "[1300]\ttraining's amex: 0.876663\tvalid_0's amex: 0.797346\n",
      "[1400]\ttraining's amex: 0.883427\tvalid_0's amex: 0.798104\n",
      "[1500]\ttraining's amex: 0.890122\tvalid_0's amex: 0.798137\n",
      "[1600]\ttraining's amex: 0.89681\tvalid_0's amex: 0.798217\n",
      "[1700]\ttraining's amex: 0.903315\tvalid_0's amex: 0.798056\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.89499 (0.9684, 0.8216)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79847 (0.9260, 0.6709)\u001b[0m\n",
      "Clear cache 264\n",
      "[100]\ttraining's amex: 0.763936\tvalid_0's amex: 0.761432\n",
      "[200]\ttraining's amex: 0.784139\tvalid_0's amex: 0.777764\n",
      "[300]\ttraining's amex: 0.798249\tvalid_0's amex: 0.787427\n",
      "[400]\ttraining's amex: 0.80872\tvalid_0's amex: 0.791644\n",
      "[500]\ttraining's amex: 0.817678\tvalid_0's amex: 0.794153\n",
      "[600]\ttraining's amex: 0.826104\tvalid_0's amex: 0.795235\n",
      "[700]\ttraining's amex: 0.834163\tvalid_0's amex: 0.795596\n",
      "[800]\ttraining's amex: 0.84156\tvalid_0's amex: 0.796053\n",
      "[900]\ttraining's amex: 0.848888\tvalid_0's amex: 0.797009\n",
      "[1000]\ttraining's amex: 0.855947\tvalid_0's amex: 0.796837\n",
      "[1100]\ttraining's amex: 0.863317\tvalid_0's amex: 0.797274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 17:49:22,128]\u001b[0m Trial 13 finished with value: 0.7957243237457016 and parameters: {'reg_alpha': 0.03419275048156644, 'reg_lambda': 10.13682796954036, 'colsample_bytree': 0.21796494267435756, 'subsample': 0.6247849970379308, 'scale_pos_weight': 1.9341486908332768, 'num_leaves': 83}. Best is trial 13 with value: 0.7957243237457016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.85103 (0.9518, 0.7503)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79723 (0.9252, 0.6692)\u001b[0m\n",
      "Clear cache 34\n",
      "alpha 0.0939 lambda 10.0913 colsample_bytree 0.255 subsample 0.637 scale_pos_weight 1.967 num_leaves 93\n",
      "[100]\ttraining's amex: 0.765563\tvalid_0's amex: 0.758642\n",
      "[200]\ttraining's amex: 0.784758\tvalid_0's amex: 0.776262\n",
      "[300]\ttraining's amex: 0.799884\tvalid_0's amex: 0.78348\n",
      "[400]\ttraining's amex: 0.810452\tvalid_0's amex: 0.787132\n",
      "[500]\ttraining's amex: 0.819998\tvalid_0's amex: 0.789774\n",
      "[600]\ttraining's amex: 0.829025\tvalid_0's amex: 0.791082\n",
      "[700]\ttraining's amex: 0.837439\tvalid_0's amex: 0.791172\n",
      "[800]\ttraining's amex: 0.845189\tvalid_0's amex: 0.792195\n",
      "[900]\ttraining's amex: 0.853043\tvalid_0's amex: 0.79294\n",
      "[1000]\ttraining's amex: 0.860301\tvalid_0's amex: 0.792637\n",
      "[1100]\ttraining's amex: 0.868203\tvalid_0's amex: 0.792829\n",
      "[1200]\ttraining's amex: 0.87593\tvalid_0's amex: 0.793544\n",
      "[1300]\ttraining's amex: 0.883273\tvalid_0's amex: 0.793636\n",
      "[1400]\ttraining's amex: 0.890601\tvalid_0's amex: 0.792989\n",
      "[1500]\ttraining's amex: 0.89724\tvalid_0's amex: 0.7931\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.88464 (0.9652, 0.8041)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79356 (0.9231, 0.6641)\u001b[0m\n",
      "Clear cache 60\n",
      "[100]\ttraining's amex: 0.765871\tvalid_0's amex: 0.756608\n",
      "[200]\ttraining's amex: 0.786324\tvalid_0's amex: 0.771572\n",
      "[300]\ttraining's amex: 0.800569\tvalid_0's amex: 0.781553\n",
      "[400]\ttraining's amex: 0.81187\tvalid_0's amex: 0.786963\n",
      "[500]\ttraining's amex: 0.821093\tvalid_0's amex: 0.789408\n",
      "[600]\ttraining's amex: 0.829613\tvalid_0's amex: 0.790554\n",
      "[700]\ttraining's amex: 0.837966\tvalid_0's amex: 0.790995\n",
      "[800]\ttraining's amex: 0.846156\tvalid_0's amex: 0.791794\n",
      "[900]\ttraining's amex: 0.853877\tvalid_0's amex: 0.792514\n",
      "[1000]\ttraining's amex: 0.861259\tvalid_0's amex: 0.792233\n",
      "[1100]\ttraining's amex: 0.868942\tvalid_0's amex: 0.792693\n",
      "[1200]\ttraining's amex: 0.876426\tvalid_0's amex: 0.792307\n",
      "[1300]\ttraining's amex: 0.88428\tvalid_0's amex: 0.792068\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.87183 (0.9603, 0.7834)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79266 (0.9233, 0.6620)\u001b[0m\n",
      "Clear cache 108\n",
      "[100]\ttraining's amex: 0.765349\tvalid_0's amex: 0.760738\n",
      "[200]\ttraining's amex: 0.785947\tvalid_0's amex: 0.777369\n",
      "[300]\ttraining's amex: 0.801046\tvalid_0's amex: 0.784056\n",
      "[400]\ttraining's amex: 0.8122\tvalid_0's amex: 0.787881\n",
      "[500]\ttraining's amex: 0.821372\tvalid_0's amex: 0.789076\n",
      "[600]\ttraining's amex: 0.829721\tvalid_0's amex: 0.791002\n",
      "[700]\ttraining's amex: 0.83849\tvalid_0's amex: 0.790853\n",
      "[800]\ttraining's amex: 0.846031\tvalid_0's amex: 0.791566\n",
      "[900]\ttraining's amex: 0.854105\tvalid_0's amex: 0.791607\n",
      "[1000]\ttraining's amex: 0.861843\tvalid_0's amex: 0.792746\n",
      "[1100]\ttraining's amex: 0.86929\tvalid_0's amex: 0.792219\n",
      "[1200]\ttraining's amex: 0.876266\tvalid_0's amex: 0.793133\n",
      "[1300]\ttraining's amex: 0.883464\tvalid_0's amex: 0.793878\n",
      "[1400]\ttraining's amex: 0.890831\tvalid_0's amex: 0.7939\n",
      "[1500]\ttraining's amex: 0.897927\tvalid_0's amex: 0.793739\n",
      "[1600]\ttraining's amex: 0.905098\tvalid_0's amex: 0.793556\n",
      "[1700]\ttraining's amex: 0.911632\tvalid_0's amex: 0.794017\n",
      "[1800]\ttraining's amex: 0.918623\tvalid_0's amex: 0.794378\n",
      "[1900]\ttraining's amex: 0.925049\tvalid_0's amex: 0.794103\n",
      "[2000]\ttraining's amex: 0.931455\tvalid_0's amex: 0.793272\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.91789 (0.9757, 0.8601)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79448 (0.9245, 0.6645)\u001b[0m\n",
      "Clear cache 374\n",
      "[100]\ttraining's amex: 0.764546\tvalid_0's amex: 0.763088\n",
      "[200]\ttraining's amex: 0.785006\tvalid_0's amex: 0.77813\n",
      "[300]\ttraining's amex: 0.799756\tvalid_0's amex: 0.785794\n",
      "[400]\ttraining's amex: 0.811016\tvalid_0's amex: 0.790129\n",
      "[500]\ttraining's amex: 0.82044\tvalid_0's amex: 0.792282\n",
      "[600]\ttraining's amex: 0.828629\tvalid_0's amex: 0.793146\n",
      "[700]\ttraining's amex: 0.837074\tvalid_0's amex: 0.79426\n",
      "[800]\ttraining's amex: 0.845088\tvalid_0's amex: 0.794594\n",
      "[900]\ttraining's amex: 0.852526\tvalid_0's amex: 0.794762\n",
      "[1000]\ttraining's amex: 0.860222\tvalid_0's amex: 0.794942\n",
      "[1100]\ttraining's amex: 0.868236\tvalid_0's amex: 0.795669\n",
      "[1200]\ttraining's amex: 0.875711\tvalid_0's amex: 0.795625\n",
      "[1300]\ttraining's amex: 0.883169\tvalid_0's amex: 0.79633\n",
      "[1400]\ttraining's amex: 0.889989\tvalid_0's amex: 0.796701\n",
      "[1500]\ttraining's amex: 0.89703\tvalid_0's amex: 0.797298\n",
      "[1600]\ttraining's amex: 0.903893\tvalid_0's amex: 0.797134\n",
      "[1700]\ttraining's amex: 0.910835\tvalid_0's amex: 0.796535\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.90142 (0.9709, 0.8319)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79797 (0.9259, 0.6701)\u001b[0m\n",
      "Clear cache 256\n",
      "[100]\ttraining's amex: 0.764487\tvalid_0's amex: 0.761665\n",
      "[200]\ttraining's amex: 0.78458\tvalid_0's amex: 0.777405\n",
      "[300]\ttraining's amex: 0.798847\tvalid_0's amex: 0.786766\n",
      "[400]\ttraining's amex: 0.810131\tvalid_0's amex: 0.791002\n",
      "[500]\ttraining's amex: 0.819842\tvalid_0's amex: 0.793478\n",
      "[600]\ttraining's amex: 0.828515\tvalid_0's amex: 0.794433\n",
      "[700]\ttraining's amex: 0.837063\tvalid_0's amex: 0.795121\n",
      "[800]\ttraining's amex: 0.845035\tvalid_0's amex: 0.79586\n",
      "[900]\ttraining's amex: 0.853041\tvalid_0's amex: 0.795098\n",
      "[1000]\ttraining's amex: 0.860415\tvalid_0's amex: 0.796506\n",
      "[1100]\ttraining's amex: 0.868502\tvalid_0's amex: 0.796427\n",
      "[1200]\ttraining's amex: 0.875991\tvalid_0's amex: 0.796116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 18:31:07,509]\u001b[0m Trial 14 finished with value: 0.7950207468701147 and parameters: {'reg_alpha': 0.0938517377152858, 'reg_lambda': 10.091278155434697, 'colsample_bytree': 0.2549576942553352, 'subsample': 0.6370554079531255, 'scale_pos_weight': 1.9666262164513497, 'num_leaves': 93}. Best is trial 13 with value: 0.7957243237457016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.86141 (0.9564, 0.7665)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79643 (0.9251, 0.6677)\u001b[0m\n",
      "Clear cache 376\n",
      "alpha 0.1815 lambda 10.3711 colsample_bytree 0.216 subsample 0.688 scale_pos_weight 1.881 num_leaves 80\n",
      "[100]\ttraining's amex: 0.766514\tvalid_0's amex: 0.758969\n",
      "[200]\ttraining's amex: 0.786023\tvalid_0's amex: 0.775028\n",
      "[300]\ttraining's amex: 0.800808\tvalid_0's amex: 0.782363\n",
      "[400]\ttraining's amex: 0.811494\tvalid_0's amex: 0.78745\n",
      "[500]\ttraining's amex: 0.819635\tvalid_0's amex: 0.789405\n",
      "[600]\ttraining's amex: 0.827908\tvalid_0's amex: 0.791244\n",
      "[700]\ttraining's amex: 0.835884\tvalid_0's amex: 0.791939\n",
      "[800]\ttraining's amex: 0.843211\tvalid_0's amex: 0.792854\n",
      "[900]\ttraining's amex: 0.850448\tvalid_0's amex: 0.793356\n",
      "[1000]\ttraining's amex: 0.858167\tvalid_0's amex: 0.794093\n",
      "[1100]\ttraining's amex: 0.864892\tvalid_0's amex: 0.793912\n",
      "[1200]\ttraining's amex: 0.8721\tvalid_0's amex: 0.793677\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.86156 (0.9559, 0.7672)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79433 (0.9228, 0.6659)\u001b[0m\n",
      "Clear cache 18\n",
      "[100]\ttraining's amex: 0.766905\tvalid_0's amex: 0.757417\n",
      "[200]\ttraining's amex: 0.786637\tvalid_0's amex: 0.773015\n",
      "[300]\ttraining's amex: 0.800726\tvalid_0's amex: 0.781984\n",
      "[400]\ttraining's amex: 0.811202\tvalid_0's amex: 0.786165\n",
      "[500]\ttraining's amex: 0.820456\tvalid_0's amex: 0.78826\n",
      "[600]\ttraining's amex: 0.828665\tvalid_0's amex: 0.790065\n",
      "[700]\ttraining's amex: 0.836071\tvalid_0's amex: 0.791212\n",
      "[800]\ttraining's amex: 0.843683\tvalid_0's amex: 0.791119\n",
      "[900]\ttraining's amex: 0.851076\tvalid_0's amex: 0.791344\n",
      "[1000]\ttraining's amex: 0.858283\tvalid_0's amex: 0.792353\n",
      "[1100]\ttraining's amex: 0.865362\tvalid_0's amex: 0.792105\n",
      "[1200]\ttraining's amex: 0.872047\tvalid_0's amex: 0.79209\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.86012 (0.9552, 0.7650)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79239 (0.9232, 0.6616)\u001b[0m\n",
      "Clear cache 414\n",
      "[100]\ttraining's amex: 0.765882\tvalid_0's amex: 0.762088\n",
      "[200]\ttraining's amex: 0.785669\tvalid_0's amex: 0.777062\n",
      "[300]\ttraining's amex: 0.800691\tvalid_0's amex: 0.784109\n",
      "[400]\ttraining's amex: 0.812128\tvalid_0's amex: 0.787749\n",
      "[500]\ttraining's amex: 0.821132\tvalid_0's amex: 0.789404\n",
      "[600]\ttraining's amex: 0.829049\tvalid_0's amex: 0.790281\n",
      "[700]\ttraining's amex: 0.836397\tvalid_0's amex: 0.790687\n",
      "[800]\ttraining's amex: 0.84403\tvalid_0's amex: 0.792018\n",
      "[900]\ttraining's amex: 0.851278\tvalid_0's amex: 0.792607\n",
      "[1000]\ttraining's amex: 0.858459\tvalid_0's amex: 0.792966\n",
      "[1100]\ttraining's amex: 0.865\tvalid_0's amex: 0.793199\n",
      "[1200]\ttraining's amex: 0.87231\tvalid_0's amex: 0.793007\n",
      "[1300]\ttraining's amex: 0.878788\tvalid_0's amex: 0.792615\n",
      "[1400]\ttraining's amex: 0.885142\tvalid_0's amex: 0.793677\n",
      "[1500]\ttraining's amex: 0.891437\tvalid_0's amex: 0.794036\n",
      "[1600]\ttraining's amex: 0.897896\tvalid_0's amex: 0.79369\n",
      "[1700]\ttraining's amex: 0.904247\tvalid_0's amex: 0.79342\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.89005 (0.9667, 0.8134)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79412 (0.9247, 0.6636)\u001b[0m\n",
      "Clear cache 8\n",
      "[100]\ttraining's amex: 0.765829\tvalid_0's amex: 0.763219\n",
      "[200]\ttraining's amex: 0.785806\tvalid_0's amex: 0.77719\n",
      "[300]\ttraining's amex: 0.80051\tvalid_0's amex: 0.785664\n",
      "[400]\ttraining's amex: 0.811088\tvalid_0's amex: 0.79092\n",
      "[500]\ttraining's amex: 0.819613\tvalid_0's amex: 0.793092\n",
      "[600]\ttraining's amex: 0.827458\tvalid_0's amex: 0.794271\n",
      "[700]\ttraining's amex: 0.83501\tvalid_0's amex: 0.794591\n",
      "[800]\ttraining's amex: 0.842662\tvalid_0's amex: 0.794615\n",
      "[900]\ttraining's amex: 0.849832\tvalid_0's amex: 0.794894\n",
      "[1000]\ttraining's amex: 0.857055\tvalid_0's amex: 0.795174\n",
      "[1100]\ttraining's amex: 0.864523\tvalid_0's amex: 0.795556\n",
      "[1200]\ttraining's amex: 0.871405\tvalid_0's amex: 0.79542\n",
      "[1300]\ttraining's amex: 0.878254\tvalid_0's amex: 0.795767\n",
      "[1400]\ttraining's amex: 0.885141\tvalid_0's amex: 0.79604\n",
      "[1500]\ttraining's amex: 0.891882\tvalid_0's amex: 0.796155\n",
      "[1600]\ttraining's amex: 0.898224\tvalid_0's amex: 0.796666\n",
      "[1700]\ttraining's amex: 0.904371\tvalid_0's amex: 0.797191\n",
      "[1800]\ttraining's amex: 0.910389\tvalid_0's amex: 0.796804\n",
      "[1900]\ttraining's amex: 0.916694\tvalid_0's amex: 0.796812\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.90434 (0.9714, 0.8373)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79745 (0.9260, 0.6689)\u001b[0m\n",
      "Clear cache 18\n",
      "[100]\ttraining's amex: 0.765611\tvalid_0's amex: 0.760544\n",
      "[200]\ttraining's amex: 0.785647\tvalid_0's amex: 0.77774\n",
      "[300]\ttraining's amex: 0.79964\tvalid_0's amex: 0.786632\n",
      "[400]\ttraining's amex: 0.810226\tvalid_0's amex: 0.791516\n",
      "[500]\ttraining's amex: 0.819195\tvalid_0's amex: 0.793596\n",
      "[600]\ttraining's amex: 0.827421\tvalid_0's amex: 0.794954\n",
      "[700]\ttraining's amex: 0.835237\tvalid_0's amex: 0.795336\n",
      "[800]\ttraining's amex: 0.843325\tvalid_0's amex: 0.795587\n",
      "[900]\ttraining's amex: 0.851007\tvalid_0's amex: 0.796649\n",
      "[1000]\ttraining's amex: 0.857868\tvalid_0's amex: 0.796437\n",
      "[1100]\ttraining's amex: 0.865088\tvalid_0's amex: 0.79636\n",
      "[1200]\ttraining's amex: 0.87215\tvalid_0's amex: 0.796582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 19:07:32,754]\u001b[0m Trial 15 finished with value: 0.79504219377386 and parameters: {'reg_alpha': 0.18148872188438875, 'reg_lambda': 10.371101245511053, 'colsample_bytree': 0.2161349136119574, 'subsample': 0.6880399164670362, 'scale_pos_weight': 1.8805764025227947, 'num_leaves': 80}. Best is trial 13 with value: 0.7957243237457016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.85671 (0.9538, 0.7597)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79693 (0.9251, 0.6688)\u001b[0m\n",
      "Clear cache 250\n",
      "alpha 0.0702 lambda 13.5175 colsample_bytree 0.273 subsample 0.613 scale_pos_weight 2.035 num_leaves 106\n",
      "[100]\ttraining's amex: 0.764684\tvalid_0's amex: 0.759361\n",
      "[200]\ttraining's amex: 0.784417\tvalid_0's amex: 0.776041\n",
      "[300]\ttraining's amex: 0.799432\tvalid_0's amex: 0.783672\n",
      "[400]\ttraining's amex: 0.810264\tvalid_0's amex: 0.787566\n",
      "[500]\ttraining's amex: 0.81891\tvalid_0's amex: 0.788866\n",
      "[600]\ttraining's amex: 0.827381\tvalid_0's amex: 0.790098\n",
      "[700]\ttraining's amex: 0.83545\tvalid_0's amex: 0.791283\n",
      "[800]\ttraining's amex: 0.843129\tvalid_0's amex: 0.791905\n",
      "[900]\ttraining's amex: 0.850568\tvalid_0's amex: 0.79264\n",
      "[1000]\ttraining's amex: 0.857932\tvalid_0's amex: 0.792519\n",
      "[1100]\ttraining's amex: 0.865313\tvalid_0's amex: 0.792965\n",
      "[1200]\ttraining's amex: 0.872518\tvalid_0's amex: 0.792807\n",
      "[1300]\ttraining's amex: 0.879652\tvalid_0's amex: 0.79282\n",
      "[1400]\ttraining's amex: 0.886264\tvalid_0's amex: 0.793225\n",
      "[1500]\ttraining's amex: 0.8929\tvalid_0's amex: 0.793545\n",
      "[1600]\ttraining's amex: 0.899515\tvalid_0's amex: 0.794702\n",
      "[1700]\ttraining's amex: 0.906\tvalid_0's amex: 0.793706\n",
      "[1800]\ttraining's amex: 0.912484\tvalid_0's amex: 0.793692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 19:16:14,223]\u001b[0m Trial 16 finished with value: 0.7944626366333687 and parameters: {'reg_alpha': 0.07015553943385826, 'reg_lambda': 13.51748415729086, 'colsample_bytree': 0.2725464509710363, 'subsample': 0.6134275014697103, 'scale_pos_weight': 2.0354728001202886, 'num_leaves': 106}. Best is trial 13 with value: 0.7957243237457016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score too high (overfitting), start a new trial\n",
      "alpha 0.0167 lambda 12.5615 colsample_bytree 0.19 subsample 0.709 scale_pos_weight 2.156 num_leaves 84\n",
      "[100]\ttraining's amex: 0.766359\tvalid_0's amex: 0.760078\n",
      "[200]\ttraining's amex: 0.785656\tvalid_0's amex: 0.776882\n",
      "[300]\ttraining's amex: 0.800252\tvalid_0's amex: 0.784206\n",
      "[400]\ttraining's amex: 0.810614\tvalid_0's amex: 0.788094\n",
      "[500]\ttraining's amex: 0.819514\tvalid_0's amex: 0.789702\n",
      "[600]\ttraining's amex: 0.827736\tvalid_0's amex: 0.7913\n",
      "[700]\ttraining's amex: 0.835557\tvalid_0's amex: 0.791422\n",
      "[800]\ttraining's amex: 0.843269\tvalid_0's amex: 0.792513\n",
      "[900]\ttraining's amex: 0.850195\tvalid_0's amex: 0.79342\n",
      "[1000]\ttraining's amex: 0.85729\tvalid_0's amex: 0.793958\n",
      "[1100]\ttraining's amex: 0.864479\tvalid_0's amex: 0.794128\n",
      "[1200]\ttraining's amex: 0.871513\tvalid_0's amex: 0.793009\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.86004 (0.9561, 0.7640)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79428 (0.9227, 0.6659)\u001b[0m\n",
      "Clear cache 472\n",
      "[100]\ttraining's amex: 0.766675\tvalid_0's amex: 0.757958\n",
      "[200]\ttraining's amex: 0.78656\tvalid_0's amex: 0.773971\n",
      "[300]\ttraining's amex: 0.800937\tvalid_0's amex: 0.783314\n",
      "[400]\ttraining's amex: 0.811765\tvalid_0's amex: 0.786983\n",
      "[500]\ttraining's amex: 0.820125\tvalid_0's amex: 0.789322\n",
      "[600]\ttraining's amex: 0.82825\tvalid_0's amex: 0.790176\n",
      "[700]\ttraining's amex: 0.83582\tvalid_0's amex: 0.790765\n",
      "[800]\ttraining's amex: 0.843416\tvalid_0's amex: 0.790919\n",
      "[900]\ttraining's amex: 0.8508\tvalid_0's amex: 0.791283\n",
      "[1000]\ttraining's amex: 0.85768\tvalid_0's amex: 0.791202\n",
      "[1100]\ttraining's amex: 0.864938\tvalid_0's amex: 0.791318\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.85271 (0.9529, 0.7526)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79141 (0.9230, 0.6598)\u001b[0m\n",
      "Clear cache 38\n",
      "[100]\ttraining's amex: 0.765869\tvalid_0's amex: 0.76155\n",
      "[200]\ttraining's amex: 0.785849\tvalid_0's amex: 0.776604\n",
      "[300]\ttraining's amex: 0.800893\tvalid_0's amex: 0.783397\n",
      "[400]\ttraining's amex: 0.811651\tvalid_0's amex: 0.786192\n",
      "[500]\ttraining's amex: 0.820155\tvalid_0's amex: 0.789307\n",
      "[600]\ttraining's amex: 0.828232\tvalid_0's amex: 0.791184\n",
      "[700]\ttraining's amex: 0.835968\tvalid_0's amex: 0.791155\n",
      "[800]\ttraining's amex: 0.843112\tvalid_0's amex: 0.791711\n",
      "[900]\ttraining's amex: 0.850129\tvalid_0's amex: 0.79262\n",
      "[1000]\ttraining's amex: 0.856834\tvalid_0's amex: 0.793481\n",
      "[1100]\ttraining's amex: 0.863963\tvalid_0's amex: 0.794061\n",
      "[1200]\ttraining's amex: 0.871118\tvalid_0's amex: 0.794368\n",
      "[1300]\ttraining's amex: 0.877543\tvalid_0's amex: 0.794443\n",
      "[1400]\ttraining's amex: 0.88403\tvalid_0's amex: 0.795119\n",
      "[1500]\ttraining's amex: 0.891129\tvalid_0's amex: 0.794491\n",
      "[1600]\ttraining's amex: 0.897456\tvalid_0's amex: 0.794319\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.88548 (0.9658, 0.8051)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79529 (0.9244, 0.6662)\u001b[0m\n",
      "Clear cache 450\n",
      "[100]\ttraining's amex: 0.765264\tvalid_0's amex: 0.763364\n",
      "[200]\ttraining's amex: 0.784881\tvalid_0's amex: 0.778713\n",
      "[300]\ttraining's amex: 0.799828\tvalid_0's amex: 0.786135\n",
      "[400]\ttraining's amex: 0.810673\tvalid_0's amex: 0.789668\n",
      "[500]\ttraining's amex: 0.818885\tvalid_0's amex: 0.792679\n",
      "[600]\ttraining's amex: 0.827182\tvalid_0's amex: 0.793812\n",
      "[700]\ttraining's amex: 0.834937\tvalid_0's amex: 0.794242\n",
      "[800]\ttraining's amex: 0.842029\tvalid_0's amex: 0.794846\n",
      "[900]\ttraining's amex: 0.848857\tvalid_0's amex: 0.795035\n",
      "[1000]\ttraining's amex: 0.856331\tvalid_0's amex: 0.79559\n",
      "[1100]\ttraining's amex: 0.863607\tvalid_0's amex: 0.795453\n",
      "[1200]\ttraining's amex: 0.870167\tvalid_0's amex: 0.795938\n",
      "[1300]\ttraining's amex: 0.877308\tvalid_0's amex: 0.795807\n",
      "[1400]\ttraining's amex: 0.884068\tvalid_0's amex: 0.795826\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.87484 (0.9619, 0.7877)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79607 (0.9260, 0.6661)\u001b[0m\n",
      "Clear cache 18\n",
      "[100]\ttraining's amex: 0.76593\tvalid_0's amex: 0.760952\n",
      "[200]\ttraining's amex: 0.784893\tvalid_0's amex: 0.776212\n",
      "[300]\ttraining's amex: 0.79972\tvalid_0's amex: 0.786737\n",
      "[400]\ttraining's amex: 0.810637\tvalid_0's amex: 0.791246\n",
      "[500]\ttraining's amex: 0.819392\tvalid_0's amex: 0.793512\n",
      "[600]\ttraining's amex: 0.82744\tvalid_0's amex: 0.793612\n",
      "[700]\ttraining's amex: 0.835007\tvalid_0's amex: 0.794865\n",
      "[800]\ttraining's amex: 0.842501\tvalid_0's amex: 0.795575\n",
      "[900]\ttraining's amex: 0.850408\tvalid_0's amex: 0.796217\n",
      "[1000]\ttraining's amex: 0.857389\tvalid_0's amex: 0.796416\n",
      "[1100]\ttraining's amex: 0.864263\tvalid_0's amex: 0.796533\n",
      "[1200]\ttraining's amex: 0.871357\tvalid_0's amex: 0.795863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-23 19:45:42,005]\u001b[0m Trial 17 finished with value: 0.7947503861772549 and parameters: {'reg_alpha': 0.01670963414677902, 'reg_lambda': 12.56150856546027, 'colsample_bytree': 0.19046355311772137, 'subsample': 0.7092053323506812, 'scale_pos_weight': 2.156200139026225, 'num_leaves': 84}. Best is trial 13 with value: 0.7957243237457016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mFold 5 | Train Score = 0.85783 (0.9549, 0.7607)\n",
      "\u001b[32m\u001b[1mFold 5 | Val Score = 0.79671 (0.9252, 0.6682)\u001b[0m\n",
      "Clear cache 346\n",
      "alpha 0.0588 lambda 16.1809 colsample_bytree 0.233 subsample 0.615 scale_pos_weight 1.88 num_leaves 92\n",
      "[100]\ttraining's amex: 0.764308\tvalid_0's amex: 0.758385\n",
      "[200]\ttraining's amex: 0.783524\tvalid_0's amex: 0.77485\n",
      "[300]\ttraining's amex: 0.798234\tvalid_0's amex: 0.782046\n",
      "[400]\ttraining's amex: 0.80869\tvalid_0's amex: 0.786687\n",
      "[500]\ttraining's amex: 0.818288\tvalid_0's amex: 0.788098\n",
      "[600]\ttraining's amex: 0.826384\tvalid_0's amex: 0.789891\n",
      "[700]\ttraining's amex: 0.833633\tvalid_0's amex: 0.790668\n",
      "[800]\ttraining's amex: 0.841685\tvalid_0's amex: 0.79201\n",
      "[900]\ttraining's amex: 0.848875\tvalid_0's amex: 0.792137\n",
      "[1000]\ttraining's amex: 0.856606\tvalid_0's amex: 0.792246\n",
      "[1100]\ttraining's amex: 0.863305\tvalid_0's amex: 0.792657\n",
      "[1200]\ttraining's amex: 0.870626\tvalid_0's amex: 0.792668\n",
      "[1300]\ttraining's amex: 0.877458\tvalid_0's amex: 0.793658\n",
      "[1400]\ttraining's amex: 0.884101\tvalid_0's amex: 0.792683\n",
      "[1500]\ttraining's amex: 0.89078\tvalid_0's amex: 0.79319\n",
      "\u001b[34m\u001b[1mFold 1 | Train Score = 0.87975 (0.9631, 0.7964)\n",
      "\u001b[32m\u001b[1mFold 1 | Val Score = 0.79361 (0.9227, 0.6645)\u001b[0m\n",
      "Clear cache 108\n",
      "[100]\ttraining's amex: 0.764802\tvalid_0's amex: 0.756886\n",
      "[200]\ttraining's amex: 0.784275\tvalid_0's amex: 0.772621\n",
      "[300]\ttraining's amex: 0.799034\tvalid_0's amex: 0.78112\n",
      "[400]\ttraining's amex: 0.809208\tvalid_0's amex: 0.785716\n",
      "[500]\ttraining's amex: 0.818153\tvalid_0's amex: 0.789057\n",
      "[600]\ttraining's amex: 0.826316\tvalid_0's amex: 0.789919\n",
      "[700]\ttraining's amex: 0.833903\tvalid_0's amex: 0.790745\n",
      "[800]\ttraining's amex: 0.841545\tvalid_0's amex: 0.790874\n",
      "[900]\ttraining's amex: 0.848515\tvalid_0's amex: 0.790866\n",
      "[1000]\ttraining's amex: 0.85605\tvalid_0's amex: 0.791953\n",
      "[1100]\ttraining's amex: 0.863415\tvalid_0's amex: 0.791911\n",
      "[1200]\ttraining's amex: 0.870586\tvalid_0's amex: 0.791814\n",
      "[1300]\ttraining's amex: 0.877784\tvalid_0's amex: 0.791585\n",
      "\u001b[34m\u001b[1mFold 2 | Train Score = 0.86814 (0.9587, 0.7776)\n",
      "\u001b[32m\u001b[1mFold 2 | Val Score = 0.79227 (0.9231, 0.6614)\u001b[0m\n",
      "Clear cache 220\n",
      "[100]\ttraining's amex: 0.764573\tvalid_0's amex: 0.761689\n",
      "[200]\ttraining's amex: 0.784263\tvalid_0's amex: 0.775962\n",
      "[300]\ttraining's amex: 0.79934\tvalid_0's amex: 0.783775\n",
      "[400]\ttraining's amex: 0.810063\tvalid_0's amex: 0.787912\n",
      "[500]\ttraining's amex: 0.818927\tvalid_0's amex: 0.789793\n",
      "[600]\ttraining's amex: 0.827346\tvalid_0's amex: 0.791499\n",
      "[700]\ttraining's amex: 0.834868\tvalid_0's amex: 0.792737\n",
      "[800]\ttraining's amex: 0.842186\tvalid_0's amex: 0.792655\n",
      "[900]\ttraining's amex: 0.849467\tvalid_0's amex: 0.793564\n",
      "[1000]\ttraining's amex: 0.856564\tvalid_0's amex: 0.793393\n",
      "[1100]\ttraining's amex: 0.86399\tvalid_0's amex: 0.793939\n",
      "[1200]\ttraining's amex: 0.871535\tvalid_0's amex: 0.794009\n",
      "[1300]\ttraining's amex: 0.878139\tvalid_0's amex: 0.794093\n",
      "[1400]\ttraining's amex: 0.884867\tvalid_0's amex: 0.794692\n",
      "[1500]\ttraining's amex: 0.891566\tvalid_0's amex: 0.794193\n",
      "[1600]\ttraining's amex: 0.897893\tvalid_0's amex: 0.794711\n",
      "[1700]\ttraining's amex: 0.904241\tvalid_0's amex: 0.794974\n",
      "[1800]\ttraining's amex: 0.910846\tvalid_0's amex: 0.794714\n",
      "\u001b[34m\u001b[1mFold 3 | Train Score = 0.90181 (0.9704, 0.8332)\n",
      "\u001b[32m\u001b[1mFold 3 | Val Score = 0.79508 (0.9243, 0.6658)\u001b[0m\n",
      "Clear cache 10\n",
      "[100]\ttraining's amex: 0.764008\tvalid_0's amex: 0.762187\n",
      "[200]\ttraining's amex: 0.783575\tvalid_0's amex: 0.776975\n",
      "[300]\ttraining's amex: 0.798287\tvalid_0's amex: 0.785225\n",
      "[400]\ttraining's amex: 0.809179\tvalid_0's amex: 0.790146\n",
      "[500]\ttraining's amex: 0.818207\tvalid_0's amex: 0.791723\n",
      "[600]\ttraining's amex: 0.826272\tvalid_0's amex: 0.793321\n",
      "[700]\ttraining's amex: 0.833603\tvalid_0's amex: 0.794724\n",
      "[800]\ttraining's amex: 0.841129\tvalid_0's amex: 0.795136\n",
      "[900]\ttraining's amex: 0.848438\tvalid_0's amex: 0.79606\n",
      "[1000]\ttraining's amex: 0.855825\tvalid_0's amex: 0.795922\n",
      "[1100]\ttraining's amex: 0.863268\tvalid_0's amex: 0.796408\n",
      "[1200]\ttraining's amex: 0.870207\tvalid_0's amex: 0.796847\n",
      "[1300]\ttraining's amex: 0.877388\tvalid_0's amex: 0.79795\n",
      "[1400]\ttraining's amex: 0.884027\tvalid_0's amex: 0.797225\n",
      "[1500]\ttraining's amex: 0.890767\tvalid_0's amex: 0.798156\n",
      "[1600]\ttraining's amex: 0.897543\tvalid_0's amex: 0.797732\n",
      "[1700]\ttraining's amex: 0.903816\tvalid_0's amex: 0.798324\n",
      "[1800]\ttraining's amex: 0.909936\tvalid_0's amex: 0.798148\n",
      "[1900]\ttraining's amex: 0.916845\tvalid_0's amex: 0.798093\n",
      "[2000]\ttraining's amex: 0.922617\tvalid_0's amex: 0.797863\n",
      "[2100]\ttraining's amex: 0.928852\tvalid_0's amex: 0.798613\n",
      "[2200]\ttraining's amex: 0.934243\tvalid_0's amex: 0.798098\n",
      "[2300]\ttraining's amex: 0.939402\tvalid_0's amex: 0.799158\n",
      "[2400]\ttraining's amex: 0.944443\tvalid_0's amex: 0.798479\n",
      "[2500]\ttraining's amex: 0.949918\tvalid_0's amex: 0.799255\n",
      "[2600]\ttraining's amex: 0.954404\tvalid_0's amex: 0.799146\n",
      "[2700]\ttraining's amex: 0.959209\tvalid_0's amex: 0.798629\n",
      "\u001b[34m\u001b[1mFold 4 | Train Score = 0.94998 (0.9845, 0.9155)\n",
      "\u001b[32m\u001b[1mFold 4 | Val Score = 0.79955 (0.9260, 0.6731)\u001b[0m\n",
      "Clear cache 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63209e65-9d82-4b2e-bf34-f4a15560f08f",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b2c30-f361-4d54-aa1a-2baf2d20715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_agg, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1057729-4387-49b7-b4e3-784ed649f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "090d2444-b672-429f-aedf-555f94fb8a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=13, values=[0.7957243237457016], datetime_start=datetime.datetime(2022, 7, 23, 17, 10, 17, 948928), datetime_complete=datetime.datetime(2022, 7, 23, 17, 49, 22, 128688), params={'reg_alpha': 0.03419275048156644, 'reg_lambda': 10.13682796954036, 'colsample_bytree': 0.21796494267435756, 'subsample': 0.6247849970379308, 'scale_pos_weight': 1.9341486908332768, 'num_leaves': 83}, distributions={'reg_alpha': LogUniformDistribution(high=0.2, low=0.001), 'reg_lambda': LogUniformDistribution(high=50.0, low=10.0), 'colsample_bytree': UniformDistribution(high=0.3, low=0.19), 'subsample': UniformDistribution(high=0.75, low=0.5), 'scale_pos_weight': UniformDistribution(high=2.5, low=1.5), 'num_leaves': IntUniformDistribution(high=125, low=75, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=13, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3895998-c541-42b5-8580-44eb8bc20e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../experiments/lgbm_gbdt_exp/optuna_study.pkl']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, f\"{CURRENT_EXP_PATH}/optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c866019b-d808-4f28-928a-7dc0d8421c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2b9d7-e6ae-4e0e-af6c-9a3ee33bf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = study_df.loc[study_df[\"state\"] == \"COMPLETE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22995960-4df7-4390-a057-54f6a09d1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df.to_csv(f\"{CURRENT_EXP_PATH}/optuna_trials.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967e81b-a756-4abe-b3e9-50804f108661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file(f'{EXP_PATH}/lgbm_gbdt_exp3/optuna_trials.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b439c86-fa0d-4db6-8b5b-2dbdc9a7aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df = study_df.drop(columns=\"number\").reset_index(drop=True).reset_index().rename(columns={\"index\": \"number\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc35b93-4119-4bfd-8f41-e84235859211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df.to_csv(f'{EXP_PATH}/lgbm_gbdt_exp3/optuna_trials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af124361-f8db-4c40-a937-045f15dd245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in get_cols(study_df, \"params\"):\n",
    "    sns.scatterplot(data=study_df, x=study_df[col], y=study_df[\"value\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4d4d4-3000-42c0-b306-3d4ca352a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df = study.trials_dataframe()\n",
    "# study_df = study_df.loc[study_df[\"state\"] == \"COMPLETE\"].reset_index(drop=True)\n",
    "# study_df.to_csv(f\"{EXP_PATH}/lgbm_dart_exp/t.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc44c2-b5cc-47a0-a4f6-e0e393618695",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2de5f-ca9d-4b2b-99ed-4c33c5a33a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, score_list, y_pred_list, held_out_index_list = [], [], [], []\n",
    "model_dict = {}\n",
    "X_val_dict = {}\n",
    "y_val_dict = {}\n",
    "y_score_dict = {}\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "for fold, (idx_tr, idx_va), n_est in zip(range(1, 10+1), kf.split(train, target), n_est_list):\n",
    "    model_dict[fold] = joblib.load(f\"{MODELS_PATH}/lgbm_models/model_{fold}.pkl\")\n",
    "    X_val_dict[fold] = train.iloc[idx_va][features]\n",
    "    y_val_dict[fold] = target[idx_va]\n",
    "    y_score_dict[fold] = model_dict[fold].predict_proba(X_val_dict[fold], raw_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e2ea6-c065-4730-bb16-daf6cb6c3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    print(i, amex_metric_np(y_score_dict[i], y_val_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d26a2-8821-47e9-a926-133148712b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = pd.concat(list(X_val_dict.values()))\n",
    "full_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5795c76-f1ae-420d-b1ac-26c7ae102239",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_gt = np.concatenate(list(y_val_dict.values()))\n",
    "len(full_train_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac46e0f-76dd-4d0f-97e8-9e4cd47a21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_scores = np.concatenate(list(y_score_dict.values()))\n",
    "len(full_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d6f6d-4b0b-4e6e-87f0-d866d7b2d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.loc[:, \"target\"] = full_train_gt\n",
    "full_train.loc[:, \"score\"] = full_train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba496c-cf37-4206-8308-1ba3ad7d1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_train.to_csv(f\"{EVALUATION_DATA_PATH}/train_single_raw_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65132c65-ddd3-4cb6-83ca-99422f726514",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c184d-3cc7-47b8-b7bb-cfbf853a6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, score_list, y_pred_list, held_out_index_list = [], [], [], []\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "for fold, (idx_tr, idx_va), n_est in zip(range(1, 10+1), kf.split(train, target), n_est_list):\n",
    "    X_train, X_val, y_train, y_val, model = None, None, None, None, None\n",
    "    start_time = datetime.datetime.now()\n",
    "    X_train = train.iloc[idx_tr][features]\n",
    "    X_val = train.iloc[idx_va][features]\n",
    "    y_train = target[idx_tr]\n",
    "    y_val = target[idx_va]\n",
    "    \n",
    "    model = my_booster(n_estimators=n_est)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model.fit(X_train, \n",
    "                  y_train,\n",
    "                  eval_set=[(X_val, y_val)], \n",
    "                  eval_metric=[lgb_amex_metric],\n",
    "                  callbacks=[log_evaluation(200)])\n",
    "    X_train, y_train = None, None\n",
    "    y_val_pred = model.predict_proba(X_val, raw_score=True)\n",
    "    score = amex_metric(y_val, y_val_pred)\n",
    "    n_trees = model.best_iteration_\n",
    "    if n_trees is None: \n",
    "        n_trees = model.n_estimators\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | {str(datetime.datetime.now() - start_time)[-12:-7]} |\"\n",
    "          f\" {n_trees:5} trees |\"\n",
    "          f\"                Score = {score:.5f}{Style.RESET_ALL}\")\n",
    "    score_list.append(score)\n",
    "    model_list.append(model)\n",
    "    held_out_index_list.append(idx_va)\n",
    "    # if INFERENCE:\n",
    "    #     y_pred_list.append(model.predict_proba(test[features], raw_score=True))\n",
    "        \n",
    "    # if ONLY_FIRST_FOLD:\n",
    "    #     break # we only want the first fold\n",
    "    \n",
    "print(f\"{Fore.GREEN}{Style.BRIGHT}OOF Score:                       {np.mean(score_list):.5f}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002a4ad-f9e9-45f0-b07b-dbcca8bff0e4",
   "metadata": {},
   "source": [
    "### Linear Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475d87c-9418-4c1c-822c-99708259bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = train_data.loc[train_data[\"customer_ID\"] == train_data[\"customer_ID\"][540]][\"P_2\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c37db-8369-40c2-aaee-7a73f3f09612",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.polyfit(x=range(len(array)), y=array, deg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7426308-7123-45c8-b5cd-a70ea9526215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(array):\n",
    "    if len(array) >= 2:\n",
    "        gradient, y_intercept = np.polyfit(x=range(len(array)), y=array.astype(\"float32\"), deg=1)\n",
    "        return gradient\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821d542-21f2-4717-be03-561634086e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_intercept(array):\n",
    "    if len(array) >= 2:\n",
    "        gradient, y_intercept = np.polyfit(x=range(len(array)), y=array.astype(\"float32\"), deg=1)\n",
    "        return y_intercept\n",
    "    else:\n",
    "        return array.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d01f4-6519-4e7f-9e90-dc3d1d4fd778",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.groupby(\"customer_ID\").agg(P_2_grad=(\"P_2\", calc_grad),\n",
    "                                        P_2_intercept=(\"P_2\", calc_intercept)).reset_index()\n",
    "train_agg_summary = train_agg_summary.merge(temp, on=\"customer_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b51106-4e0a-4bb2-b0fd-e10dbd9a35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test.groupby(\"customer_ID\").agg(P_2_grad=(\"P_2\", calc_grad),\n",
    "                                       P_2_intercept=(\"P_2\", calc_intercept)).reset_index()\n",
    "test_agg_summary = test_agg_summary.merge(temp, on=\"customer_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d8cfc-3c72-46e7-85fb-d176e2922edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Single LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4562d2b-ca79-4af6-ab41-7ea7d14ebe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3303e6a-e8e3-45b8-9acf-037976239cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'metrics': \"custom\",\n",
    "    'first_metric_only': True, \n",
    "    'random_state': 1,\n",
    "    'reg_alpha': 1, #0.0125, \n",
    "    'reg_lambda': 60, \n",
    "    'learning_rate': 0.1, \n",
    "    'n_estimators': 2000, \n",
    "    'colsample_bytree': 0.5, \n",
    "    'subsample': 0.7, \n",
    "    'subsample_freq': 5, \n",
    "    'min_child_samples': 2400, \n",
    "    'scale_pos_weight': 1.9, \n",
    "    'max_bins': 10, \n",
    "    'num_leaves': 50,\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a581c34-0a4e-4609-8d6e-eceefc946a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est_list = repeat(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3928ad-efd2-45fe-bce6-371961aa3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_score_list, val_score_list = [], []\n",
    "# for fold, (idx_tr, idx_va) in zip(range(1, 5+1), kf.split(train_agg, target)):\n",
    "#     fold = str(fold)\n",
    "#     X_train, y_train = train_agg.iloc[idx_tr], target[idx_tr]\n",
    "#     train_data = lgb.Dataset(\n",
    "#         X_train,\n",
    "#         y_train\n",
    "#     )\n",
    "#     X_val, y_val = train_agg.iloc[idx_va], target[idx_va], \n",
    "#     valid_data = lgb.Dataset(\n",
    "#         X_val,\n",
    "#         y_val,\n",
    "#         reference=train_data\n",
    "#     )\n",
    "#     print(\"Start Training\")\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.filterwarnings('ignore', category=UserWarning)\n",
    "#         model = lgb.train(\n",
    "#             params=params,\n",
    "#             train_set=train_data, \n",
    "#             valid_sets=valid_data, \n",
    "#             feval=lgb_amex_metric, \n",
    "#             early_stopping_rounds=5,\n",
    "#             categorical_feature=cat_columns,\n",
    "#             callbacks=[\n",
    "#                 log_evaluation(5),\n",
    "#             ]\n",
    "#         )\n",
    "#     y_train_pred = model.predict(X_train, raw_score=True)\n",
    "#     train_score, train_g, train_t4 = amex_metric(y_train, y_train_pred)\n",
    "#     X_train, y_train = None, None\n",
    "#     y_val_pred = model.predict(X_val, raw_score=True)\n",
    "#     val_score, val_g, val_t4 = amex_metric(y_val, y_val_pred)\n",
    "#     X_val, y_val = None, None\n",
    "#     train_score_list.append(train_score)\n",
    "#     val_score_list.append(val_score)\n",
    "#     if val_score > best_scores_json[\"validation\"][fold]:\n",
    "#         print(\"Good\")\n",
    "#         # best_scores_json[\"train\"][fold] = train_score\n",
    "#         # best_scores_json[\"validation\"][fold] = val_score\n",
    "#         # with open(f'{CURRENT_EXP_PATH}/best_scores.json', \"w\") as outfile:\n",
    "#         #     json.dump(best_scores_json, outfile)\n",
    "#         # joblib.dump(model, f'{CURRENT_EXP_PATH}/models/model{fold}.pkl')\n",
    "#     elif np.mean(train_score_list) >= np.mean(list(best_scores_json[\"train\"].values())) + 0.05:\n",
    "#         print(f\"Train score too high (overfitting), start a new trial\")\n",
    "#     print(f\"{Fore.BLUE}{Style.BRIGHT}Fold {fold} | Train Score = {train_score:.5f} ({train_g:.4f}, {train_t4:.4f})\")\n",
    "#     print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | Val Score = {val_score:.5f} ({val_g:.4f}, {val_t4:.4f}){Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abae68b-4dcf-440f-8111-c5a7db50ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(val_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c41aa-f5fe-4508-aecf-91a81534081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_df = plot_feature_importance(model.feature_name_, model.feature_importances_, figsize=(16, 50), ascending=True, limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d227d4-762a-4266-8608-a12ff165fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df.loc[imp_df[\"feature\"] == \"dummy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ead564-f43e-4fbb-9abe-41f276d7ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imp_features = sorted(imp_df.loc[imp_df[\"feature_importance\"] == 0][\"feature\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc1ec5-291d-4b66-8d64-185da08601d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(zero_imp_features, name=\"feature\").to_csv(f\"{DROP_FEATURES_PATH}/noob_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0b275-8eb3-4f10-a06f-8f51e7193969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[\"target\"] = target\n",
    "# train.to_pickle(f\"{EXP_PATH}/lgbm_gbdt_exp2/train_val.pkl\")\n",
    "# joblib.dump(train_score_list, f'{EXP_PATH}/lgbm_gbdt_exp2/5_fold_train_scores.pkl')\n",
    "# joblib.dump(val_score_list, f'{EXP_PATH}/lgbm_gbdt_exp2/5_fold_val_scores.pkl')\n",
    "# joblib.dump(val_idx_list, f'{EXP_PATH}/lgbm_gbdt_exp2/5_fold_val_indices.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4366dff-f9ec-49ab-ae29-3f047a13d504",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tune LGBM using Optuna (Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1ce3c-49b9-452c-9e71-7deeaac29eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"random_state\": 1,\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.001, 0.1, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 15, 30, log=True),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.015, 0.03, log=True),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1500, 1600, 1700, 1800, 1900, 2000]),\n",
    "        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", np.arange(0.15, 0.4, 0.01)),\n",
    "        \"subsample\": trial.suggest_categorical(\"subsample\", np.arange(0.6, 0.8, 0.02)),\n",
    "        \"subsample_freq\": trial.suggest_categorical(\"subsample_freq\", [1, 2]),\n",
    "        \"min_child_samples\": trial.suggest_categorical(\"min_child_samples\", [2000, 2250, 2500]),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0.01, 450, log=True),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical(\"scale_pos_weight\", np.arange(1.25, 2.5, 0.05)),\n",
    "        \"max_bins\": trial.suggest_categorical(\"max_bins\", np.arange(400, 550, 25)),\n",
    "        \"num_leaves\": trial.suggest_categorical(\"num_leaves\", np.arange(70, 180, 10)),\n",
    "    }\n",
    "    print(params)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_agg, target, test_size=0.2)\n",
    "    model = LGBMClassifier(**params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val, y_val)], \n",
    "            eval_metric=[lgb_amex_metric],\n",
    "            callbacks=[log_evaluation(200)]\n",
    "        )\n",
    "    y_train_pred = model.predict_proba(X_train, raw_score=True)\n",
    "    train_score = amex_metric(y_train, y_train_pred)\n",
    "    y_val_pred = model.predict_proba(X_val, raw_score=True)\n",
    "    val_score = amex_metric(y_val, y_val_pred)\n",
    "    print(f\"Fold {fold} | Train Score = {train_score:.5f}\")\n",
    "    print(f\"{Fore.GREEN}{Style.BRIGHT}Fold {fold} | Val   Score = {val_score:.5f}{Style.RESET_ALL}\")\n",
    "    return val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae9081-fcba-492f-8978-4a6289a9ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1f1bd-4acf-4f70-a910-5f7d88248517",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
